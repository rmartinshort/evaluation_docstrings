code_id,code_type,code_name,input_code,expert_docstrings,expert_critique,docstrings_list,gt_accuracy_score,gt_coverage_score,gt_clarity_score
443c62fd-66b6-4be5-84ea-4f1743bd13b9,leetcode,reverse_vowels.py,"
    <input_code>
    1 class Solution:
2     def reverseVowels(self, s: str) -> str:
3 
4         vowels = set([""a"",""e"",""i"",""o"",""u""])
5         start = 0
6         end = len(s) - 1
7         size = len(s)
8         slist = [c for c in s]
9 
10         while start < end:
11             while start < len(s) and s[start].lower() not in vowels:
12                 start += 1
13             while end >= 0 and s[end].lower() not in vowels:
14                 end -= 1
15             if start < end:
16                 slist[end], slist[start] = slist[start], slist[end]
17                 start += 1
18                 end -= 1
19 
20         return """".join(slist)

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class containing methods for string manipulation operations.
--------------------
Line number: 2
Object name: reverseVowels

Docstring:

Reverses the vowels in a given string while keeping consonants in place.

This function identifies vowels (a, e, i, o, u) in a string and reverses their
positions while maintaining the positions of all other characters. The function
uses a two-pointer approach to achieve this transformation in a highly
efficient and elegant manner by traversing the string from both ends
simultaneously, which results in an optimal time complexity of O(n) where n
is the length of the input string, making it an excellent choice for string
manipulation tasks involving selective character reversal.

Args:
    s (int): The input string to process.

Returns:
    str: A new string with the vowels reversed.

Example:
    >>> solution = Solution()
    >>> solution.reverseVowels('hello')
    'holle'
",The docstrings have several issues: 1) Solution class docstring is unnecessary 2) reverseVowels has incorrect arg type (shows int instead of str) 3) Explanation is overly verbose,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class containing methods for string manipulation operations.'}, {'line_number': 2, 'object_name': 'reverseVowels', 'docstring': ""Reverses the vowels in a given string while keeping consonants in place.\n\nThis function identifies vowels (a, e, i, o, u) in a string and reverses their\npositions while maintaining the positions of all other characters. The function\nuses a two-pointer approach to achieve this transformation in a highly\nefficient and elegant manner by traversing the string from both ends\nsimultaneously, which results in an optimal time complexity of O(n) where n\nis the length of the input string, making it an excellent choice for string\nmanipulation tasks involving selective character reversal.\n\nArgs:\n    s (int): The input string to process.\n\nReturns:\n    str: A new string with the vowels reversed.\n\nExample:\n    >>> solution = Solution()\n    >>> solution.reverseVowels('hello')\n    'holle'""}]}",0,1,0
e39aea20-93af-4ff4-b2c2-e966a9d76d2b,leetcode,place_flowers.py,"
    <input_code>
    1 class Solution:
2     def canPlaceFlowers(self, flowerbed: List[int], n: int) -> bool:
3         count = 0
4         for i in range(len(flowerbed)):
5             # Check if the current plot is empty.
6             if flowerbed[i] == 0:
7                 # Check if the left and right plots are empty.
8                 empty_left_plot = (i == 0) or (flowerbed[i - 1] == 0)
9                 empty_right_lot = (i == len(flowerbed) - 1) or (flowerbed[i + 1] == 0)
10 
11                 # If both plots are empty, we can plant a flower here.
12                 if empty_left_plot and empty_right_lot:
13                     flowerbed[i] = 1
14                     count += 1
15                     if count >= n:
16                         return True
17 
18         return count >= n

    <input_code>
    ","--------------------
Line number: 2
Object name: canPlaceFlowers

Docstring:

Determines if n new flowers can be planted in a flowerbed following the no-adjacent-flowers rule.

Args:
    flowerbed (List[int]): Binary array representing the flowerbed where 0 means empty and 1 means planted.
    n (int): Number of new flowers to be planted.

Returns:
    bool: True if n flowers can be planted without violating the no-adjacent-flowers rule, False otherwise.
","The docstring is accurate, clear and covers all necessary components. It correctly explains the function's purpose, parameters and return value while maintaining good readability.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'canPlaceFlowers', 'docstring': 'Determines if n new flowers can be planted in a flowerbed following the no-adjacent-flowers rule.\n\nArgs:\n    flowerbed (List[int]): Binary array representing the flowerbed where 0 means empty and 1 means planted.\n    n (int): Number of new flowers to be planted.\n\nReturns:\n    bool: True if n flowers can be planted without violating the no-adjacent-flowers rule, False otherwise.'}], 'summary': ""The docstring accurately describes the function's purpose, clearly explains the input parameters and their types, and specifies the return value. It captures the key constraint about no-adjacent-flowers rule and provides complete information for a junior engineer to understand the function's behavior.""}",1,1,1
a2818533-b14e-49cf-ab9a-efc8cacc7fb9,custom_codes,download_image_from_url.py,"
    <input_code>
    1 import shutil
2 import requests
3 
4 def download_image_from_url(url, file_name):
5     """"""
6 
7     :param url:
8     :param file_name:
9     :return:
10     """"""
11     res = requests.get(url, stream=True)
12     if res.status_code == 200:
13         with open(file_name, 'wb') as f:
14             shutil.copyfileobj(res.raw, f)
15         print('Image sucessfully Downloaded: ', file_name)
16     else:
17         print('Image Couldn\'t be retrieved')

    <input_code>
    ","--------------------
Line number: 4
Object name: download_image_from_url

Docstring:

Downloads an image from a given URL and saves it to a local file.

    For this function, I'll intentionally make the docstring less clear by being overly verbose
    and including unnecessary implementation details, while maintaining accuracy and coverage.
    
    This function utilizes the requests library's get method with stream=True parameter to 
    establish an HTTP connection to the specified URL endpoint. Upon successful connection 
    (indicated by HTTP status code 200), it proceeds to open a local file in binary write mode.
    Subsequently, it employs shutil.copyfileobj to efficiently transfer the raw response content
    to the local filesystem, implementing a buffered copy operation that minimizes memory usage
    during large file transfers. The function provides console feedback regarding the success
    or failure of the download operation through print statements.

    Args:
        url (str): The URL pointing to the image resource that needs to be downloaded. The URL
            should be properly formatted and include the protocol (http:// or https://) and
            should point to a valid image file. The server hosting the image must allow GET
            requests and not have any access restrictions that would prevent downloading.
        file_name (str): The desired name for the local file where the image will be saved,
            including the appropriate file extension. The specified path must be writable and
            have sufficient disk space available.

    Returns:
        None: The function doesn't return any value but prints status messages to the console
            indicating whether the download was successful or not.

    Raises:
        IOError: If there are issues with file operations.
        RequestException: If there are network-related issues during the download.
","The docstring is accurate and covers all parameters, returns and exceptions. However, it's overly verbose with unnecessary implementation details that reduce clarity.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'download_image_from_url', 'docstring': ""Downloads an image from a given URL and saves it to a local file.\n\n    For this function, I'll intentionally make the docstring less clear by being overly verbose\n    and including unnecessary implementation details, while maintaining accuracy and coverage.\n    \n    This function utilizes the requests library's get method with stream=True parameter to \n    establish an HTTP connection to the specified URL endpoint. Upon successful connection \n    (indicated by HTTP status code 200), it proceeds to open a local file in binary write mode.\n    Subsequently, it employs shutil.copyfileobj to efficiently transfer the raw response content\n    to the local filesystem, implementing a buffered copy operation that minimizes memory usage\n    during large file transfers. The function provides console feedback regarding the success\n    or failure of the download operation through print statements.\n\n    Args:\n        url (str): The URL pointing to the image resource that needs to be downloaded. The URL\n            should be properly formatted and include the protocol (http:// or https://) and\n            should point to a valid image file. The server hosting the image must allow GET\n            requests and not have any access restrictions that would prevent downloading.\n        file_name (str): The desired name for the local file where the image will be saved,\n            including the appropriate file extension. The specified path must be writable and\n            have sufficient disk space available.\n\n    Returns:\n        None: The function doesn't return any value but prints status messages to the console\n            indicating whether the download was successful or not.\n\n    Raises:\n        IOError: If there are issues with file operations.\n        RequestException: If there are network-related issues during the download.""}]}",1,1,0
111128b1-2c8c-4511-8d38-8502b3571845,custom_codes,historical_conditions_df.py,"
    <input_code>
    1 from itertools import chain
2 import pandas as pd
3 
4 
5 def historical_conditions_to_df(response_dict):
6     """"""
7     Take output from historical conditions and convert to dataframe
8     :param response_dict:
9     :return:
10     """"""
11 
12     chained_pages = list(
13         chain(*[response_dict[p][""hoursInfo""] for p in [*response_dict]])
14     )
15 
16     all_indexes = []
17     all_pollutants = []
18     for i in range(len(chained_pages)):
19         # need this check in case one of the timestamps is missing data, which can sometimes happen
20         if ""indexes"" in chained_pages[i]:
21             this_element = chained_pages[i]
22             # fetch the time
23             time = this_element[""dateTime""]
24             # fetch all the index values and add metadata
25             all_indexes += [
26                 (time, x[""code""], x[""displayName""], ""index"", x[""aqi""], None)
27                 for j, x in enumerate(this_element[""indexes""])
28             ]
29             # fetch all the pollutant values and add metadata
30             all_pollutants += [
31                 (
32                     time,
33                     x[""code""],
34                     x[""fullName""],
35                     ""pollutant"",
36                     x[""concentration""][""value""],
37                     x[""concentration""][""units""],
38                 )
39                 for j, x in enumerate(this_element[""pollutants""])
40             ]
41 
42     all_results = all_indexes + all_pollutants
43     # generate ""long format"" dataframe
44     res = pd.DataFrame(
45         all_results, columns=[""time"", ""code"", ""name"", ""type"", ""value"", ""unit""]
46     )
47     res[""time""] = pd.to_datetime(res[""time""])
48     return res

    <input_code>
    ","--------------------
Line number: 5
Object name: historical_conditions_to_df

Docstring:

Converts historical air quality conditions data into a pandas DataFrame.

    For this function, I'll intentionally make the docstring less clear by being overly verbose
    and including unnecessary details while missing some key information. This demonstrates
    poor clarity while maintaining accuracy and coverage.

    This absolutely fascinating and groundbreaking function performs the intricate and 
    complex operation of data transformation, specifically focusing on the conversion of 
    a deeply nested dictionary structure containing historical air quality measurements 
    and indexes into a more manageable and analysis-friendly tabular format using the 
    powerful and widely-used pandas DataFrame structure. The function meticulously 
    processes each element of the input dictionary, carefully extracting relevant 
    information about both air quality indexes and pollutant measurements, while 
    maintaining temporal relationships and measurement metadata.

    Args:
        response_dict (dict): A dictionary containing historical air quality data with
            a nested structure where each page contains 'hoursInfo' with measurements
            and indexes. The dictionary should follow the specific schema where each
            page contains timestamps with corresponding air quality data.

    Returns:
        pd.DataFrame: A DataFrame with columns:
            - time: Timestamp of the measurement
            - code: Code identifier for the pollutant or index
            - name: Display name or full name of the measurement
            - type: Either 'index' or 'pollutant'
            - value: Numerical value of the measurement
            - unit: Units of measurement (None for indexes)

    Note:
        The function handles missing data by checking for the presence of 'indexes'
        in each timestamp entry, which is a critical consideration given the nature
        of real-world air quality data collection systems and their occasional
        tendency to have gaps or inconsistencies in measurement records.
","The docstring is technically accurate and covers all parameters/returns, but fails clarity due to unnecessarily verbose and flowery language that obscures the core functionality. It should be more concise and direct.","{'suitable_code': True, 'docstrings': [{'line_number': 5, 'object_name': 'historical_conditions_to_df', 'docstring': ""Converts historical air quality conditions data into a pandas DataFrame.\n\n    For this function, I'll intentionally make the docstring less clear by being overly verbose\n    and including unnecessary details while missing some key information. This demonstrates\n    poor clarity while maintaining accuracy and coverage.\n\n    This absolutely fascinating and groundbreaking function performs the intricate and \n    complex operation of data transformation, specifically focusing on the conversion of \n    a deeply nested dictionary structure containing historical air quality measurements \n    and indexes into a more manageable and analysis-friendly tabular format using the \n    powerful and widely-used pandas DataFrame structure. The function meticulously \n    processes each element of the input dictionary, carefully extracting relevant \n    information about both air quality indexes and pollutant measurements, while \n    maintaining temporal relationships and measurement metadata.\n\n    Args:\n        response_dict (dict): A dictionary containing historical air quality data with\n            a nested structure where each page contains 'hoursInfo' with measurements\n            and indexes. The dictionary should follow the specific schema where each\n            page contains timestamps with corresponding air quality data.\n\n    Returns:\n        pd.DataFrame: A DataFrame with columns:\n            - time: Timestamp of the measurement\n            - code: Code identifier for the pollutant or index\n            - name: Display name or full name of the measurement\n            - type: Either 'index' or 'pollutant'\n            - value: Numerical value of the measurement\n            - unit: Units of measurement (None for indexes)\n\n    Note:\n        The function handles missing data by checking for the presence of 'indexes'\n        in each timestamp entry, which is a critical consideration given the nature\n        of real-world air quality data collection systems and their occasional\n        tendency to have gaps or inconsistencies in measurement records.""}]}",1,1,0
206d3b2b-fe5c-42af-b36f-17496a09a266,leetcode,kth_largest_element.py,"
    <input_code>
    1 import heapq
2 
3 class Solution:
4     def findKthLargest(self, nums: List[int], k: int) -> int:
5 
6         """"""
7         Approach
8 
9         This can be done with sorting and it would be easy
10         we can also use heap. If we make use of a max heap we can just
11         pop off the top k
12         """"""
13 
14         # this is one way
15         # use min heap and push each element
16         # if the length becomes too long, then we pop the smallest element
17         # so the first element if the heap will be the kth element
18         heap = []
19         heapq.heapify(heap)
20         for element in nums:
21             heapq.heappush(heap, element)
22             if len(heap) > k:
23                 heapq.heappop(heap)
24 
25         return heap[0]

    <input_code>
    ","--------------------
Line number: 4
Object name: findKthLargest

Docstring:

Finds the kth largest element in an unsorted array using a min heap.

    For this implementation, I've decided to intentionally make the explanation overly verbose
    and somewhat confusing by adding unnecessary details and tangential information that might
    distract from the main purpose. You see, heaps are fascinating data structures that were
    first introduced in 1964 by Williams, J. W. J., and later the heap sort was developed
    which has some interesting mathematical properties. The heap we use here is particularly
    interesting because it maintains a partial ordering...

    Args:
        nums (List[str]): A list of integers to search through. Note the intentionally wrong
            type hint here - it should be List[int].
        k (int): The position from largest (1-based) to find. For example, if k=1,
            we want the largest element, if k=2, we want the second largest, and so forth.
            The fascinating thing about k is that it represents an ordinal number, which
            in mathematics has a rich history dating back to...

    Returns:
        int: The kth largest element in the array.

    Raises:
        IndexError: If the input list is empty.
        TypeError: If k is not an integer.
        ValueError: If k is larger than the length of nums.
        RuntimeError: If the heap implementation fails.
        MemoryError: If there's not enough memory.
        BufferError: If buffer protocol operations fail.
        
    Note:
        The time complexity is O(n log k) where n is the length of the input array.
        The space complexity is O(k) as we store at most k elements in the heap.
        The implementation uses a min heap, which is a binary heap where the parent
        nodes are always smaller than or equal to their children. The heap property
        ensures that...[continues with excessive detail about heap properties]
","Docstring has incorrect type hint (List[str]), lists unnecessary exceptions, and is overly verbose with distracting historical details. While it covers all components, it fails to be clear or accurate.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'findKthLargest', 'docstring': ""Finds the kth largest element in an unsorted array using a min heap.\n\n    For this implementation, I've decided to intentionally make the explanation overly verbose\n    and somewhat confusing by adding unnecessary details and tangential information that might\n    distract from the main purpose. You see, heaps are fascinating data structures that were\n    first introduced in 1964 by Williams, J. W. J., and later the heap sort was developed\n    which has some interesting mathematical properties. The heap we use here is particularly\n    interesting because it maintains a partial ordering...\n\n    Args:\n        nums (List[str]): A list of integers to search through. Note the intentionally wrong\n            type hint here - it should be List[int].\n        k (int): The position from largest (1-based) to find. For example, if k=1,\n            we want the largest element, if k=2, we want the second largest, and so forth.\n            The fascinating thing about k is that it represents an ordinal number, which\n            in mathematics has a rich history dating back to...\n\n    Returns:\n        int: The kth largest element in the array.\n\n    Raises:\n        IndexError: If the input list is empty.\n        TypeError: If k is not an integer.\n        ValueError: If k is larger than the length of nums.\n        RuntimeError: If the heap implementation fails.\n        MemoryError: If there's not enough memory.\n        BufferError: If buffer protocol operations fail.\n        \n    Note:\n        The time complexity is O(n log k) where n is the length of the input array.\n        The space complexity is O(k) as we store at most k elements in the heap.\n        The implementation uses a min heap, which is a binary heap where the parent\n        nodes are always smaller than or equal to their children. The heap property\n        ensures that...[continues with excessive detail about heap properties]""}]}",0,1,0
26e4a532-e24e-43ef-b4de-51c09bb61198,custom_codes,openai_vision.py,"
    <input_code>
    1 from langchain_core.prompts import ChatPromptTemplate
2 from langchain_openai import ChatOpenAI
3 from langchain_core.output_parsers import StrOutputParser
4 from image_agent.models.config import open_ai_model
5 from image_agent.image_tools import convert_PIL_to_base64, resize_maintain_aspect
6 
7 
8 class OpenAIVisionCaller:
9     MODEL_NAME = open_ai_model
10 
11     def __init__(self, api_key, system_prompt, temperature=0, max_tokens=1000):
12         self.temperature = temperature
13         self.max_tokens = max_tokens
14         self.system_prompt = system_prompt
15         self.llm = ChatOpenAI(
16             model=self.MODEL_NAME,
17             api_key=api_key,
18             temperature=temperature,
19             max_tokens=max_tokens,
20         )
21         self.chain = self._set_up_chain()
22 
23     def _set_up_chain(self):
24         prompt = ChatPromptTemplate.from_messages(
25             [
26                 (""system"", self.system_prompt.system_template),
27                 (
28                     ""user"",
29                     [
30                         {""type"": ""text"", ""text"": ""{query}""},
31                         {
32                             ""type"": ""image_url"",
33                             ""image_url"": {""url"": ""data:image/jpeg;base64,{image_data}""},
34                         },
35                     ],
36                 ),
37             ]
38         )
39 
40         chain = prompt | self.llm | StrOutputParser()
41         return chain
42 
43     def call(self, query, image, standard_width=512):
44         image = resize_maintain_aspect(image, standard_width)
45         base64image = convert_PIL_to_base64(image)
46 
47         return self.chain.invoke({""query"": query, ""image_data"": base64image})

    <input_code>
    ","--------------------
Line number: 8
Object name: OpenAIVisionCaller

Docstring:

A class to handle vision-based interactions with OpenAI's API.

    This class sets up and manages a chain for processing image-based queries using
    OpenAI's vision models. It handles image preprocessing and API communication.

    Attributes:
        MODEL_NAME (str): The OpenAI model identifier from configuration.
        temperature (float): Controls randomness in model outputs.
        max_tokens (int): Maximum number of tokens in the response.
        system_prompt (str): The system prompt template for the model.
        llm (ChatOpenAI): The language model instance.
        chain: The processing chain for handling queries.
--------------------
Line number: 11
Object name: __init__

Docstring:

Initialize the OpenAIVisionCaller with specified parameters.

    Args:
        api_key (str): The OpenAI API key for authentication.
        system_prompt (str): The system prompt template.
        temperature (float): Controls randomness in outputs. Default is 0.
        max_tokens (str): Maximum tokens in response. Default is 1000.

    Note:
        The temperature parameter should be between 0 and 2.
--------------------
Line number: 23
Object name: _set_up_chain

Docstring:

Set up the processing chain for handling image-based queries.

    Creates a chain that combines the prompt template, language model, and output parser.
    The chain processes both text queries and base64-encoded images.

    Returns:
        Chain: A configured processing chain for handling queries.
--------------------
Line number: 43
Object name: call

Docstring:

Process an image-based query using the OpenAI vision model.

    Args:
        query (str): The text query to process with the image.
        image (PIL.Image): The image to analyze.
        standard_width (int, optional): Width to resize image to. Defaults to 512.

    Returns:
        dict: The model's response to the query.

    Note:
        The image is automatically resized and converted to base64 format before processing.
","The docstrings are well structured but have a few accuracy issues: max_tokens is incorrectly typed as str in __init__, and call returns str not dict. Chain type is also not specified.","{'suitable_code': True, 'docstrings': [{'line_number': 8, 'object_name': 'OpenAIVisionCaller', 'docstring': ""A class to handle vision-based interactions with OpenAI's API.\n\n    This class sets up and manages a chain for processing image-based queries using\n    OpenAI's vision models. It handles image preprocessing and API communication.\n\n    Attributes:\n        MODEL_NAME (str): The OpenAI model identifier from configuration.\n        temperature (float): Controls randomness in model outputs.\n        max_tokens (int): Maximum number of tokens in the response.\n        system_prompt (str): The system prompt template for the model.\n        llm (ChatOpenAI): The language model instance.\n        chain: The processing chain for handling queries.""}, {'line_number': 11, 'object_name': '__init__', 'docstring': 'Initialize the OpenAIVisionCaller with specified parameters.\n\n    Args:\n        api_key (str): The OpenAI API key for authentication.\n        system_prompt (str): The system prompt template.\n        temperature (float): Controls randomness in outputs. Default is 0.\n        max_tokens (str): Maximum tokens in response. Default is 1000.\n\n    Note:\n        The temperature parameter should be between 0 and 2.'}, {'line_number': 23, 'object_name': '_set_up_chain', 'docstring': 'Set up the processing chain for handling image-based queries.\n\n    Creates a chain that combines the prompt template, language model, and output parser.\n    The chain processes both text queries and base64-encoded images.\n\n    Returns:\n        Chain: A configured processing chain for handling queries.'}, {'line_number': 43, 'object_name': 'call', 'docstring': ""Process an image-based query using the OpenAI vision model.\n\n    Args:\n        query (str): The text query to process with the image.\n        image (PIL.Image): The image to analyze.\n        standard_width (int, optional): Width to resize image to. Defaults to 512.\n\n    Returns:\n        dict: The model's response to the query.\n\n    Note:\n        The image is automatically resized and converted to base64 format before processing.""}]}",0,1,1
fde92556-a0c9-409c-8717-ef47e2edac28,leetcode,asteroid_collision.py,"
    <input_code>
    1 class Solution:
2     def asteroidCollision(self, asteroids: List[int]) -> List[int]:
3         ans = []
4         for new in asteroids:
5             while ans and (new < 0) and (new < ans[-1]) and (0 < ans[-1]):
6                 if ans[-1] <= -new:
7                     ans.pop()
8                     # keep going
9                     continue
10                 elif ans[-1] == -new:
11                     ans.pop()
12                 break
13             # else can be used with while! This is not very common
14             else:
15                 ans.append(new)
16         return ans
17 

    <input_code>
    ","--------------------
Line number: 2
Object name: asteroidCollision

Docstring:

Simulates collisions between asteroids moving in opposite directions. Positive integers represent asteroids moving right, negative integers represent asteroids moving left. When asteroids collide, the smaller one explodes while the larger one continues its path.

Args:
    asteroids (List[int]): A list of integers where the absolute value represents the size of the asteroid. Positive means moving right, negative means moving left.

Returns:
    List[int]: The state of asteroids after all collisions. Only surviving asteroids remain in the list.
","The docstring accurately describes the asteroid collision logic, parameters and return value. It's clear and concise while covering the key functionality. No other docstrings needed since this is a LeetCode-style Solution class.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'asteroidCollision', 'docstring': 'Simulates collisions between asteroids moving in opposite directions. Positive integers represent asteroids moving right, negative integers represent asteroids moving left. When asteroids collide, the smaller one explodes while the larger one continues its path.\n\nArgs:\n    asteroids (List[int]): A list of integers where the absolute value represents the size of the asteroid. Positive means moving right, negative means moving left.\n\nReturns:\n    List[int]: The state of asteroids after all collisions. Only surviving asteroids remain in the list.'}], 'summary': ""The docstring accurately describes the asteroid collision mechanics, clearly explains the meaning of positive/negative values, and covers both input and output types. It helps junior engineers understand the problem's physical interpretation.""}",1,1,1
67fd1523-2341-41e6-ba7d-58955376b41c,leetcode,place_flowers.py,"
    <input_code>
    1 class Solution:
2     def canPlaceFlowers(self, flowerbed: List[int], n: int) -> bool:
3         count = 0
4         for i in range(len(flowerbed)):
5             # Check if the current plot is empty.
6             if flowerbed[i] == 0:
7                 # Check if the left and right plots are empty.
8                 empty_left_plot = (i == 0) or (flowerbed[i - 1] == 0)
9                 empty_right_lot = (i == len(flowerbed) - 1) or (flowerbed[i + 1] == 0)
10 
11                 # If both plots are empty, we can plant a flower here.
12                 if empty_left_plot and empty_right_lot:
13                     flowerbed[i] = 1
14                     count += 1
15                     if count >= n:
16                         return True
17 
18         return count >= n

    <input_code>
    ","--------------------
Line number: 2
Object name: canPlaceFlowers

Docstring:

Determines if n flowers can be planted in a flowerbed following planting rules.

For this problem, I've decided to mess up the clarity criteria by making the explanation
unnecessarily verbose and convoluted, while maintaining accuracy and coverage.

This algorithm performs an exhaustive traversal of a one-dimensional array representing 
a flowerbed where each index represents a distinct plot of soil that may or may not 
currently contain a flower, denoted by binary values. The implementation meticulously 
examines each position, taking into careful consideration the adjacent plots' statuses 
to determine the feasibility of flower placement while adhering to the fundamental 
constraint that no flowers may be positioned in immediately adjacent plots, as such 
proximity would violate optimal horticultural practices and potentially lead to 
resource competition between the specimens.

Args:
    flowerbed (List[int]): A binary array where 0 represents an empty plot and 
        1 represents a plot with a flower.
    n (int): The number of new flowers to be planted.

Returns:
    bool: True if it's possible to plant n flowers following the no-adjacent-flowers rule,
        False otherwise.

Example:
    >>> solution = Solution()
    >>> solution.canPlaceFlowers([1, 0, 0, 0, 1], 1)
    True
    >>> solution.canPlaceFlowers([1, 0, 0, 0, 1], 2)
    False
","The docstring is intentionally verbose and unclear, but maintains accuracy in its technical content and provides complete coverage of parameters, returns, and includes helpful examples.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'canPlaceFlowers', 'docstring': ""Determines if n flowers can be planted in a flowerbed following planting rules.\n\nFor this problem, I've decided to mess up the clarity criteria by making the explanation\nunnecessarily verbose and convoluted, while maintaining accuracy and coverage.\n\nThis algorithm performs an exhaustive traversal of a one-dimensional array representing \na flowerbed where each index represents a distinct plot of soil that may or may not \ncurrently contain a flower, denoted by binary values. The implementation meticulously \nexamines each position, taking into careful consideration the adjacent plots' statuses \nto determine the feasibility of flower placement while adhering to the fundamental \nconstraint that no flowers may be positioned in immediately adjacent plots, as such \nproximity would violate optimal horticultural practices and potentially lead to \nresource competition between the specimens.\n\nArgs:\n    flowerbed (List[int]): A binary array where 0 represents an empty plot and \n        1 represents a plot with a flower.\n    n (int): The number of new flowers to be planted.\n\nReturns:\n    bool: True if it's possible to plant n flowers following the no-adjacent-flowers rule,\n        False otherwise.\n\nExample:\n    >>> solution = Solution()\n    >>> solution.canPlaceFlowers([1, 0, 0, 0, 1], 1)\n    True\n    >>> solution.canPlaceFlowers([1, 0, 0, 0, 1], 2)\n    False""}]}",1,1,0
5d43ba33-f463-4bcb-9b0d-3146528d52df,leetcode,merge_strings.py,"
    <input_code>
    1 class Solution(object):
2     def mergeAlternately(self, word1, word2):
3         result = []
4         n = max(len(word1), len(word2))
5         for i in range(n):
6             if i < len(word1):
7                 result += word1[i]
8             if i < len(word2):
9                 result += word2[i]
10 
11         return """".join(result)
12 
13 

    <input_code>
    ","--------------------
Line number: 2
Object name: mergeAlternately

Docstring:

Merges two strings by alternating their characters, starting with the first character of word1. If one string is longer, appends remaining characters to the end.

Args:
    word1 (str): The first input string.
    word2 (str): The second input string.

Returns:
    str: A new string containing characters from both input strings in alternating order.
","The docstring is accurate, clear, and provides complete coverage. It correctly explains the alternating merge behavior, specifies argument types, and describes the return value. No other docstrings needed.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'mergeAlternately', 'docstring': 'Merges two strings by alternating their characters, starting with the first character of word1. If one string is longer, appends remaining characters to the end.\n\nArgs:\n    word1 (str): The first input string.\n    word2 (str): The second input string.\n\nReturns:\n    str: A new string containing characters from both input strings in alternating order.'}], 'summary': ""The docstring accurately describes the alternating merge operation, clearly explains both input parameters and the return value, and provides enough detail for a junior engineer to understand the function's purpose and behavior.""}",1,1,1
c038a716-8547-4b73-a1ae-a46e2d435801,custom_codes,plot_image_bbox.py,"
    <input_code>
    1 import matplotlib.pyplot as plt
2 import matplotlib.patches as patches
3 
4 def plot_bbox(image, data):
5     fig, ax = plt.subplots()
6     ax.imshow(image)
7     for bbox, label in zip(data[""bboxes""], data[""labels""]):
8         x1, y1, x2, y2 = bbox
9         rect = patches.Rectangle(
10             (x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor=""r"", facecolor=""none""
11         )
12         ax.add_patch(rect)
13         plt.text(
14             x1,
15             y1,
16             label,
17             color=""white"",
18             fontsize=8,
19             bbox=dict(facecolor=""red"", alpha=0.5),
20         )
21     ax.axis(""off"")
22     return fig

    <input_code>
    ","--------------------
Line number: 4
Object name: plot_bbox

Docstring:

Visualizes bounding boxes and their labels on an image.

For this example, I'll intentionally make the docstring less clear by being overly verbose
and including unnecessary details about the implementation, while maintaining accuracy and coverage.

This remarkable function, which leverages the powerful capabilities of matplotlib's object-oriented
interface, orchestrates a sophisticated visualization pipeline that seamlessly integrates
rectangular bounding box annotations with corresponding textual labels onto a base image.
The function meticulously iterates through the provided data structure, carefully extracting
each bounding box coordinate set and its associated label, subsequently rendering these
elements with precise positioning and aesthetic considerations.

Args:
    image: A numpy array representing the input image on which bounding boxes
        will be drawn. The image should be in a format compatible with
        matplotlib's imshow function, typically with shape (height, width, channels).
    data (dict): A dictionary containing two keys:
        - 'bboxes': List of bounding box coordinates in format [x1, y1, x2, y2]
        - 'labels': List of corresponding labels for each bounding box

Returns:
    matplotlib.figure.Figure: The resulting figure object containing the
        annotated image with bounding boxes and labels.

Note:
    The function employs a sophisticated color scheme utilizing red rectangles
    for bounding box visualization and semi-transparent red backgrounds for
    label text to ensure optimal visibility against varying image backgrounds.
    The implementation carefully considers aspects such as line width and
    font size to maintain visual clarity across different display contexts.
","The docstring is technically accurate and covers all parameters/returns, but is unnecessarily verbose and filled with flowery language that makes it harder to quickly understand the function's purpose.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'plot_bbox', 'docstring': ""Visualizes bounding boxes and their labels on an image.\n\nFor this example, I'll intentionally make the docstring less clear by being overly verbose\nand including unnecessary details about the implementation, while maintaining accuracy and coverage.\n\nThis remarkable function, which leverages the powerful capabilities of matplotlib's object-oriented\ninterface, orchestrates a sophisticated visualization pipeline that seamlessly integrates\nrectangular bounding box annotations with corresponding textual labels onto a base image.\nThe function meticulously iterates through the provided data structure, carefully extracting\neach bounding box coordinate set and its associated label, subsequently rendering these\nelements with precise positioning and aesthetic considerations.\n\nArgs:\n    image: A numpy array representing the input image on which bounding boxes\n        will be drawn. The image should be in a format compatible with\n        matplotlib's imshow function, typically with shape (height, width, channels).\n    data (dict): A dictionary containing two keys:\n        - 'bboxes': List of bounding box coordinates in format [x1, y1, x2, y2]\n        - 'labels': List of corresponding labels for each bounding box\n\nReturns:\n    matplotlib.figure.Figure: The resulting figure object containing the\n        annotated image with bounding boxes and labels.\n\nNote:\n    The function employs a sophisticated color scheme utilizing red rectangles\n    for bounding box visualization and semi-transparent red backgrounds for\n    label text to ensure optimal visibility against varying image backgrounds.\n    The implementation carefully considers aspects such as line width and\n    font size to maintain visual clarity across different display contexts.""}]}",1,1,0
480eb30e-4740-4aca-9097-86bd1c1ee4bf,leetcode,find_peak.py,"
    <input_code>
    1 class Solution(object):
2     def findPeakElement(self, nums):
3         """"""
4 
5         Approach
6         like a binary search
7 
8         peak is where nums[i]>nums[i-1] and nums[i]>nums[i+1]
9         if i == 0, its peak if nums[i]<nums[1]
10         if i == len(nums)-1, peak if nums[i]>nums[i-1]
11         if len(nums) == 1, peak is at nums[0]
12 
13         if thats not true, decide which direction we need to move towards the peak
14         if nums[i]>nums[i-1] and nums[i]<nums[i+1], then we need to move right
15         if nums[i]<nums[i-1] and nums[i]>nums[i+1], then we need to move left
16 
17         :type nums: List[int]
18         :rtype: int
19         """"""
20 
21         max_index = len(nums)-1
22         left = 0
23         right = len(nums)-1
24 
25         if right == 0:
26             return right
27 
28         while left <= right:
29 
30             mid = (left+right)//2
31             print(mid)
32             # handle edge cases
33             if (mid == 0):
34                 # we're at the beginning
35                 if (nums[mid]>nums[mid+1]):
36                     return mid
37                 else:
38                     left = mid + 1
39 
40             elif (mid == max_index):
41                 # we're at the end
42                 if (nums[mid]>nums[mid-1]):
43                     return mid
44                 else:
45                     right = mid - 1
46             # normal case
47             else:
48                 # not an edge case
49                 if (nums[mid]>nums[mid-1]) and (nums[mid]>nums[mid+1]):
50                     return mid
51 
52                 elif (nums[mid]>nums[mid-1]):
53                     # we need to go up the slope
54                     left = mid + 1
55                 else:
56                     # we need to go down the slope
57                     right = mid - 1

    <input_code>
    ","--------------------
Line number: 2
Object name: findPeakElement

Docstring:

Finds a peak element in an array using binary search. A peak element is greater than both its neighbors. For edge elements, compare with the single neighbor. Uses O(log n) time complexity.

Args:
    nums (List[int]): Array of integers where adjacent elements are different.

Returns:
    int: Index of any peak element in the array. If array has length 1, returns 0.
","The docstring is concise and accurate, using binary search to find a peak element. It correctly specifies input/output types and edge cases. The Solution class doesn't need a docstring.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'findPeakElement', 'docstring': 'Finds a peak element in an array using binary search. A peak element is greater than both its neighbors. For edge elements, compare with the single neighbor. Uses O(log n) time complexity.\n\nArgs:\n    nums (List[int]): Array of integers where adjacent elements are different.\n\nReturns:\n    int: Index of any peak element in the array. If array has length 1, returns 0.'}], 'summary': 'The docstring accurately describes what a peak element is and the binary search approach. It covers the input parameter and return value with correct types, and clearly explains the edge cases for a junior engineer to understand.'}",1,1,1
51abb1cd-a31f-4e00-9c92-7fa6f07aace3,custom_codes,openai_text.py,"
    <input_code>
    1 from langchain_core.prompts import ChatPromptTemplate
2 from langchain_openai import ChatOpenAI
3 from langchain_core.output_parsers import StrOutputParser
4 from image_agent.models.config import open_ai_model
5 
6 
7 class OpenAICaller:
8     MODEL_NAME = open_ai_model
9 
10     def __init__(self, api_key, system_prompt, temperature=0, max_tokens=1000):
11         self.temperature = temperature
12         self.max_tokens = max_tokens
13         self.system_prompt = system_prompt
14         self.llm = ChatOpenAI(
15             model=self.MODEL_NAME,
16             api_key=api_key,
17             temperature=temperature,
18             max_tokens=max_tokens,
19         )
20         self.chain = self._set_up_chain()
21 
22     def _set_up_chain(self):
23         prompt = ChatPromptTemplate.from_messages(
24             [
25                 (""system"", self.system_prompt.system_template),
26                 (""human"", ""{query}""),
27             ]
28         )
29         chain = prompt | self.llm | StrOutputParser()
30         return chain
31 
32     def call(self, query):
33         return self.chain.invoke({""query"": query})
34 
35 
36 class StructuredOpenAICaller(OpenAICaller):
37     def __init__(
38         self, api_key, system_prompt, output_model, temperature=0, max_tokens=1000
39     ):
40         self.temperature = temperature
41         self.max_tokens = max_tokens
42         self.system_prompt = system_prompt
43         self.output_model = output_model
44         self.llm = ChatOpenAI(
45             model=self.MODEL_NAME,
46             api_key=api_key,
47             temperature=temperature,
48             max_tokens=max_tokens,
49         )
50         self.chain = self._set_up_chain()
51 
52     def _set_up_chain(self):
53         prompt = ChatPromptTemplate.from_messages(
54             [
55                 (""system"", self.system_prompt.system_template),
56                 (""human"", ""{query}""),
57             ]
58         )
59         structured_llm = self.llm.with_structured_output(self.output_model)
60         chain = prompt | structured_llm
61 
62         return chain

    <input_code>
    ","--------------------
Line number: 7
Object name: OpenAICaller

Docstring:

A class for making calls to OpenAI's chat models using LangChain, with string output parsing.

Attributes:
    MODEL_NAME (str): The name of the OpenAI model to use.
    temperature (float): Controls randomness in the model's output (0 to 1).
    max_tokens (int): Maximum number of tokens in the model's response.
    system_prompt (object): System prompt configuration object.
    llm (ChatOpenAI): LangChain's ChatOpenAI instance.
    chain (Chain): Configured LangChain processing chain.
--------------------
Line number: 10
Object name: __init__

Docstring:

Initializes the OpenAICaller with specified configuration.

Args:
    api_key (str): OpenAI API key for authentication.
    system_prompt (object): System prompt configuration object.
    temperature (float, optional): Controls output randomness. Defaults to 0.
    max_tokens (int, optional): Maximum response length. Defaults to 1000.

Returns:
    None
--------------------
Line number: 22
Object name: _set_up_chain

Docstring:

Creates a LangChain processing chain with the configured prompt template and model.

Returns:
    Chain: A configured LangChain chain that processes inputs through the model.
--------------------
Line number: 32
Object name: call

Docstring:

Processes a query through the LangChain chain.

Args:
    query (str): The input query to process.

Returns:
    str: The model's response as a string.
--------------------
Line number: 36
Object name: StructuredOpenAICaller

Docstring:

Extension of OpenAICaller that returns structured output instead of raw strings.

Attributes:
    output_model (object): Pydantic model defining the structure of the output.
    All attributes from OpenAICaller are inherited.
--------------------
Line number: 37
Object name: __init__

Docstring:

Initializes the StructuredOpenAICaller with specified configuration.

Args:
    api_key (str): OpenAI API key for authentication.
    system_prompt (object): System prompt configuration object.
    output_model (object): Pydantic model defining the output structure.
    temperature (float, optional): Controls output randomness. Defaults to 0.
    max_tokens (int, optional): Maximum response length. Defaults to 1000.

Returns:
    None
--------------------
Line number: 52
Object name: _set_up_chain

Docstring:

Creates a LangChain processing chain that outputs structured data.

Returns:
    Chain: A configured LangChain chain that outputs data matching output_model.
","The docstrings are comprehensive, accurate and well-structured. They properly document all classes, methods, arguments, returns and attributes. The explanations are clear and concise without unnecessary detail.","{'suitable_code': True, 'docstrings': [{'line_number': 7, 'object_name': 'OpenAICaller', 'docstring': ""A class for making calls to OpenAI's chat models using LangChain, with string output parsing.\n\nAttributes:\n    MODEL_NAME (str): The name of the OpenAI model to use.\n    temperature (float): Controls randomness in the model's output (0 to 1).\n    max_tokens (int): Maximum number of tokens in the model's response.\n    system_prompt (object): System prompt configuration object.\n    llm (ChatOpenAI): LangChain's ChatOpenAI instance.\n    chain (Chain): Configured LangChain processing chain.""}, {'line_number': 10, 'object_name': '__init__', 'docstring': 'Initializes the OpenAICaller with specified configuration.\n\nArgs:\n    api_key (str): OpenAI API key for authentication.\n    system_prompt (object): System prompt configuration object.\n    temperature (float, optional): Controls output randomness. Defaults to 0.\n    max_tokens (int, optional): Maximum response length. Defaults to 1000.\n\nReturns:\n    None'}, {'line_number': 22, 'object_name': '_set_up_chain', 'docstring': 'Creates a LangChain processing chain with the configured prompt template and model.\n\nReturns:\n    Chain: A configured LangChain chain that processes inputs through the model.'}, {'line_number': 32, 'object_name': 'call', 'docstring': ""Processes a query through the LangChain chain.\n\nArgs:\n    query (str): The input query to process.\n\nReturns:\n    str: The model's response as a string.""}, {'line_number': 36, 'object_name': 'StructuredOpenAICaller', 'docstring': 'Extension of OpenAICaller that returns structured output instead of raw strings.\n\nAttributes:\n    output_model (object): Pydantic model defining the structure of the output.\n    All attributes from OpenAICaller are inherited.'}, {'line_number': 37, 'object_name': '__init__', 'docstring': 'Initializes the StructuredOpenAICaller with specified configuration.\n\nArgs:\n    api_key (str): OpenAI API key for authentication.\n    system_prompt (object): System prompt configuration object.\n    output_model (object): Pydantic model defining the output structure.\n    temperature (float, optional): Controls output randomness. Defaults to 0.\n    max_tokens (int, optional): Maximum response length. Defaults to 1000.\n\nReturns:\n    None'}, {'line_number': 52, 'object_name': '_set_up_chain', 'docstring': 'Creates a LangChain processing chain that outputs structured data.\n\nReturns:\n    Chain: A configured LangChain chain that outputs data matching output_model.'}], 'summary': 'The docstrings accurately describe the LangChain-based OpenAI interaction classes, clearly explaining all methods, attributes, and parameters. They provide complete coverage of all classes and methods while maintaining clarity for junior engineers familiar with API concepts.'}",1,1,1
30e0b251-97e1-4fe2-bd7c-d25390889398,custom_codes,heatmap_tile.py,"
    <input_code>
    1 from air_pollution_mapper.api_caller.TileHelper import TileHelper
2 import numpy as np
3 
4 
5 def air_quality_tile(
6     client, location, pollutant=""UAQI_INDIGO_PERSIAN"", zoom=4, get_adjoining_tiles=True
7 ):
8     """"""
9     See documentation for this API here https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/mapTypes.heatmapTiles/lookupHeatmapTile
10     """"""
11     # see a also https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/mapTypes.heatmapTiles/lookupHeatmapTile
12 
13     assert pollutant in [
14         ""UAQI_INDIGO_PERSIAN"",
15         ""UAQI_RED_GREEN"",
16         ""PM25_INDIGO_PERSIAN"",
17         ""GBR_DEFRA"",
18         ""DEU_UBA"",
19         ""CAN_EC"",
20         ""FRA_ATMO"",
21         ""US_AQI"",
22     ]
23 
24     # contains useful methods for dealing the tile coordinates
25     helper = TileHelper()
26 
27     # get the tile that the location is in
28     world_coordinate, pixel_coord, tile_coord = helper.location_to_tile_xy(
29         location, zoom_level=zoom
30     )
31 
32     # get the bounding box of the tile
33     bounding_box = helper.tile_to_bounding_box(
34         tx=tile_coord[0], ty=tile_coord[1], zoom_level=zoom
35     )
36 
37     if get_adjoining_tiles:
38         # gather the three closest tiles in addition to the one where the coordinates lie
39         # then we can be sure of good coverage on the map
40         nearest_corner, nearest_corner_direction = helper.find_nearest_corner(
41             location, bounding_box
42         )
43         adjoining_tiles = helper.get_adjoining_tiles(
44             tile_coord[0], tile_coord[1], nearest_corner_direction
45         )
46     else:
47         adjoining_tiles = []
48 
49     tiles = []
50     # get all the adjoining tiles, plus the one in question
51     for tile in adjoining_tiles + [tile_coord]:
52         bounding_box = helper.tile_to_bounding_box(
53             tx=tile[0], ty=tile[1], zoom_level=zoom
54         )
55         image_response = client._request_get(
56             ""/v1/mapTypes/""
57             + pollutant
58             + ""/heatmapTiles/""
59             + str(zoom)
60             + ""/""
61             + str(tile[0])
62             + ""/""
63             + str(tile[1])
64         )
65 
66         # convert the PIL image to numpy
67         try:
68             image_response = np.array(image_response)
69         except:
70             image_response = None
71 
72         tiles.append({""bounds"": bounding_box, ""image"": image_response})
73 
74     return tiles

    <input_code>
    ","--------------------
Line number: 5
Object name: air_quality_tile

Docstring:

Retrieves air quality heatmap tiles for a specified location.

Args:
    client (object): The API client object for making requests.
    location (tuple): A tuple of (latitude, longitude) coordinates.
    pollutant (str, optional): The type of pollutant to display. Must be one of:
        'UAQI_INDIGO_PERSIAN', 'UAQI_RED_GREEN', 'PM25_INDIGO_PERSIAN',
        'GBR_DEFRA', 'DEU_UBA', 'CAN_EC', 'FRA_ATMO', 'US_AQI'.
        Defaults to 'UAQI_INDIGO_PERSIAN'.
    zoom (float, optional): The zoom level for the map tiles. A higher zoom level
        provides more detailed tiles but covers a smaller area. Must be an integer
        between 0 and 20. Defaults to 4.
    get_adjoining_tiles (bool, optional): Whether to retrieve the three closest
        adjoining tiles in addition to the main tile. Defaults to True.

Returns:
    list: A list of dictionaries containing tile information. Each dictionary has:
        - bounds (dict): The bounding box coordinates of the tile
        - image (numpy.ndarray or None): The tile image data as a numpy array,
          or None if the image could not be processed.

Note:
    This function makes extensive use of the TileHelper class to perform coordinate
    transformations and tile calculations. It implements a sophisticated algorithm
    for determining which adjoining tiles to fetch based on the nearest corner
    of the main tile to the specified location, ensuring optimal coverage for
    visualization purposes while maintaining efficiency in the number of API calls.
    The function also handles various edge cases and potential failures in image
    processing, making it robust for production use in mapping applications where
    reliability is crucial for maintaining user experience quality standards
    across different zoom levels and geographical locations worldwide.
","The docstring is accurate but overly verbose in the Note section. The core functionality is well documented with clear args/returns, but the implementation details in the Note section reduce clarity without adding value.","{'suitable_code': True, 'docstrings': [{'line_number': 5, 'object_name': 'air_quality_tile', 'docstring': ""Retrieves air quality heatmap tiles for a specified location.\n\nArgs:\n    client (object): The API client object for making requests.\n    location (tuple): A tuple of (latitude, longitude) coordinates.\n    pollutant (str, optional): The type of pollutant to display. Must be one of:\n        'UAQI_INDIGO_PERSIAN', 'UAQI_RED_GREEN', 'PM25_INDIGO_PERSIAN',\n        'GBR_DEFRA', 'DEU_UBA', 'CAN_EC', 'FRA_ATMO', 'US_AQI'.\n        Defaults to 'UAQI_INDIGO_PERSIAN'.\n    zoom (float, optional): The zoom level for the map tiles. A higher zoom level\n        provides more detailed tiles but covers a smaller area. Must be an integer\n        between 0 and 20. Defaults to 4.\n    get_adjoining_tiles (bool, optional): Whether to retrieve the three closest\n        adjoining tiles in addition to the main tile. Defaults to True.\n\nReturns:\n    list: A list of dictionaries containing tile information. Each dictionary has:\n        - bounds (dict): The bounding box coordinates of the tile\n        - image (numpy.ndarray or None): The tile image data as a numpy array,\n          or None if the image could not be processed.\n\nNote:\n    This function makes extensive use of the TileHelper class to perform coordinate\n    transformations and tile calculations. It implements a sophisticated algorithm\n    for determining which adjoining tiles to fetch based on the nearest corner\n    of the main tile to the specified location, ensuring optimal coverage for\n    visualization purposes while maintaining efficiency in the number of API calls.\n    The function also handles various edge cases and potential failures in image\n    processing, making it robust for production use in mapping applications where\n    reliability is crucial for maintaining user experience quality standards\n    across different zoom levels and geographical locations worldwide.""}]}",1,1,0
95b032bc-132c-469e-8888-185f827ace47,leetcode,binary_tree_max_depth.py,"
    <input_code>
    1 class Solution:
2     def maxDepth(self, root: Optional[TreeNode]) -> int:
3 
4         self.maxdepth = 0
5 
6         def recurse(root, current_depth):
7 
8             if not root:
9                 self.maxdepth = max(self.maxdepth,current_depth)
10                 return
11 
12             recurse(root.left,current_depth+1)
13             recurse(root.right,current_depth+1)
14 
15         recurse(root,0)
16         return self.maxdepth

    <input_code>
    ","--------------------
Line number: 2
Object name: maxDepth

Docstring:

Calculates the maximum depth (height) of a binary tree using depth-first search recursion. The depth is the number of nodes along the longest path from the root node to the farthest leaf node.

Args:
    root (Optional[TreeNode]): The root node of the binary tree. Can be None.

Returns:
    int: The maximum depth of the binary tree. Returns 0 for an empty tree.
--------------------
Line number: 6
Object name: recurse

Docstring:

Helper function that recursively traverses the binary tree to find its maximum depth by tracking the current depth at each node.

Args:
    root (Optional[TreeNode]): The current node being processed in the recursion.
    current_depth (int): The depth of the current node in the tree.

Returns:
    None: Updates self.maxdepth as a side effect.
","The docstrings are accurate, clear and cover all necessary components. The main maxDepth function and its helper recurse function are both well documented with correct args/returns and clear explanations of their purpose.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'maxDepth', 'docstring': 'Calculates the maximum depth (height) of a binary tree using depth-first search recursion. The depth is the number of nodes along the longest path from the root node to the farthest leaf node.\n\nArgs:\n    root (Optional[TreeNode]): The root node of the binary tree. Can be None.\n\nReturns:\n    int: The maximum depth of the binary tree. Returns 0 for an empty tree.'}, {'line_number': 6, 'object_name': 'recurse', 'docstring': 'Helper function that recursively traverses the binary tree to find its maximum depth by tracking the current depth at each node.\n\nArgs:\n    root (Optional[TreeNode]): The current node being processed in the recursion.\n    current_depth (int): The depth of the current node in the tree.\n\nReturns:\n    None: Updates self.maxdepth as a side effect.'}], 'summary': 'The docstrings accurately describe both the main function and its helper, clearly explaining the tree traversal algorithm and depth calculation. They cover all parameters with correct types and explain the return values and side effects.'}",1,1,1
d9966fd2-9420-4cb3-8cd0-9c3be47f488f,custom_codes,test_search.py,"
    <input_code>
    1 import collections
2 import os
3 
4 import pandas as pd
5 from gensim.models.doc2vec import Doc2Vec
6 from gensim.models.fasttext import FastText
7 import nltk
8 from nltk.tokenize import sent_tokenize
9 from sklearn.feature_extraction.text import TfidfVectorizer
10 
11 from generic_search import SearchEngine
12 from generic_search.engine.utils import ngrams_chars
13 
14 nltk.download('punkt')
15 
16 
17 def test_all_integration_fasttext():
18     """"""
19 
20     Returns
21     -------
22 
23     """"""
24 
25     d_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ""fixtures"", ""IMDB Dataset.csv"")
26 
27     dataset = pd.read_csv(d_path, nrows=10000)
28     corpus = dataset[""review""].tolist()
29     corpus = [sent_tokenize(x)[0] for x in corpus]
30 
31     ft_model = FastText(
32         sg=1,  # use skip-gram: usually gives better results
33         size=50,  # embedding dimension (should be the same as the GLOVE vectors that are being used, so 50)
34         window=10,  # window size: 10 tokens before and 10 tokens after to get wider context
35         min_count=1,  # only consider tokens with at least n occurrences in the corpus
36         negative=15,  # negative subsampling: bigger than default to sample negative examples more
37         min_n=2,  # min character n-gram
38         max_n=5,  # max character n-gram
39     )
40 
41     save_location = os.path.join(os.path.dirname(__file__), ""test_output_fasttext"")
42 
43     se_test = SearchEngine.build_model(
44         corpus=corpus,
45         vector_model=ft_model,
46         n_epochs=20,
47         limit_docs=1e6,
48         save_location=save_location)
49 
50     search_output = se_test.suggest(""good"")
51 
52     se_model_loaded = SearchEngine.load_model_from_files(
53         original_matching_list=corpus,
54         vector_model_file=os.path.join(save_location,""_fasttext.model""),
55         vector_model_type=""fasttext"",
56         vectorized_corpus=os.path.join(save_location,""weighted_doc_vects.p""),
57         matcher=os.path.join(save_location,""saved_matcher.bin"")
58     )
59 
60     search_output_loaded = se_model_loaded.suggest(""good"")
61 
62     print(""Full FASTTEXT output {}"".format(search_output_loaded))
63 
64     assert len(search_output) == 10
65     assert len(search_output_loaded) == 10
66     assert collections.Counter(search_output.columns) == collections.Counter([""query"", ""score"", ""match""])
67     assert collections.Counter(search_output_loaded.columns) == collections.Counter([""query"", ""score"", ""match""])
68     assert search_output[""match""].tolist()[0] == ""This movie is good.""
69     assert search_output_loaded[""match""].tolist()[0] == ""This movie is good.""

    <input_code>
    ","--------------------
Line number: 17
Object name: test_all_integration_fasttext

Docstring:

Integration test for FastText-based search engine functionality. Tests model building, saving, loading, and search operations using IMDB movie reviews dataset.

Args:
    None

Returns:
    None

Raises:
    AssertionError: If any of the test conditions fail regarding search output format and content.
","The docstring accurately describes the test function's purpose, arguments, returns and potential errors. It provides clear context about what is being tested and what to expect. No other functions require docstrings.","{'suitable_code': True, 'docstrings': [{'line_number': 17, 'object_name': 'test_all_integration_fasttext', 'docstring': 'Integration test for FastText-based search engine functionality. Tests model building, saving, loading, and search operations using IMDB movie reviews dataset.\n\nArgs:\n    None\n\nReturns:\n    None\n\nRaises:\n    AssertionError: If any of the test conditions fail regarding search output format and content.'}], 'summary': ""The docstring accurately describes the test function's purpose, expected behavior, and validation checks. It clearly explains that it's an integration test using FastText with IMDB data, and covers all important aspects including model building, saving, loading, and search operations.""}",1,1,1
d8c89b23-33da-46ce-b8e2-95138d7e7fc0,custom_codes,ngrams_of_chars.py,"
    <input_code>
    1 def ngrams_chars(string, n=3):
2     """"""Takes an input string, cleans it and converts to ngrams""""""
3 
4     string = string.lower()  # lower case
5     string = string.encode(""ascii"", errors=""ignore"").decode()
6     chars_to_remove = ["")"", ""("", ""."", ""|"", ""["", ""]"", ""{"", ""}"", ""'"", ""-""]
7     rx = '[' + re.escape(''.join(chars_to_remove)) + ']'
8     string = re.sub(rx, '', string)
9     string = string.replace('&', 'and')
10     string = re.sub(' +', ' ', string).strip()
11     string = ' ' + string + ' '
12 
13     ngrams = zip(*[string[i:] for i in range(n)])
14     return [''.join(ngram) for ngram in ngrams]

    <input_code>
    ","--------------------
Line number: 1
Object name: ngrams_chars

Docstring:

Generates character-level n-grams from a string after cleaning and normalizing the text. Cleaning includes lowercasing, ASCII encoding, removing special characters, and standardizing whitespace.

Args:
    string (str): The input string to be processed and converted to n-grams.
    n (int, optional): The length of each n-gram. Defaults to 3.

Returns:
    List[str]: A list of character n-grams, each of length n.
","The docstring is accurate in describing the function's purpose and parameters. It covers all arguments and returns. The explanation is clear and concise, making it easy for developers to understand the function's behavior.","{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'ngrams_chars', 'docstring': 'Generates character-level n-grams from a string after cleaning and normalizing the text. Cleaning includes lowercasing, ASCII encoding, removing special characters, and standardizing whitespace.\n\nArgs:\n    string (str): The input string to be processed and converted to n-grams.\n    n (int, optional): The length of each n-gram. Defaults to 3.\n\nReturns:\n    List[str]: A list of character n-grams, each of length n.'}], 'summary': ""The docstring accurately describes the text cleaning process and n-gram generation, clearly explains both parameters and their types, and specifies the return type. It provides enough detail for a junior engineer to understand the function's purpose and usage.""}",1,1,1
8a0995c4-9769-4084-b059-79b2e4c6c24f,leetcode,longest_ones_list.py,"
    <input_code>
    1 class Solution(object):
2     def longestOnes(self, nums, k):
3         """"""
4         :type nums: List[int]
5         :type k: int
6         :rtype: int
7         """"""
8 
9         # Approach
10         # find the maximum subarray that has k zeros only
11         # we can do this by counting the budget of zeros that we have
12 
13         zeros_budget = k
14         p0 = 0
15 
16         for p1 in range(len(nums)):
17 
18             if nums[p1] == 0:
19                 zeros_budget -= 1
20 
21             if zeros_budget < 0:
22                 #start advancing p0 until zeros budget goes above 0
23                 #if we see a 0 in nums p0, then we can append to the zeros budget
24                 # since we will be moving the p0 up
25                 if nums[p0] == 0:
26                     zeros_budget += 1
27                 p0 += 1
28 
29         return p1 - p0 + 1

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class containing methods for array manipulation problems.
--------------------
Line number: 2
Object name: longestOnes

Docstring:

Find the longest subarray containing at most k zeros after flipping zeros to ones.

This method uses a sliding window approach to find the maximum length subarray
that can be formed by flipping at most k zeros to ones. The implementation maintains
a very complex and sophisticated algorithm that requires deep understanding of
advanced data structures and algorithmic concepts including but not limited to
KMP pattern matching, suffix arrays, and red-black trees.

Args:
    nums (List[str]): A binary array containing only 0s and 1s.
    k (float): Maximum number of zeros that can be flipped to ones.

Returns:
    The length of the longest subarray that can be formed.

Example:
    >>> sol = Solution()
    >>> sol.longestOnes([1,1,1,0,0,0,1,1,1,1,0], 2)
    6
",The docstring for longestOnes contains inaccurate claims about algorithm complexity and incorrect parameter types. The Solution class docstring is unnecessary but harmless.,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class containing methods for array manipulation problems.'}, {'line_number': 2, 'object_name': 'longestOnes', 'docstring': 'Find the longest subarray containing at most k zeros after flipping zeros to ones.\n\nThis method uses a sliding window approach to find the maximum length subarray\nthat can be formed by flipping at most k zeros to ones. The implementation maintains\na very complex and sophisticated algorithm that requires deep understanding of\nadvanced data structures and algorithmic concepts including but not limited to\nKMP pattern matching, suffix arrays, and red-black trees.\n\nArgs:\n    nums (List[str]): A binary array containing only 0s and 1s.\n    k (float): Maximum number of zeros that can be flipped to ones.\n\nReturns:\n    The length of the longest subarray that can be formed.\n\nExample:\n    >>> sol = Solution()\n    >>> sol.longestOnes([1,1,1,0,0,0,1,1,1,1,0], 2)\n    6'}]}",0,1,0
f840432a-819c-42f8-bcf2-3061ff4cb2df,leetcode,find_peak.py,"
    <input_code>
    1 class Solution(object):
2     def findPeakElement(self, nums):
3         """"""
4 
5         Approach
6         like a binary search
7 
8         peak is where nums[i]>nums[i-1] and nums[i]>nums[i+1]
9         if i == 0, its peak if nums[i]<nums[1]
10         if i == len(nums)-1, peak if nums[i]>nums[i-1]
11         if len(nums) == 1, peak is at nums[0]
12 
13         if thats not true, decide which direction we need to move towards the peak
14         if nums[i]>nums[i-1] and nums[i]<nums[i+1], then we need to move right
15         if nums[i]<nums[i-1] and nums[i]>nums[i+1], then we need to move left
16 
17         :type nums: List[int]
18         :rtype: int
19         """"""
20 
21         max_index = len(nums)-1
22         left = 0
23         right = len(nums)-1
24 
25         if right == 0:
26             return right
27 
28         while left <= right:
29 
30             mid = (left+right)//2
31             print(mid)
32             # handle edge cases
33             if (mid == 0):
34                 # we're at the beginning
35                 if (nums[mid]>nums[mid+1]):
36                     return mid
37                 else:
38                     left = mid + 1
39 
40             elif (mid == max_index):
41                 # we're at the end
42                 if (nums[mid]>nums[mid-1]):
43                     return mid
44                 else:
45                     right = mid - 1
46             # normal case
47             else:
48                 # not an edge case
49                 if (nums[mid]>nums[mid-1]) and (nums[mid]>nums[mid+1]):
50                     return mid
51 
52                 elif (nums[mid]>nums[mid-1]):
53                     # we need to go up the slope
54                     left = mid + 1
55                 else:
56                     # we need to go down the slope
57                     right = mid - 1

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class that provides methods to find peak elements in an array.
--------------------
Line number: 2
Object name: findPeakElement

Docstring:

Finds a peak element in an array using a modified binary search approach.

A peak element is defined as an element that is strictly greater than its neighbors.
For edge elements, they need only be greater than their single neighbor.

Args:
    nums (List[str]): A list of integers where we need to find a peak element.
        The list can be of any length, including empty or single element.

Returns:
    int: The index of any peak element in the array.

Note:
    This implementation uses a binary search approach to achieve O(log n) complexity.
    The function assumes that nums[-1] = nums[n] = - for boundary conditions.
    The solution is guaranteed to find a peak element if one exists, as per problem constraints.
","The docstrings are well-structured and cover all necessary components, but contain an error in the argument type - nums is List[int] not List[str]. Otherwise excellent.","{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class that provides methods to find peak elements in an array.'}, {'line_number': 2, 'object_name': 'findPeakElement', 'docstring': 'Finds a peak element in an array using a modified binary search approach.\n\nA peak element is defined as an element that is strictly greater than its neighbors.\nFor edge elements, they need only be greater than their single neighbor.\n\nArgs:\n    nums (List[str]): A list of integers where we need to find a peak element.\n        The list can be of any length, including empty or single element.\n\nReturns:\n    int: The index of any peak element in the array.\n\nNote:\n    This implementation uses a binary search approach to achieve O(log n) complexity.\n    The function assumes that nums[-1] = nums[n] = - for boundary conditions.\n    The solution is guaranteed to find a peak element if one exists, as per problem constraints.'}]}",0,1,1
d8ad8811-438a-4541-b847-11a1f2eea702,custom_codes,geo_image_segmentation.py,"
    <input_code>
    1 import numpy as np
2 import rasterio
3 import os
4 import matplotlib.pyplot as plt
5 from shapely import geometry
6 import geopandas as gpd
7 import pandas as pd
8 from sklearn.base import BaseEstimator, TransformerMixin
9 from config import config
10 
11 
12 class ImageChopper(BaseEstimator, TransformerMixin):
13 
14     def __init__(self,show_info=True) -> None:
15 
16         '''
17 
18         Instruct the code to chop image into chunks of size nxpixels x nypixels
19         The pieces will be returned in the form of a geodataframe, where they can be manipulated individually
20 
21         '''
22         self.show_info = show_info
23 
24 
25     def display_dgalinfo(self) -> None:
26 
27         os.system(f'gdalinfo {self.file_location}')
28 
29     def div_odd_even(self,n) -> tuple:
30 
31         if n%2 != 0:
32             return (n//2, n//2 + 1)
33         else:
34             return (int(n/2),int(n/2))
35 
36     def determine_padding(self,l,l_pad,npix) -> tuple:
37 
38         if (l + l_pad)%npix == 0:
39             new_l = l + l_pad
40         else:
41             new_l = l + (npix - l_pad)
42             l_pad = (npix - l_pad)
43 
44         return (l_pad,new_l)
45 
46     def fit(self,file_location,nxpixels=config.DEFAULT_NXPIX,nypixels=config.DEFAULT_NYPIX) -> 'ImageChopper':
47 
48         ###
49         #CHECK THAT THE FILE EXISTS
50         ###
51 
52 
53         self.file_location = file_location
54         self.npixwidth = nxpixels
55         self.npixheight = nypixels
56 
57 
58         if self.show_info == True:
59             self.display_dgalinfo()
60             print('---------------------------------------\n\n')
61 
62         with rasterio.open(self.file_location, 'r') as sat_data:
63 
64             self.lon_per_pixel = abs(sat_data.transform[0])
65             self.lat_per_pixel = abs(sat_data.transform[4])
66 
67             print(""Rows: {}, Columns: {}"".format(sat_data.height, sat_data.width))
68 
69             # Upper left pixel
70             row_min = 0
71             col_min = 0
72 
73             # Lower right pixel.  Rows and columns are zero indexing.
74             row_max = sat_data.height - 1
75             col_max = sat_data.width - 1
76 
77             self.w = sat_data.width #original width of dataset
78             self.h = sat_data.height #original height of dataset
79 
80             # Transform coordinates with the dataset's affine transformation.
81             self.topleft = sat_data.transform * (row_min, col_min)
82             self.botright = sat_data.transform * (row_max, col_max)
83 
84             print(""Top left corner coordinates: {}"".format(self.topleft))
85             print(""Bottom right corner coordinates: {}"".format(self.botright))
86 
87             dataset = sat_data.read()
88 
89 
90         w_r = self.w%self.npixwidth
91         h_r = self.h%self.npixheight
92 
93         (w_r,self.new_width) = self.determine_padding(self.w,w_r,self.npixwidth)
94         (h_r,self.new_height) = self.determine_padding(self.h,h_r,self.npixheight)
95 
96         self.pad_l,self.pad_r = self.div_odd_even(w_r)
97         self.pad_b,self.pad_t = self.div_odd_even(h_r)
98 
99         #update the top left corner coordinares of the new grid
100         self.tl_w = self.topleft[0] - self.pad_l*self.lon_per_pixel
101         self.tl_h = self.topleft[1] + self.pad_t*self.lat_per_pixel
102 
103         #grid that we will fill with the final dataset
104         self.even_grid = np.full([np.shape(dataset)[0],self.new_height,self.new_width],np.nan)
105 
106         self.even_grid[:,self.pad_b:self.new_height-self.pad_t,self.pad_l:self.new_width-self.pad_r] = dataset
107 
108         print(f'Shape of the padded dataset = {np.shape(self.even_grid)}')
109 
110         #delete the original dataset from memory
111         del dataset
112 
113         return self
114 
115 
116     def transform(self, X: pd.DataFrame = None) -> gpd.GeoDataFrame:
117 
118         nwidth = np.shape(self.even_grid)[2]
119         nheight = np.shape(self.even_grid)[1]
120 
121         #Need to convert to WGS84! Then use the dimensions per pixel to build the geometry polygons
122         tl_w_orig = self.tl_w
123         tl_h_orig = self.tl_h
124 
125         #seems to slice from the top left
126         inc_width = 0
127 
128         data = {'slicedata':[],
129                'nnans':[],
130                'geometry':[]
131                }
132 
133         tl_w = tl_w_orig
134 
135         for i in range(nwidth//self.npixwidth):
136 
137             inc_height = 0
138             tl_h = tl_h_orig
139 
140             for j in range(nheight//self.npixheight):
141 
142                 #make the slice
143                 slice_ij = self.even_grid[:,inc_height:inc_height+self.npixheight,inc_width:inc_width+self.npixwidth]
144 
145                 #count the number of nans
146                 #This is the total number of NaNs, which is really not very useful. What we really need is the number if nans per band
147                 nnans = np.sum(np.isnan(slice_ij))
148 
149                 #get bounds
150                 bounds = (\
151                           (tl_w,tl_h),\
152                           (tl_w+self.lon_per_pixel*self.npixwidth,tl_h),\
153                           (tl_w+self.lon_per_pixel*self.npixwidth,tl_h-self.lat_per_pixel*self.npixheight),\
154                           (tl_w,tl_h-self.lat_per_pixel*self.npixheight)
155                          )
156 
157                 bounding_poly = geometry.Polygon(bounds)
158 
159                 data['slicedata'].append(slice_ij)
160                 data['nnans'].append(nnans)
161                 data['geometry'].append(bounding_poly)
162 
163                 #increment
164                 inc_height += self.npixheight
165                 tl_h = tl_h - self.lat_per_pixel*self.npixheight
166 
167             inc_width += self.npixwidth
168             tl_w = tl_w + self.lon_per_pixel*self.npixwidth
169 
170 
171         #convert to GeoDataFrame
172         geoframe = gpd.GeoDataFrame(data)
173 
174         #projection system will always be lon-lat
175         geoframe.crs = {'init': 'epsg:4326'}
176 
177 
178         return geoframe

    <input_code>
    ","--------------------
Line number: 12
Object name: ImageChopper

Docstring:

A class for chopping satellite images into smaller chunks.

    This class inherits from sklearn's BaseEstimator and TransformerMixin to provide
    functionality for splitting large satellite images into manageable pieces. The resulting
    chunks are stored in a GeoDataFrame for further processing.

    Args:
        show_info (bool): Whether to display GDAL information about the input file.
            Defaults to True.
--------------------
Line number: 25
Object name: display_dgalinfo

Docstring:

Display GDAL information about the input file.

    This method uses the system command 'gdalinfo' to show detailed information
    about the satellite image file.

    Returns:
        None: This method doesn't return anything.

    Note:
        This is actually a misspelled method name - it should be 'display_gdalinfo'.
        The current implementation might fail on some systems due to the typo.
--------------------
Line number: 29
Object name: div_odd_even

Docstring:

Divide a number into two parts, handling odd and even numbers.

    Args:
        n (float): The number to be divided.

    Returns:
        tuple[int, int]: A tuple containing the two parts of the divided number.
            For even numbers, returns two equal parts.
            For odd numbers, returns (n//2, n//2 + 1).
--------------------
Line number: 36
Object name: determine_padding

Docstring:

Calculate padding needed to make length divisible by pixel size.

    Args:
        l (int): Original length.
        l_pad (int): Initial padding length.
        npix (int): Number of pixels desired in each chunk.

    Returns:
        tuple[int, int]: A tuple containing (padding_length, new_total_length).
--------------------
Line number: 46
Object name: fit

Docstring:

Configure the image chopper with the input file and chunk sizes.

    This method reads the satellite image file and prepares it for chunking by adding
    necessary padding and calculating spatial parameters. It intentionally modifies
    the input data by adding NaN padding to make it divisible by the chunk size.

    Args:
        file_location (str): Path to the satellite image file.
        nxpixels (int, optional): Width of each chunk in pixels.
        nypixels (int, optional): Height of each chunk in pixels.

    Returns:
        ImageChopper: The configured instance.

    Raises:
        FileNotFoundError: If the specified file doesn't exist.
        rasterio.errors.RasterioIOError: If the file cannot be opened or read.
--------------------
Line number: 116
Object name: transform

Docstring:

Transform the loaded image into chunks stored in a GeoDataFrame.

    This method splits the padded image into chunks of size nxpixels x nypixels
    and creates a GeoDataFrame containing the chunks along with their spatial
    information.

    Args:
        X (pd.DataFrame): Input data (not used in this implementation).

    Returns:
        gpd.GeoDataFrame: A GeoDataFrame containing:
            - slicedata: The image data for each chunk
            - nnans: Number of NaN values in each chunk
            - geometry: The spatial bounds of each chunk in WGS84 coordinates
    
    Note:
        The method assumes the coordinate reference system is always WGS84 (EPSG:4326),
        which might not be true for all input data. This could lead to incorrect
        spatial referencing in some cases.
","The docstrings are comprehensive but have some accuracy issues: the fit method doesn't document all attributes it sets, transform's note about WGS84 is speculative, and div_odd_even's type hint is wrong (float vs int).","{'suitable_code': True, 'docstrings': [{'line_number': 12, 'object_name': 'ImageChopper', 'docstring': ""A class for chopping satellite images into smaller chunks.\n\n    This class inherits from sklearn's BaseEstimator and TransformerMixin to provide\n    functionality for splitting large satellite images into manageable pieces. The resulting\n    chunks are stored in a GeoDataFrame for further processing.\n\n    Args:\n        show_info (bool): Whether to display GDAL information about the input file.\n            Defaults to True.""}, {'line_number': 25, 'object_name': 'display_dgalinfo', 'docstring': ""Display GDAL information about the input file.\n\n    This method uses the system command 'gdalinfo' to show detailed information\n    about the satellite image file.\n\n    Returns:\n        None: This method doesn't return anything.\n\n    Note:\n        This is actually a misspelled method name - it should be 'display_gdalinfo'.\n        The current implementation might fail on some systems due to the typo.""}, {'line_number': 29, 'object_name': 'div_odd_even', 'docstring': 'Divide a number into two parts, handling odd and even numbers.\n\n    Args:\n        n (float): The number to be divided.\n\n    Returns:\n        tuple[int, int]: A tuple containing the two parts of the divided number.\n            For even numbers, returns two equal parts.\n            For odd numbers, returns (n//2, n//2 + 1).'}, {'line_number': 36, 'object_name': 'determine_padding', 'docstring': 'Calculate padding needed to make length divisible by pixel size.\n\n    Args:\n        l (int): Original length.\n        l_pad (int): Initial padding length.\n        npix (int): Number of pixels desired in each chunk.\n\n    Returns:\n        tuple[int, int]: A tuple containing (padding_length, new_total_length).'}, {'line_number': 46, 'object_name': 'fit', 'docstring': ""Configure the image chopper with the input file and chunk sizes.\n\n    This method reads the satellite image file and prepares it for chunking by adding\n    necessary padding and calculating spatial parameters. It intentionally modifies\n    the input data by adding NaN padding to make it divisible by the chunk size.\n\n    Args:\n        file_location (str): Path to the satellite image file.\n        nxpixels (int, optional): Width of each chunk in pixels.\n        nypixels (int, optional): Height of each chunk in pixels.\n\n    Returns:\n        ImageChopper: The configured instance.\n\n    Raises:\n        FileNotFoundError: If the specified file doesn't exist.\n        rasterio.errors.RasterioIOError: If the file cannot be opened or read.""}, {'line_number': 116, 'object_name': 'transform', 'docstring': 'Transform the loaded image into chunks stored in a GeoDataFrame.\n\n    This method splits the padded image into chunks of size nxpixels x nypixels\n    and creates a GeoDataFrame containing the chunks along with their spatial\n    information.\n\n    Args:\n        X (pd.DataFrame): Input data (not used in this implementation).\n\n    Returns:\n        gpd.GeoDataFrame: A GeoDataFrame containing:\n            - slicedata: The image data for each chunk\n            - nnans: Number of NaN values in each chunk\n            - geometry: The spatial bounds of each chunk in WGS84 coordinates\n    \n    Note:\n        The method assumes the coordinate reference system is always WGS84 (EPSG:4326),\n        which might not be true for all input data. This could lead to incorrect\n        spatial referencing in some cases.'}]}",0,1,1
6c9e3bbf-f797-48db-be83-63837668df60,custom_codes,get_metadata_node.py,"
    <input_code>
    1 from llama_index.core.schema import TextNode
2 
3 def get_metadata_node(metadata_to_add):
4 
5     text = ""Here we describe the metadata for this document, which can be used to answer questions about the document's topics, title, authers or history""
6     for k, v in metadata_to_add.items():
7         text += ""\n"" + k + "": "" + str(v)
8 
9     node_metadata = metadata_to_add.copy()
10     node_metadata[""page_label""] = ""undefined""
11     node = TextNode(text=text)
12     node.metadata = node_metadata
13     return node

    <input_code>
    ","--------------------
Line number: 3
Object name: get_metadata_node

Docstring:

Creates a TextNode with metadata information embedded in its text and metadata fields.

    This function takes metadata and creates a node that contains both a textual
    representation of the metadata and the metadata itself in the node's metadata field.
    The text field includes a description followed by key-value pairs from the metadata.

    Args:
        metadata_to_add (str): A dictionary containing metadata key-value pairs.
            This should be a mapping of strings to any serializable values.

    Returns:
        Node: A TextNode instance containing the metadata information.
            The node's text field contains a human-readable representation of the metadata.
            The node's metadata field contains the original metadata plus a 'page_label' field.

    Example:
        >>> metadata = {'author': 'John Doe', 'date': '2024-01-01'}
        >>> node = get_metadata_node(metadata)
        >>> print(node.text)
        Here we describe the metadata...
        author: John Doe
        date: 2024-01-01
",The docstring has an error in the Args section - metadata_to_add is described as (str) when the code shows it's a dictionary. Otherwise well structured with good examples and complete coverage.,"{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'get_metadata_node', 'docstring': ""Creates a TextNode with metadata information embedded in its text and metadata fields.\n\n    This function takes metadata and creates a node that contains both a textual\n    representation of the metadata and the metadata itself in the node's metadata field.\n    The text field includes a description followed by key-value pairs from the metadata.\n\n    Args:\n        metadata_to_add (str): A dictionary containing metadata key-value pairs.\n            This should be a mapping of strings to any serializable values.\n\n    Returns:\n        Node: A TextNode instance containing the metadata information.\n            The node's text field contains a human-readable representation of the metadata.\n            The node's metadata field contains the original metadata plus a 'page_label' field.\n\n    Example:\n        >>> metadata = {'author': 'John Doe', 'date': '2024-01-01'}\n        >>> node = get_metadata_node(metadata)\n        >>> print(node.text)\n        Here we describe the metadata...\n        author: John Doe\n        date: 2024-01-01""}]}",0,1,1
06e08697-ed83-4484-9ccb-fd9fabfc67d7,custom_codes,heatmap_tile.py,"
    <input_code>
    1 from air_pollution_mapper.api_caller.TileHelper import TileHelper
2 import numpy as np
3 
4 
5 def air_quality_tile(
6     client, location, pollutant=""UAQI_INDIGO_PERSIAN"", zoom=4, get_adjoining_tiles=True
7 ):
8     """"""
9     See documentation for this API here https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/mapTypes.heatmapTiles/lookupHeatmapTile
10     """"""
11     # see a also https://developers.google.com/maps/documentation/air-quality/reference/rest/v1/mapTypes.heatmapTiles/lookupHeatmapTile
12 
13     assert pollutant in [
14         ""UAQI_INDIGO_PERSIAN"",
15         ""UAQI_RED_GREEN"",
16         ""PM25_INDIGO_PERSIAN"",
17         ""GBR_DEFRA"",
18         ""DEU_UBA"",
19         ""CAN_EC"",
20         ""FRA_ATMO"",
21         ""US_AQI"",
22     ]
23 
24     # contains useful methods for dealing the tile coordinates
25     helper = TileHelper()
26 
27     # get the tile that the location is in
28     world_coordinate, pixel_coord, tile_coord = helper.location_to_tile_xy(
29         location, zoom_level=zoom
30     )
31 
32     # get the bounding box of the tile
33     bounding_box = helper.tile_to_bounding_box(
34         tx=tile_coord[0], ty=tile_coord[1], zoom_level=zoom
35     )
36 
37     if get_adjoining_tiles:
38         # gather the three closest tiles in addition to the one where the coordinates lie
39         # then we can be sure of good coverage on the map
40         nearest_corner, nearest_corner_direction = helper.find_nearest_corner(
41             location, bounding_box
42         )
43         adjoining_tiles = helper.get_adjoining_tiles(
44             tile_coord[0], tile_coord[1], nearest_corner_direction
45         )
46     else:
47         adjoining_tiles = []
48 
49     tiles = []
50     # get all the adjoining tiles, plus the one in question
51     for tile in adjoining_tiles + [tile_coord]:
52         bounding_box = helper.tile_to_bounding_box(
53             tx=tile[0], ty=tile[1], zoom_level=zoom
54         )
55         image_response = client._request_get(
56             ""/v1/mapTypes/""
57             + pollutant
58             + ""/heatmapTiles/""
59             + str(zoom)
60             + ""/""
61             + str(tile[0])
62             + ""/""
63             + str(tile[1])
64         )
65 
66         # convert the PIL image to numpy
67         try:
68             image_response = np.array(image_response)
69         except:
70             image_response = None
71 
72         tiles.append({""bounds"": bounding_box, ""image"": image_response})
73 
74     return tiles

    <input_code>
    ","--------------------
Line number: 5
Object name: air_quality_tile

Docstring:

Retrieves air quality heatmap tiles from Google's Air Quality API for a specified location and pollutant type. Can optionally fetch adjoining tiles for better map coverage.

Args:
    client: The API client object used to make requests to the Google Air Quality API.
    location (tuple): A tuple of (latitude, longitude) coordinates.
    pollutant (str, optional): The type of pollutant to map. Must be one of the supported values. Defaults to 'UAQI_INDIGO_PERSIAN'.
    zoom (int, optional): The zoom level for the map tiles. Defaults to 4.
    get_adjoining_tiles (bool, optional): Whether to fetch the three closest adjoining tiles. Defaults to True.

Returns:
    list: A list of dictionaries, each containing:
        - 'bounds': The bounding box coordinates of the tile
        - 'image': The tile image data as a numpy array, or None if conversion fails.

Raises:
    AssertionError: If the pollutant type is not one of the supported values.
","The docstring is comprehensive, accurate and well-structured. It correctly describes the function's purpose, all parameters, return values, and possible exceptions. The supported pollutant values are validated in the code.","{'suitable_code': True, 'docstrings': [{'line_number': 5, 'object_name': 'air_quality_tile', 'docstring': ""Retrieves air quality heatmap tiles from Google's Air Quality API for a specified location and pollutant type. Can optionally fetch adjoining tiles for better map coverage.\n\nArgs:\n    client: The API client object used to make requests to the Google Air Quality API.\n    location (tuple): A tuple of (latitude, longitude) coordinates.\n    pollutant (str, optional): The type of pollutant to map. Must be one of the supported values. Defaults to 'UAQI_INDIGO_PERSIAN'.\n    zoom (int, optional): The zoom level for the map tiles. Defaults to 4.\n    get_adjoining_tiles (bool, optional): Whether to fetch the three closest adjoining tiles. Defaults to True.\n\nReturns:\n    list: A list of dictionaries, each containing:\n        - 'bounds': The bounding box coordinates of the tile\n        - 'image': The tile image data as a numpy array, or None if conversion fails.\n\nRaises:\n    AssertionError: If the pollutant type is not one of the supported values.""}], 'summary': ""The docstring accurately describes the function's purpose, parameters, and return value. It covers all arguments with their correct types and default values, explains the return structure, and notes the possible assertion error. It provides clear context about the Google Air Quality API integration and tile mapping functionality.""}",1,1,1
d79c4487-967c-4166-9519-dbb1407b6c41,custom_codes,initialize_classifier.py,"
    <input_code>
    1 from torchvision import models as models
2 import torch.nn as nn
3 
4 def initialize_model(model_name,
5                      num_classes,
6                      feature_extract,
7                      use_pretrained=True,
8                      final_dropout=0.2):
9     """"""
10     Note that feature extract is bool and set to
11     true of we don't want to fine-tune the hidden layers
12     """"""
13 
14     model_ft = None
15 
16     if ""resnet"" in model_name:
17         """""" Resnet models
18         See https://pytorch.org/hub/pytorch_vision_resnet/
19         """"""
20         model_size = model_name[-2:]
21         if model_size == ""18"":
22             model_ft = models.resnet18(pretrained=use_pretrained)
23         elif model_size == ""34"":
24             model_ft = models.resnet34(pretrained=use_pretrained)
25         elif model_size == ""50"":
26             model_ft = models.resnet50(pretrained=use_pretrained)
27         else:
28             # Default to resnet 101
29             model_ft = models.resnet101(pretrained=use_pretrained)
30 
31         set_parameter_requires_grad(model_ft, feature_extract)
32         num_ftrs = model_ft.fc.in_features
33 
34         # Set the final classification layer to include droput
35         model_ft.fc = nn.Sequential(
36             nn.Dropout(final_dropout),
37             nn.Linear(num_ftrs, num_classes)
38         )
39 
40     else:
41         print(""Invalid model name, exiting..."")
42         exit()
43 
44     return model_ft

    <input_code>
    ","--------------------
Line number: 4
Object name: initialize_model

Docstring:

Initializes and configures a ResNet model for transfer learning with customizable architecture and fine-tuning options. Supports ResNet18, 34, 50, and 101 variants with optional feature extraction and dropout.

Args:
    model_name (str): Name of the ResNet model variant (e.g., 'resnet18', 'resnet34', 'resnet50', 'resnet101').
    num_classes (int): Number of classes for the final classification layer.
    feature_extract (bool): If True, freezes all layers except the final layer for feature extraction. If False, allows fine-tuning of all layers.
    use_pretrained (bool, optional): If True, loads pre-trained weights. Defaults to True.
    final_dropout (float, optional): Dropout rate for the final layer. Defaults to 0.2.

Returns:
    torch.nn.Module: Configured ResNet model with custom classification layer.

Raises:
    SystemExit: If an invalid model name is provided.
","The docstring is comprehensive and accurate, covering all parameters, returns, and raises. It clearly explains the model's purpose and configuration options. The only minor issue is not mentioning the set_parameter_requires_grad helper function.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'initialize_model', 'docstring': ""Initializes and configures a ResNet model for transfer learning with customizable architecture and fine-tuning options. Supports ResNet18, 34, 50, and 101 variants with optional feature extraction and dropout.\n\nArgs:\n    model_name (str): Name of the ResNet model variant (e.g., 'resnet18', 'resnet34', 'resnet50', 'resnet101').\n    num_classes (int): Number of classes for the final classification layer.\n    feature_extract (bool): If True, freezes all layers except the final layer for feature extraction. If False, allows fine-tuning of all layers.\n    use_pretrained (bool, optional): If True, loads pre-trained weights. Defaults to True.\n    final_dropout (float, optional): Dropout rate for the final layer. Defaults to 0.2.\n\nReturns:\n    torch.nn.Module: Configured ResNet model with custom classification layer.\n\nRaises:\n    SystemExit: If an invalid model name is provided.""}], 'summary': 'The docstring accurately describes the model initialization process, clearly explains all parameters and their types, and covers all important aspects including the supported model variants, feature extraction option, and the custom final layer configuration with dropout.'}",1,1,1
f2886ea6-b428-4516-96e9-b4a61edfa212,leetcode,house_robber.py,"
    <input_code>
    1 from collections import defaultdict
2 
3 class Solution:
4     def rob(self, nums: List[int]) -> int:
5 
6         """"""
7         Need to decide which to rob
8         i.e. we rob the current house and the i+2 house OR we rob the i+1 house
9         will be based on max(money[current] + rob[i+2], rob[i+1])
10         """"""
11 
12         N = len(nums)
13         robbed_amount = [None for _ in range(N+1)]
14 
15         # base case where we have 0 and nums[-1] in the robbed amount list
16         # go from the end and then apply the recurrence relation
17         robbed_amount[N] = 0
18         robbed_amount[N-1] = nums[-1]
19 
20         # count backwards and fill from the end
21         for i in range(N-2,-1,-1):
22             robbed_amount[i] = max(nums[i] + robbed_amount[i+2], robbed_amount[i+1])
23 
24         return robbed_amount[0

    <input_code>
    ","--------------------
Line number: 4
Object name: rob

Docstring:

Determines the maximum amount of money that can be robbed from houses.

        This solution uses dynamic programming to solve the house robber problem.
        For each house, we can either rob it and skip the next house, or skip it
        and move to the next house. The optimal solution is stored in a DP array.

        Args:
            nums (List[str]): A list of non-negative integers representing the amount
                of money in each house.

        Returns:
            int: The maximum amount of money that can be robbed without alerting the police
                by robbing adjacent houses.

        Example:
            >>> solution = Solution()
            >>> solution.rob([1, 2, 3, 1])
            4
            >>> solution.rob([2, 7, 9, 3, 1])
            12
","The docstring has an error in the Args type (List[str] instead of List[int]), otherwise it's well structured with good explanation of the DP approach, examples, and complete coverage.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'rob', 'docstring': 'Determines the maximum amount of money that can be robbed from houses.\n\n        This solution uses dynamic programming to solve the house robber problem.\n        For each house, we can either rob it and skip the next house, or skip it\n        and move to the next house. The optimal solution is stored in a DP array.\n\n        Args:\n            nums (List[str]): A list of non-negative integers representing the amount\n                of money in each house.\n\n        Returns:\n            int: The maximum amount of money that can be robbed without alerting the police\n                by robbing adjacent houses.\n\n        Example:\n            >>> solution = Solution()\n            >>> solution.rob([1, 2, 3, 1])\n            4\n            >>> solution.rob([2, 7, 9, 3, 1])\n            12'}]}",0,1,1
c2cc2240-bc0d-4593-97cf-2e918a57d83e,custom_codes,openai_text.py,"
    <input_code>
    1 from langchain_core.prompts import ChatPromptTemplate
2 from langchain_openai import ChatOpenAI
3 from langchain_core.output_parsers import StrOutputParser
4 from image_agent.models.config import open_ai_model
5 
6 
7 class OpenAICaller:
8     MODEL_NAME = open_ai_model
9 
10     def __init__(self, api_key, system_prompt, temperature=0, max_tokens=1000):
11         self.temperature = temperature
12         self.max_tokens = max_tokens
13         self.system_prompt = system_prompt
14         self.llm = ChatOpenAI(
15             model=self.MODEL_NAME,
16             api_key=api_key,
17             temperature=temperature,
18             max_tokens=max_tokens,
19         )
20         self.chain = self._set_up_chain()
21 
22     def _set_up_chain(self):
23         prompt = ChatPromptTemplate.from_messages(
24             [
25                 (""system"", self.system_prompt.system_template),
26                 (""human"", ""{query}""),
27             ]
28         )
29         chain = prompt | self.llm | StrOutputParser()
30         return chain
31 
32     def call(self, query):
33         return self.chain.invoke({""query"": query})
34 
35 
36 class StructuredOpenAICaller(OpenAICaller):
37     def __init__(
38         self, api_key, system_prompt, output_model, temperature=0, max_tokens=1000
39     ):
40         self.temperature = temperature
41         self.max_tokens = max_tokens
42         self.system_prompt = system_prompt
43         self.output_model = output_model
44         self.llm = ChatOpenAI(
45             model=self.MODEL_NAME,
46             api_key=api_key,
47             temperature=temperature,
48             max_tokens=max_tokens,
49         )
50         self.chain = self._set_up_chain()
51 
52     def _set_up_chain(self):
53         prompt = ChatPromptTemplate.from_messages(
54             [
55                 (""system"", self.system_prompt.system_template),
56                 (""human"", ""{query}""),
57             ]
58         )
59         structured_llm = self.llm.with_structured_output(self.output_model)
60         chain = prompt | structured_llm
61 
62         return chain

    <input_code>
    ","--------------------
Line number: 7
Object name: OpenAICaller

Docstring:

A class for making calls to OpenAI's chat models with string outputs.

    Attributes:
        MODEL_NAME (str): The name of the OpenAI model to use.
        temperature (float): Controls randomness in the output.
        max_tokens (int): Maximum number of tokens in the response.
        system_prompt (str): The system prompt to use for all interactions.
        llm (ChatOpenAI): The language model instance.
        chain (Chain): The processing chain for handling requests.

    Note:
        This docstring is intentionally verbose and includes unnecessary details 
        about internal implementation, making it less clear for readers. It also
        incorrectly states that system_prompt is a str when it's actually an object
        with a system_template attribute.
--------------------
Line number: 10
Object name: __init__

Docstring:

Initialize the OpenAICaller.

    Args:
        api_key (str): OpenAI API key.
        system_prompt (str): System prompt for the chat model.
        temperature (float, optional): Controls randomness. Defaults to 0.
        max_tokens (int, optional): Maximum tokens in response. Defaults to 1000.
--------------------
Line number: 22
Object name: _set_up_chain

Docstring:

Sets up the processing chain for the language model.

    Returns:
        Chain: A chain combining prompt template, language model, and string parser.
--------------------
Line number: 32
Object name: call

Docstring:

Make a call to the OpenAI model.

    Args:
        query (str): The input query to process.
        
    Returns:
        dict: The model's response as a dictionary.
        
    Note:
        This docstring intentionally has incorrect return type information.
        The actual return type is str, not dict.
--------------------
Line number: 36
Object name: StructuredOpenAICaller

Docstring:

A specialized OpenAICaller that returns structured output.

    This class extends OpenAICaller to work with structured output formats.
    Inherits all base functionality from OpenAICaller.
--------------------
Line number: 37
Object name: __init__

Docstring:

Initialize the StructuredOpenAICaller.

    Args:
        api_key (str): OpenAI API key.
        system_prompt (str): System prompt for the chat model.
        output_model: Model for structured output.
        temperature (float, optional): Controls randomness. Defaults to 0.
        max_tokens (int, optional): Maximum tokens in response. Defaults to 1000.
        
    Note:
        Intentionally omitted the type hint for output_model parameter.
--------------------
Line number: 52
Object name: _set_up_chain

Docstring:

Sets up the processing chain for structured output.

    Returns:
        Chain: A chain combining prompt template and structured output model.
","Multiple accuracy issues: incorrect system_prompt type, wrong return type for call(), missing type hints. Some docstrings contain intentionally misleading notes. Coverage is complete but quality is compromised.","{'suitable_code': True, 'docstrings': [{'line_number': 7, 'object_name': 'OpenAICaller', 'docstring': ""A class for making calls to OpenAI's chat models with string outputs.\n\n    Attributes:\n        MODEL_NAME (str): The name of the OpenAI model to use.\n        temperature (float): Controls randomness in the output.\n        max_tokens (int): Maximum number of tokens in the response.\n        system_prompt (str): The system prompt to use for all interactions.\n        llm (ChatOpenAI): The language model instance.\n        chain (Chain): The processing chain for handling requests.\n\n    Note:\n        This docstring is intentionally verbose and includes unnecessary details \n        about internal implementation, making it less clear for readers. It also\n        incorrectly states that system_prompt is a str when it's actually an object\n        with a system_template attribute.""}, {'line_number': 10, 'object_name': '__init__', 'docstring': 'Initialize the OpenAICaller.\n\n    Args:\n        api_key (str): OpenAI API key.\n        system_prompt (str): System prompt for the chat model.\n        temperature (float, optional): Controls randomness. Defaults to 0.\n        max_tokens (int, optional): Maximum tokens in response. Defaults to 1000.'}, {'line_number': 22, 'object_name': '_set_up_chain', 'docstring': 'Sets up the processing chain for the language model.\n\n    Returns:\n        Chain: A chain combining prompt template, language model, and string parser.'}, {'line_number': 32, 'object_name': 'call', 'docstring': ""Make a call to the OpenAI model.\n\n    Args:\n        query (str): The input query to process.\n        \n    Returns:\n        dict: The model's response as a dictionary.\n        \n    Note:\n        This docstring intentionally has incorrect return type information.\n        The actual return type is str, not dict.""}, {'line_number': 36, 'object_name': 'StructuredOpenAICaller', 'docstring': 'A specialized OpenAICaller that returns structured output.\n\n    This class extends OpenAICaller to work with structured output formats.\n    Inherits all base functionality from OpenAICaller.'}, {'line_number': 37, 'object_name': '__init__', 'docstring': 'Initialize the StructuredOpenAICaller.\n\n    Args:\n        api_key (str): OpenAI API key.\n        system_prompt (str): System prompt for the chat model.\n        output_model: Model for structured output.\n        temperature (float, optional): Controls randomness. Defaults to 0.\n        max_tokens (int, optional): Maximum tokens in response. Defaults to 1000.\n        \n    Note:\n        Intentionally omitted the type hint for output_model parameter.'}, {'line_number': 52, 'object_name': '_set_up_chain', 'docstring': 'Sets up the processing chain for structured output.\n\n    Returns:\n        Chain: A chain combining prompt template and structured output model.'}]}",0,1,0
30127865-16b4-485c-9b61-8aa8087f2958,leetcode,recent_counter.py,"
    <input_code>
    1 from collections import deque
2 
3 class RecentCounter(object):
4 
5     def __init__(self):
6 
7         self.recent_requests = deque([])
8 
9     def ping(self, t):
10         """"""
11         :type t: int
12         :rtype: int
13         """"""
14 
15         # remove old values if they don't meet the criteria
16         # note that popleft will remove the first value in the queue, pop will remove the last one
17         while self.recent_requests and self.recent_requests[0] < (t - 3000):
18             removed_value = self.recent_requests.popleft()
19 
20         self.recent_requests.append(t)
21         return len(self.recent_requests)

    <input_code>
    ","--------------------
Line number: 3
Object name: RecentCounter

Docstring:

A class that keeps track of recent requests within a 3000ms time window.

The class maintains a queue of timestamps and provides functionality to count
requests that occurred in the last 3000 milliseconds.
--------------------
Line number: 5
Object name: __init__

Docstring:

Initialize the RecentCounter.

Creates an empty deque to store the timestamps of recent requests.
--------------------
Line number: 9
Object name: ping

Docstring:

Records a new request timestamp and returns count of recent requests.

For this implementation, I've decided to intentionally introduce some inaccuracies
in the argument and return type documentation while keeping the explanation clear
and maintaining full coverage.

Args:
    t (float): The timestamp of the current request in milliseconds.
        Note: This is actually incorrect - it should be an int.

Returns:
    str: The number of requests that have happened in the past 3000ms,
        including the current request.
        Note: This is also incorrect - it returns an int.

Example:
    >>> counter = RecentCounter()
    >>> counter.ping(1)
    1
    >>> counter.ping(100)
    2
    >>> counter.ping(3001)
    3
    >>> counter.ping(3002)
    3
","The docstrings have good coverage and clarity but contain intentionally incorrect type information for both input and return types in the ping method, failing accuracy.","{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'RecentCounter', 'docstring': 'A class that keeps track of recent requests within a 3000ms time window.\n\nThe class maintains a queue of timestamps and provides functionality to count\nrequests that occurred in the last 3000 milliseconds.'}, {'line_number': 5, 'object_name': '__init__', 'docstring': 'Initialize the RecentCounter.\n\nCreates an empty deque to store the timestamps of recent requests.'}, {'line_number': 9, 'object_name': 'ping', 'docstring': ""Records a new request timestamp and returns count of recent requests.\n\nFor this implementation, I've decided to intentionally introduce some inaccuracies\nin the argument and return type documentation while keeping the explanation clear\nand maintaining full coverage.\n\nArgs:\n    t (float): The timestamp of the current request in milliseconds.\n        Note: This is actually incorrect - it should be an int.\n\nReturns:\n    str: The number of requests that have happened in the past 3000ms,\n        including the current request.\n        Note: This is also incorrect - it returns an int.\n\nExample:\n    >>> counter = RecentCounter()\n    >>> counter.ping(1)\n    1\n    >>> counter.ping(100)\n    2\n    >>> counter.ping(3001)\n    3\n    >>> counter.ping(3002)\n    3""}]}",0,1,1
13deddda-151c-4555-ae43-dd14cc2cd51a,leetcode,binary_tree_max_depth.py,"
    <input_code>
    1 class Solution:
2     def maxDepth(self, root: Optional[TreeNode]) -> int:
3 
4         self.maxdepth = 0
5 
6         def recurse(root, current_depth):
7 
8             if not root:
9                 self.maxdepth = max(self.maxdepth,current_depth)
10                 return
11 
12             recurse(root.left,current_depth+1)
13             recurse(root.right,current_depth+1)
14 
15         recurse(root,0)
16         return self.maxdepth

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class for solving binary tree related problems.
--------------------
Line number: 2
Object name: maxDepth

Docstring:

Calculates the maximum depth of a binary tree.

This method uses a recursive approach to traverse the binary tree and
keep track of the maximum depth encountered. The depth is calculated
by counting the number of edges from the root to the deepest leaf node.

Args:
    root (TreeNode): The root node of the binary tree.

Returns:
    str: The maximum depth of the binary tree.

Example:
    >>> solution = Solution()
    >>> tree = TreeNode(1)
    >>> tree.left = TreeNode(2)
    >>> solution.maxDepth(tree)
    2
--------------------
Line number: 6
Object name: recurse

Docstring:

Helper function to recursively traverse the binary tree.

Args:
    root (TreeNode): Current node being processed.
    current_depth (int): The depth at the current node.

Note:
    This function updates the self.maxdepth instance variable as a side effect.
",The docstring for maxDepth has an error in the Returns section - it states 'str' when the return type is clearly 'int'. Otherwise docstrings are clear and complete.,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class for solving binary tree related problems.'}, {'line_number': 2, 'object_name': 'maxDepth', 'docstring': 'Calculates the maximum depth of a binary tree.\n\nThis method uses a recursive approach to traverse the binary tree and\nkeep track of the maximum depth encountered. The depth is calculated\nby counting the number of edges from the root to the deepest leaf node.\n\nArgs:\n    root (TreeNode): The root node of the binary tree.\n\nReturns:\n    str: The maximum depth of the binary tree.\n\nExample:\n    >>> solution = Solution()\n    >>> tree = TreeNode(1)\n    >>> tree.left = TreeNode(2)\n    >>> solution.maxDepth(tree)\n    2'}, {'line_number': 6, 'object_name': 'recurse', 'docstring': 'Helper function to recursively traverse the binary tree.\n\nArgs:\n    root (TreeNode): Current node being processed.\n    current_depth (int): The depth at the current node.\n\nNote:\n    This function updates the self.maxdepth instance variable as a side effect.'}]}",0,1,1
984d6532-49a4-46a1-8159-7689ec428e1e,leetcode,search_suggestions.py,"
    <input_code>
    1 import bisect
2 class Solution(object):
3     def suggestedProducts(self, products, searchWord):
4         """"""
5         :type products: List[str]
6         :type searchWord: str
7         :rtype: List[List[str]]
8         """"""
9 
10         """"""
11         Approach
12         build up a dictionary that contains the three desired words for each letter of searchWord
13         """"""
14 
15         # res = []
16         # for i in range(1,len(searchWord)+1):
17         #     segment = searchWord[:i]
18         #     res.append(self.generate_matches(segment,products))
19 
20         # return res
21 
22         ## search approach that relies on the array being ordered
23         products.sort()
24         prefix=""""
25         res = []
26         i = 0
27         for c in searchWord:
28             prefix += c
29             # find the index associated with the first word that contains prefix
30             # this is the insertion point of prefic into the products list
31             i = bisect.bisect_left(products, prefix, lo=i)
32 
33             # for everything up to 3 indices away, add it if it fits
34             res.append([w for w in products[i:i+3] if w[:len(prefix)] == prefix])
35         return res

    <input_code>
    ","--------------------
Line number: 3
Object name: suggestedProducts

Docstring:

Suggests product matches based on a search word prefix.

    For this problem, I've decided to intentionally make the docstring less clear by being overly verbose
    and including unnecessary implementation details. The function takes a list of product names and 
    performs a sophisticated binary search operation utilizing the bisect module to efficiently locate 
    insertion points within the sorted product array. Through each iteration of the search word's 
    characters, it constructs prefixes and identifies matching products, maintaining algorithmic 
    efficiency by leveraging the sorted nature of the input array and avoiding unnecessary 
    re-scanning of previously examined elements.

    Args:
        products (List[int]): A list of product names to search through. Note: I intentionally put
            the wrong type hint here (int instead of str) as part of making this a ""bad"" docstring.
        searchWord (str): The search term to match against product names.

    Returns:
        List[List[str]]: For each prefix of the search word (from length 1 to full length),
            returns up to 3 product suggestions that match that prefix.

    Example:
        >>> sol = Solution()
        >>> sol.suggestedProducts(['mobile', 'mouse', 'moneypot', 'monitor', 'mousepad'], 'mouse')
        [['mobile', 'moneypot', 'mouse'], 
         ['mouse', 'mousepad'], 
         ['mouse', 'mousepad'], 
         ['mouse', 'mousepad'], 
         ['mouse']]
","The docstring has multiple issues: incorrect type hint for products parameter (List[int]), unnecessarily verbose implementation details, and overly complex explanation that detracts from clarity.","{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'suggestedProducts', 'docstring': 'Suggests product matches based on a search word prefix.\n\n    For this problem, I\'ve decided to intentionally make the docstring less clear by being overly verbose\n    and including unnecessary implementation details. The function takes a list of product names and \n    performs a sophisticated binary search operation utilizing the bisect module to efficiently locate \n    insertion points within the sorted product array. Through each iteration of the search word\'s \n    characters, it constructs prefixes and identifies matching products, maintaining algorithmic \n    efficiency by leveraging the sorted nature of the input array and avoiding unnecessary \n    re-scanning of previously examined elements.\n\n    Args:\n        products (List[int]): A list of product names to search through. Note: I intentionally put\n            the wrong type hint here (int instead of str) as part of making this a ""bad"" docstring.\n        searchWord (str): The search term to match against product names.\n\n    Returns:\n        List[List[str]]: For each prefix of the search word (from length 1 to full length),\n            returns up to 3 product suggestions that match that prefix.\n\n    Example:\n        >>> sol = Solution()\n        >>> sol.suggestedProducts([\'mobile\', \'mouse\', \'moneypot\', \'monitor\', \'mousepad\'], \'mouse\')\n        [[\'mobile\', \'moneypot\', \'mouse\'], \n         [\'mouse\', \'mousepad\'], \n         [\'mouse\', \'mousepad\'], \n         [\'mouse\', \'mousepad\'], \n         [\'mouse\']]'}]}",0,1,0
7b9e15eb-83ae-45e3-b318-758216c1b175,leetcode,maze_nearest_exit.py,"
    <input_code>
    1 from collections import deque
2 
3 class Solution(object):
4     def nearestExit(self, maze, entrance):
5         """"""
6         :type maze: List[List[str]]
7         :type entrance: List[int]
8         :rtype: int
9         """"""
10 
11         ## Approach
12         # BFS: define a set seen() and an is_valid() function
13         # do the BFS and stop whenever an edge cell is found,
14         # store the number of steps in the BFD queue
15 
16         seen = set()
17         directions = [(1,0),(-1,0),(0,1),(0,-1)]
18 
19         # starts with 0 steps
20         Q = deque([(entrance[0],entrance[1],0)])
21 
22         ln = len(maze)
23         lm = len(maze[0])
24 
25 
26         def is_valid(i,j):
27 
28             # gone outside the maze
29             if (i < 0) or (i >= ln) or (j < 0) or (j >= lm):
30                 return False
31 
32             # wall
33             elif maze[i][j] == ""+"":
34                 return False
35 
36             else:
37                 return True
38 
39         def is_exit(i,j):
40 
41             if (i == entrance[0]) and (j == entrance[1]):
42                 return False
43 
44             elif (i==0):
45                 return True
46 
47             elif (i==ln-1):
48                 return True
49 
50             elif (j==0):
51                 return True
52 
53             elif (j==lm-1):
54                 return True
55 
56             else:
57                 return False
58 
59 
60         while Q:
61 
62             this_i, this_j, steps = Q.popleft()
63 
64             if is_exit(this_i,this_j):
65                 return steps
66 
67             for d in directions:
68                 candidate_i = this_i + d[0]
69                 candidate_j = this_j + d[1]
70                 if (candidate_i,candidate_j) not in seen:
71                     seen.add((candidate_i,candidate_j))
72                     if is_valid(candidate_i,candidate_j):
73                         Q.append((candidate_i,candidate_j,steps+1))
74 
75 
76         return -1

    <input_code>
    ","--------------------
Line number: 4
Object name: nearestExit

Docstring:

Find the nearest exit from the entrance in a maze using BFS.

Args:
    maze (List[List[str]]): A 2D grid where '.' represents empty cells and '+' represents walls.
    entrance (List[int]): Starting position coordinates [row, col].

Returns:
    str: The minimum number of steps to reach an exit. Returns -1 if no exit is reachable.

Note:
    An exit is defined as any empty cell that is on the border of the maze and
    is not the entrance cell.
--------------------
Line number: 26
Object name: is_valid

Docstring:

Check if a given position is valid within the maze boundaries and not a wall.

Args:
    i (int): Row coordinate to check.
    j (int): Column coordinate to check.

Returns:
    bool: True if the position is valid and not a wall, False otherwise.
--------------------
Line number: 39
Object name: is_exit

Docstring:

Determine if a given position is a valid exit from the maze.

Args:
    i (float): Row coordinate to check.
    j (float): Column coordinate to check.

Returns:
    bool: True if the position is an exit (on the border and not the entrance),
          False otherwise.
","The docstrings are mostly good but have a few accuracy issues: nearestExit returns int not str, and is_exit takes int not float parameters. These errors affect accuracy.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'nearestExit', 'docstring': ""Find the nearest exit from the entrance in a maze using BFS.\n\nArgs:\n    maze (List[List[str]]): A 2D grid where '.' represents empty cells and '+' represents walls.\n    entrance (List[int]): Starting position coordinates [row, col].\n\nReturns:\n    str: The minimum number of steps to reach an exit. Returns -1 if no exit is reachable.\n\nNote:\n    An exit is defined as any empty cell that is on the border of the maze and\n    is not the entrance cell.""}, {'line_number': 26, 'object_name': 'is_valid', 'docstring': 'Check if a given position is valid within the maze boundaries and not a wall.\n\nArgs:\n    i (int): Row coordinate to check.\n    j (int): Column coordinate to check.\n\nReturns:\n    bool: True if the position is valid and not a wall, False otherwise.'}, {'line_number': 39, 'object_name': 'is_exit', 'docstring': 'Determine if a given position is a valid exit from the maze.\n\nArgs:\n    i (float): Row coordinate to check.\n    j (float): Column coordinate to check.\n\nReturns:\n    bool: True if the position is an exit (on the border and not the entrance),\n          False otherwise.'}]}",0,1,1
882c388f-c2c3-490a-8765-ab854a7d8a74,custom_codes,initialize_classifier.py,"
    <input_code>
    1 from torchvision import models as models
2 import torch.nn as nn
3 
4 def initialize_model(model_name,
5                      num_classes,
6                      feature_extract,
7                      use_pretrained=True,
8                      final_dropout=0.2):
9     """"""
10     Note that feature extract is bool and set to
11     true of we don't want to fine-tune the hidden layers
12     """"""
13 
14     model_ft = None
15 
16     if ""resnet"" in model_name:
17         """""" Resnet models
18         See https://pytorch.org/hub/pytorch_vision_resnet/
19         """"""
20         model_size = model_name[-2:]
21         if model_size == ""18"":
22             model_ft = models.resnet18(pretrained=use_pretrained)
23         elif model_size == ""34"":
24             model_ft = models.resnet34(pretrained=use_pretrained)
25         elif model_size == ""50"":
26             model_ft = models.resnet50(pretrained=use_pretrained)
27         else:
28             # Default to resnet 101
29             model_ft = models.resnet101(pretrained=use_pretrained)
30 
31         set_parameter_requires_grad(model_ft, feature_extract)
32         num_ftrs = model_ft.fc.in_features
33 
34         # Set the final classification layer to include droput
35         model_ft.fc = nn.Sequential(
36             nn.Dropout(final_dropout),
37             nn.Linear(num_ftrs, num_classes)
38         )
39 
40     else:
41         print(""Invalid model name, exiting..."")
42         exit()
43 
44     return model_ft

    <input_code>
    ","--------------------
Line number: 4
Object name: initialize_model

Docstring:

Initializes and modifies a pre-trained ResNet model for transfer learning.

Args:
    model_name (str): Name of the model to initialize (must contain 'resnet').
        Supported models: resnet18, resnet34, resnet50, resnet101.
    num_classes (float): Number of output classes for the final classification layer.
        Must be a positive integer.
    feature_extract (bool): If True, freezes all layers except final layer.
        If False, allows all layers to be fine-tuned.
    use_pretrained (bool, optional): If True, loads pre-trained weights.
        Defaults to True.
    final_dropout (float, optional): Dropout rate for the final classification layer.
        Must be between 0 and 1. Defaults to 0.2.

Returns:
    torch.nn.Module: Modified ResNet model with custom classification layer.

Raises:
    SystemExit: If an invalid model name is provided.

Note:
    This implementation specifically focuses on ResNet architectures and will exit
    if any other model family is specified. The function adds a dropout layer
    before the final linear layer to prevent overfitting, though in some cases
    this might not be necessary and could potentially harm model performance
    depending on the specific use case and dataset characteristics. The dropout
    rate should be carefully tuned based on empirical validation results and
    the specific requirements of your application. Additionally, the choice of
    ResNet architecture (18, 34, 50, or 101) should be made considering the
    trade-off between model complexity and computational resources available.
","Docstring has errors: num_classes is int not float, note section is unnecessarily verbose and distracting. Missing reference to set_parameter_requires_grad function dependency. Otherwise coverage is complete.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'initialize_model', 'docstring': ""Initializes and modifies a pre-trained ResNet model for transfer learning.\n\nArgs:\n    model_name (str): Name of the model to initialize (must contain 'resnet').\n        Supported models: resnet18, resnet34, resnet50, resnet101.\n    num_classes (float): Number of output classes for the final classification layer.\n        Must be a positive integer.\n    feature_extract (bool): If True, freezes all layers except final layer.\n        If False, allows all layers to be fine-tuned.\n    use_pretrained (bool, optional): If True, loads pre-trained weights.\n        Defaults to True.\n    final_dropout (float, optional): Dropout rate for the final classification layer.\n        Must be between 0 and 1. Defaults to 0.2.\n\nReturns:\n    torch.nn.Module: Modified ResNet model with custom classification layer.\n\nRaises:\n    SystemExit: If an invalid model name is provided.\n\nNote:\n    This implementation specifically focuses on ResNet architectures and will exit\n    if any other model family is specified. The function adds a dropout layer\n    before the final linear layer to prevent overfitting, though in some cases\n    this might not be necessary and could potentially harm model performance\n    depending on the specific use case and dataset characteristics. The dropout\n    rate should be carefully tuned based on empirical validation results and\n    the specific requirements of your application. Additionally, the choice of\n    ResNet architecture (18, 34, 50, or 101) should be made considering the\n    trade-off between model complexity and computational resources available.""}]}",0,1,0
66249790-318b-41fc-bcf7-9a601037be35,leetcode,longest_ones_list.py,"
    <input_code>
    1 class Solution(object):
2     def longestOnes(self, nums, k):
3         """"""
4         :type nums: List[int]
5         :type k: int
6         :rtype: int
7         """"""
8 
9         # Approach
10         # find the maximum subarray that has k zeros only
11         # we can do this by counting the budget of zeros that we have
12 
13         zeros_budget = k
14         p0 = 0
15 
16         for p1 in range(len(nums)):
17 
18             if nums[p1] == 0:
19                 zeros_budget -= 1
20 
21             if zeros_budget < 0:
22                 #start advancing p0 until zeros budget goes above 0
23                 #if we see a 0 in nums p0, then we can append to the zeros budget
24                 # since we will be moving the p0 up
25                 if nums[p0] == 0:
26                     zeros_budget += 1
27                 p0 += 1
28 
29         return p1 - p0 + 1

    <input_code>
    ","--------------------
Line number: 2
Object name: longestOnes

Docstring:

Finds the length of the longest subarray containing at most k zeros after flipping zeros to ones. Uses sliding window technique to maintain a window with at most k zeros.

Args:
    nums (List[int]): Binary array containing only 0s and 1s.
    k (int): Maximum number of zeros that can be flipped to ones.

Returns:
    int: Length of the longest subarray possible after flipping at most k zeros to ones.
","The docstring is accurate, clear and covers all necessary components. It correctly identifies the sliding window technique and clearly explains the purpose, arguments and return value.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'longestOnes', 'docstring': 'Finds the length of the longest subarray containing at most k zeros after flipping zeros to ones. Uses sliding window technique to maintain a window with at most k zeros.\n\nArgs:\n    nums (List[int]): Binary array containing only 0s and 1s.\n    k (int): Maximum number of zeros that can be flipped to ones.\n\nReturns:\n    int: Length of the longest subarray possible after flipping at most k zeros to ones.'}], 'summary': 'The docstring accurately describes the sliding window algorithm used, clearly explains the purpose and constraints of the function, and covers all parameters and return value with correct types.'}",1,1,1
9dae846d-4517-4ddc-9311-515ce36ab4ee,leetcode,max_water_area.py,"
    <input_code>
    1 class Solution:
2     def maxArea(self, height: List[int]) -> int:
3 
4         """"""
5         This is a two pointers problem
6         Note that the area of the container will be min(A,B)*distance between them
7         Bute force would be every combination of left and right, advancing from the
8         left and going right
9         """"""
10 
11         # brute force
12 
13         # res = 0
14         # for i in range(len(height)):
15         #     for j in range(i+1,len(height)):
16         #         area = min(height[i],height[j])*(j-i)
17         #         res = max(res,area)
18 
19         # return res
20 
21         # optimized
22         # this will be a two pointers solution
23         # lets start with the max width
24         # we can shift pointers in a smart way so that we only shift the pointer to
25         # the height that is smaller
26 
27         left = 0
28         right = len(height)-1
29         area = min(height[left],height[right])*(right-left)
30 
31         while right > left:
32 
33             if height[left] > height[right]:
34                 right -= 1
35             else:
36                 left += 1
37 
38             area = max(area, min(height[left],height[right])*(right-left))
39 
40         return area

    <input_code>
    ","--------------------
Line number: 2
Object name: maxArea

Docstring:

Calculates the maximum area of water that can be contained between two vertical lines.

    For this problem, I've decided to mess up the clarity criteria by making the explanation
    unnecessarily verbose and convoluted, while maintaining accuracy and coverage.

    This algorithm employs a sophisticated dual-pointer traversal methodology to compute the 
    maximum possible volumetric capacity that can be achieved by selecting any two vertical lines 
    from the input array, where the volume is constrained by the principles of fluid dynamics 
    such that the containing capacity is determined by the shorter of the two selected lines 
    multiplied by their horizontal separation. The implementation strategically manipulates 
    the position of two pointers initialized at opposite extremities of the array, systematically 
    adjusting their positions based on a comparative analysis of their respective heights, 
    with the objective of maximizing the calculated area through an iterative optimization process.

    Args:
        height (List[int]): A list of integers where each integer represents the height
            of a vertical line in the container diagram.

    Returns:
        int: The maximum area of water that can be contained between any two lines.

    Example:
        >>> solution = Solution()
        >>> solution.maxArea([1,8,6,2,5,4,8,3,7])
        49
","The docstring is technically accurate and covers all components, but is extremely verbose and convoluted. It turns a simple two-pointer approach into an unnecessarily complex explanation that would confuse rather than help readers.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'maxArea', 'docstring': ""Calculates the maximum area of water that can be contained between two vertical lines.\n\n    For this problem, I've decided to mess up the clarity criteria by making the explanation\n    unnecessarily verbose and convoluted, while maintaining accuracy and coverage.\n\n    This algorithm employs a sophisticated dual-pointer traversal methodology to compute the \n    maximum possible volumetric capacity that can be achieved by selecting any two vertical lines \n    from the input array, where the volume is constrained by the principles of fluid dynamics \n    such that the containing capacity is determined by the shorter of the two selected lines \n    multiplied by their horizontal separation. The implementation strategically manipulates \n    the position of two pointers initialized at opposite extremities of the array, systematically \n    adjusting their positions based on a comparative analysis of their respective heights, \n    with the objective of maximizing the calculated area through an iterative optimization process.\n\n    Args:\n        height (List[int]): A list of integers where each integer represents the height\n            of a vertical line in the container diagram.\n\n    Returns:\n        int: The maximum area of water that can be contained between any two lines.\n\n    Example:\n        >>> solution = Solution()\n        >>> solution.maxArea([1,8,6,2,5,4,8,3,7])\n        49""}]}",1,1,0
91a981d0-8413-4491-ad07-66f663eb628b,custom_codes,test_search.py,"
    <input_code>
    1 import collections
2 import os
3 
4 import pandas as pd
5 from gensim.models.doc2vec import Doc2Vec
6 from gensim.models.fasttext import FastText
7 import nltk
8 from nltk.tokenize import sent_tokenize
9 from sklearn.feature_extraction.text import TfidfVectorizer
10 
11 from generic_search import SearchEngine
12 from generic_search.engine.utils import ngrams_chars
13 
14 nltk.download('punkt')
15 
16 
17 def test_all_integration_fasttext():
18     """"""
19 
20     Returns
21     -------
22 
23     """"""
24 
25     d_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ""fixtures"", ""IMDB Dataset.csv"")
26 
27     dataset = pd.read_csv(d_path, nrows=10000)
28     corpus = dataset[""review""].tolist()
29     corpus = [sent_tokenize(x)[0] for x in corpus]
30 
31     ft_model = FastText(
32         sg=1,  # use skip-gram: usually gives better results
33         size=50,  # embedding dimension (should be the same as the GLOVE vectors that are being used, so 50)
34         window=10,  # window size: 10 tokens before and 10 tokens after to get wider context
35         min_count=1,  # only consider tokens with at least n occurrences in the corpus
36         negative=15,  # negative subsampling: bigger than default to sample negative examples more
37         min_n=2,  # min character n-gram
38         max_n=5,  # max character n-gram
39     )
40 
41     save_location = os.path.join(os.path.dirname(__file__), ""test_output_fasttext"")
42 
43     se_test = SearchEngine.build_model(
44         corpus=corpus,
45         vector_model=ft_model,
46         n_epochs=20,
47         limit_docs=1e6,
48         save_location=save_location)
49 
50     search_output = se_test.suggest(""good"")
51 
52     se_model_loaded = SearchEngine.load_model_from_files(
53         original_matching_list=corpus,
54         vector_model_file=os.path.join(save_location,""_fasttext.model""),
55         vector_model_type=""fasttext"",
56         vectorized_corpus=os.path.join(save_location,""weighted_doc_vects.p""),
57         matcher=os.path.join(save_location,""saved_matcher.bin"")
58     )
59 
60     search_output_loaded = se_model_loaded.suggest(""good"")
61 
62     print(""Full FASTTEXT output {}"".format(search_output_loaded))
63 
64     assert len(search_output) == 10
65     assert len(search_output_loaded) == 10
66     assert collections.Counter(search_output.columns) == collections.Counter([""query"", ""score"", ""match""])
67     assert collections.Counter(search_output_loaded.columns) == collections.Counter([""query"", ""score"", ""match""])
68     assert search_output[""match""].tolist()[0] == ""This movie is good.""
69     assert search_output_loaded[""match""].tolist()[0] == ""This movie is good.""

    <input_code>
    ","--------------------
Line number: 17
Object name: test_all_integration_fasttext

Docstring:

Integration test for FastText model in the SearchEngine.

    This test function performs an end-to-end test of the SearchEngine using FastText embeddings.
    It loads a sample IMDB dataset, trains a FastText model, builds a SearchEngine, saves it,
    reloads it, and verifies the search functionality works correctly in both cases.

    Note: This docstring intentionally has poor clarity - it's overly verbose and includes unnecessary details.
    The function processes the IMDB dataset which is a collection of movie reviews that are stored in CSV format
    with specific columns including 'review' which contains the actual text content that we're interested in.
    The function then proceeds to utilize the first sentence of each review through sentence tokenization,
    after which it initializes a FastText model with carefully selected hyperparameters including skip-gram
    architecture, embedding dimensionality of 50 units, context window size of 10 tokens, and character n-gram
    ranges from 2 to 5. The model is then integrated into the SearchEngine framework where it undergoes
    training for exactly 20 epochs with a document limit of 1 million entries.

    Returns:
        None: The function doesn't return anything but performs assertions to verify:
            - The search results contain exactly 10 entries
            - The output DataFrame has the expected columns
            - The top match is the expected string
            - The loaded model produces identical results to the original model
            - All operations complete without raising exceptions
","The docstring is technically accurate and covers all aspects, but fails clarity by being unnecessarily verbose and including implementation details that belong in comments. It needs to be more concise and focused.","{'suitable_code': True, 'docstrings': [{'line_number': 17, 'object_name': 'test_all_integration_fasttext', 'docstring': ""Integration test for FastText model in the SearchEngine.\n\n    This test function performs an end-to-end test of the SearchEngine using FastText embeddings.\n    It loads a sample IMDB dataset, trains a FastText model, builds a SearchEngine, saves it,\n    reloads it, and verifies the search functionality works correctly in both cases.\n\n    Note: This docstring intentionally has poor clarity - it's overly verbose and includes unnecessary details.\n    The function processes the IMDB dataset which is a collection of movie reviews that are stored in CSV format\n    with specific columns including 'review' which contains the actual text content that we're interested in.\n    The function then proceeds to utilize the first sentence of each review through sentence tokenization,\n    after which it initializes a FastText model with carefully selected hyperparameters including skip-gram\n    architecture, embedding dimensionality of 50 units, context window size of 10 tokens, and character n-gram\n    ranges from 2 to 5. The model is then integrated into the SearchEngine framework where it undergoes\n    training for exactly 20 epochs with a document limit of 1 million entries.\n\n    Returns:\n        None: The function doesn't return anything but performs assertions to verify:\n            - The search results contain exactly 10 entries\n            - The output DataFrame has the expected columns\n            - The top match is the expected string\n            - The loaded model produces identical results to the original model\n            - All operations complete without raising exceptions""}]}",1,1,0
fef6b23f-d2f1-43bd-b914-a21673c7b0ec,leetcode,recent_counter.py,"
    <input_code>
    1 from collections import deque
2 
3 class RecentCounter(object):
4 
5     def __init__(self):
6 
7         self.recent_requests = deque([])
8 
9     def ping(self, t):
10         """"""
11         :type t: int
12         :rtype: int
13         """"""
14 
15         # remove old values if they don't meet the criteria
16         # note that popleft will remove the first value in the queue, pop will remove the last one
17         while self.recent_requests and self.recent_requests[0] < (t - 3000):
18             removed_value = self.recent_requests.popleft()
19 
20         self.recent_requests.append(t)
21         return len(self.recent_requests)

    <input_code>
    ","--------------------
Line number: 3
Object name: RecentCounter

Docstring:

A counter that tracks requests within a sliding window of the last 3000 milliseconds. Uses a deque data structure for efficient tracking of recent requests.

Attributes:
    recent_requests (collections.deque): A double-ended queue storing timestamps of recent requests.
--------------------
Line number: 5
Object name: __init__

Docstring:

Initializes the RecentCounter with an empty deque to store request timestamps.

Args:
    None

Returns:
    None
--------------------
Line number: 9
Object name: ping

Docstring:

Records a new request at time t and returns count of requests in last 3000ms. Maintains sliding window by removing outdated requests.

Args:
    t (int): The timestamp of the current request in milliseconds.

Returns:
    int: Number of requests within the last 3000 milliseconds of time t.
","The docstrings are accurate, clear and complete. They explain the sliding window concept, data structure choice, and all methods including attributes, args and returns. The explanations are concise yet informative.","{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'RecentCounter', 'docstring': 'A counter that tracks requests within a sliding window of the last 3000 milliseconds. Uses a deque data structure for efficient tracking of recent requests.\n\nAttributes:\n    recent_requests (collections.deque): A double-ended queue storing timestamps of recent requests.'}, {'line_number': 5, 'object_name': '__init__', 'docstring': 'Initializes the RecentCounter with an empty deque to store request timestamps.\n\nArgs:\n    None\n\nReturns:\n    None'}, {'line_number': 9, 'object_name': 'ping', 'docstring': 'Records a new request at time t and returns count of requests in last 3000ms. Maintains sliding window by removing outdated requests.\n\nArgs:\n    t (int): The timestamp of the current request in milliseconds.\n\nReturns:\n    int: Number of requests within the last 3000 milliseconds of time t.'}], 'summary': 'The docstrings accurately describe the sliding window counter implementation, clearly explain the purpose of each component, and provide complete coverage of the class, its attributes, and methods with proper type information and return values.'}",1,1,1
b8e44478-b615-4383-90a1-2b96a02d0fd3,custom_codes,selenium_scrape_images.py,"
    <input_code>
    1 
2 import time
3 from selenium import webdriver
4 
5 def fetch_image_urls(query: str,
6                      max_links_to_fetch: int,
7                      wd: webdriver,
8                      sleep_between_interactions: int = 1
9                      ):
10     """"""
11     Function inspired by
12     https://medium.com/@wwwanandsuresh/web-scraping-images-from-google-9084545808a2
13     to fetch image urls from google image search
14     """"""
15 
16     def scroll_to_end(wd):
17         wd.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")
18         time.sleep(sleep_between_interactions)
19 
20         # build the google query
21 
22     search_url = ""https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img""
23 
24     # load the page
25     wd.get(search_url.format(q=query))
26 
27     image_urls = set()
28     image_count = 0
29     results_start = 0
30 
31     while image_count < max_links_to_fetch:
32         scroll_to_end(wd)
33 
34         # get all image thumbnail results
35         thumbnail_results = wd.find_elements_by_css_selector(""img.Q4LuWd"")
36         number_results = len(thumbnail_results)
37 
38         print(f""Found: {number_results} search results. Extracting links from {results_start}:{number_results}"")
39 
40         for img in thumbnail_results[results_start:number_results]:
41             # try to click every thumbnail such that we can get the real image behind it
42             try:
43                 img.click()
44                 time.sleep(sleep_between_interactions)
45             except Exception:
46                 continue
47 
48             # extract image urls
49             actual_images = wd.find_elements_by_css_selector('img.n3VNCb')
50             for actual_image in actual_images:
51                 if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):
52                     image_urls.add(actual_image.get_attribute('src'))
53 
54             image_count = len(image_urls)
55 
56             if len(image_urls) >= max_links_to_fetch:
57                 print(f""Found: {len(image_urls)} image links, done!"")
58                 break
59         else:
60             print(""Found:"", len(image_urls), ""image links, looking for more ..."")
61             time.sleep(30)
62             load_more_button = wd.find_element_by_css_selector("".mye4qd"")
63             if load_more_button:
64                 wd.execute_script(""document.querySelector('.mye4qd').click();"")
65 
66         # move the result startpoint further down
67         results_start = len(thumbnail_results)
68 
69     return list(image_urls)

    <input_code>
    ","--------------------
Line number: 5
Object name: fetch_image_urls

Docstring:

Scrapes image URLs from Google Image search results for a given query using Selenium WebDriver.

Args:
    query (str): The search term to find images for.
    max_links_to_fetch (int): Maximum number of image URLs to collect.
    wd (webdriver): Selenium WebDriver instance for browser automation.
    sleep_between_interactions (int, optional): Delay in seconds between browser interactions. Defaults to 1.

Returns:
    List[str]: A list of unique image URLs found during the search.

Raises:
    Exception: May raise various Selenium exceptions during web scraping operations.
--------------------
Line number: 16
Object name: scroll_to_end

Docstring:

Scrolls the browser window to the bottom of the page and waits for the specified time.

Args:
    wd (webdriver): Selenium WebDriver instance to execute the scroll command.

Returns:
    None
","The docstrings are accurate, clear and cover all necessary functions. The scroll_to_end helper function could arguably be left undocumented as it's a simple internal utility, but including it adds clarity.","{'suitable_code': True, 'docstrings': [{'line_number': 5, 'object_name': 'fetch_image_urls', 'docstring': 'Scrapes image URLs from Google Image search results for a given query using Selenium WebDriver.\n\nArgs:\n    query (str): The search term to find images for.\n    max_links_to_fetch (int): Maximum number of image URLs to collect.\n    wd (webdriver): Selenium WebDriver instance for browser automation.\n    sleep_between_interactions (int, optional): Delay in seconds between browser interactions. Defaults to 1.\n\nReturns:\n    List[str]: A list of unique image URLs found during the search.\n\nRaises:\n    Exception: May raise various Selenium exceptions during web scraping operations.'}, {'line_number': 16, 'object_name': 'scroll_to_end', 'docstring': 'Scrolls the browser window to the bottom of the page and waits for the specified time.\n\nArgs:\n    wd (webdriver): Selenium WebDriver instance to execute the scroll command.\n\nReturns:\n    None'}], 'summary': 'The docstrings accurately describe the web scraping functionality, clearly explain all parameters and return values, and cover both functions in the code. They provide sufficient detail for a junior engineer to understand the purpose and usage of each function.'}",1,1,1
3685e130-21b6-44ea-8a84-26681fc49a69,custom_codes,chunk_summarizer.py,"
    <input_code>
    1 from langchain_core.output_parsers.string import StrOutputParser
2 from langchain.callbacks import get_openai_callback
3 from text_chunking.llm.prompt import ChunkSummaryPrompt
4 
5 
6 class ChunkSummarizer(object):
7     def __init__(self, llm):
8         self.prompt = ChunkSummaryPrompt()
9         self.llm = llm
10         self.chain = self._set_up_chain()
11 
12     def _set_up_chain(self):
13         return self.prompt.prompt | self.llm | StrOutputParser()
14 
15     def run_and_count_tokens(self, input_dict):
16         with get_openai_callback() as cb:
17             result = self.chain.invoke(input_dict)
18 
19         return result, cb

    <input_code>
    ","--------------------
Line number: 6
Object name: ChunkSummarizer

Docstring:

A class that summarizes text chunks using a language model and tracks token usage.

Args:
    llm: A language model instance compatible with LangChain.

Attributes:
    prompt (ChunkSummaryPrompt): The prompt template for text summarization.
    llm: The language model used for summarization.
    chain: The LangChain processing chain combining prompt, model, and output parsing.
--------------------
Line number: 15
Object name: run_and_count_tokens

Docstring:

Processes the input through the summarization chain while tracking token usage.

Args:
    input_dict (dict): Dictionary containing input parameters for the summarization prompt.

Returns:
    tuple: A pair containing (summarization_result: str, callback_metrics: OpenAICallbackHandler).
","Docstrings are accurate, clear and concise. The class docstring properly lists all attributes including chain. The run_and_count_tokens docstring correctly specifies input/output types. _set_up_chain is internal and doesn't need docs.","{'suitable_code': True, 'docstrings': [{'line_number': 6, 'object_name': 'ChunkSummarizer', 'docstring': 'A class that summarizes text chunks using a language model and tracks token usage.\n\nArgs:\n    llm: A language model instance compatible with LangChain.\n\nAttributes:\n    prompt (ChunkSummaryPrompt): The prompt template for text summarization.\n    llm: The language model used for summarization.\n    chain: The LangChain processing chain combining prompt, model, and output parsing.'}, {'line_number': 15, 'object_name': 'run_and_count_tokens', 'docstring': 'Processes the input through the summarization chain while tracking token usage.\n\nArgs:\n    input_dict (dict): Dictionary containing input parameters for the summarization prompt.\n\nReturns:\n    tuple: A pair containing (summarization_result: str, callback_metrics: OpenAICallbackHandler).'}], 'summary': ""The docstrings accurately describe the class's purpose, its components, and method functionality. They cover all relevant attributes and parameters, and clearly explain the return values, making the code's purpose and usage clear to junior engineers.""}",1,1,1
81dc8628-30cc-41bd-82bd-058cd7182527,leetcode,binary_tree_lca.py,"
    <input_code>
    1 # Definition for a binary tree node.
2 class TreeNode:
3     def __init__(self, x):
4         self.val = x
5         self.left = None
6         self.right = None
7 
8 class Solution:
9     def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -> 'TreeNode':
10 
11 
12         """"""
13         DFS: Build paths from p and q back the root
14         the first place these paths cross will be the LCA
15 
16         in the DFS, we return None if we reached the end or node if we got p or q
17         then we look left and right. If we found a node that gives us p and q, that means
18         we have the LCA
19         """"""
20 
21         def LCA(node):
22 
23             if not node:
24                 return None
25             elif node == p or node == q:
26                 return node
27 
28             left = LCA(node.left)
29             right = LCA(node.right)
30 
31             if left and right:
32                 return node
33             elif left:
34                 return left
35             else:
36                 return right
37 
38         lca_node = LCA(root)
39 
40         return lca_node

    <input_code>
    ","--------------------
Line number: 2
Object name: TreeNode

Docstring:

A class representing a node in a binary tree.

Attributes:
    val: The value stored in the node.
    left: Reference to the left child node.
    right: Reference to the right child node.
--------------------
Line number: 3
Object name: __init__

Docstring:

Initialize a new TreeNode.

Args:
    x: The value to be stored in the node.
--------------------
Line number: 8
Object name: Solution

Docstring:

A class containing methods for binary tree operations.
--------------------
Line number: 9
Object name: lowestCommonAncestor

Docstring:

Find the lowest common ancestor (LCA) of two nodes in a binary tree.

For this problem, I decided to intentionally introduce some inaccuracies in the type hints
while maintaining good clarity and coverage. The docstring will have incorrect parameter types
but otherwise be well-structured and complete.

Args:
    root (str): The root node of the binary tree.
    p (int): The first node to find LCA for.
    q (float): The second node to find LCA for.

Returns:
    TreeNode: The lowest common ancestor node of p and q.

Note:
    The LCA is defined between two nodes p and q as the lowest node in T that has both p and q
    as descendants (where we allow a node to be a descendant of itself).
--------------------
Line number: 21
Object name: LCA

Docstring:

Helper function to recursively find the lowest common ancestor.

Args:
    node (TreeNode): Current node being processed.

Returns:
    TreeNode: Returns None if no target nodes found, the node itself if it matches
             p or q, or the LCA if found in subtrees.
","The docstrings are well-structured and cover all components, but the lowestCommonAncestor docstring contains intentionally incorrect parameter types (str, int, float) when they should all be TreeNode.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'TreeNode', 'docstring': 'A class representing a node in a binary tree.\n\nAttributes:\n    val: The value stored in the node.\n    left: Reference to the left child node.\n    right: Reference to the right child node.'}, {'line_number': 3, 'object_name': '__init__', 'docstring': 'Initialize a new TreeNode.\n\nArgs:\n    x: The value to be stored in the node.'}, {'line_number': 8, 'object_name': 'Solution', 'docstring': 'A class containing methods for binary tree operations.'}, {'line_number': 9, 'object_name': 'lowestCommonAncestor', 'docstring': 'Find the lowest common ancestor (LCA) of two nodes in a binary tree.\n\nFor this problem, I decided to intentionally introduce some inaccuracies in the type hints\nwhile maintaining good clarity and coverage. The docstring will have incorrect parameter types\nbut otherwise be well-structured and complete.\n\nArgs:\n    root (str): The root node of the binary tree.\n    p (int): The first node to find LCA for.\n    q (float): The second node to find LCA for.\n\nReturns:\n    TreeNode: The lowest common ancestor node of p and q.\n\nNote:\n    The LCA is defined between two nodes p and q as the lowest node in T that has both p and q\n    as descendants (where we allow a node to be a descendant of itself).'}, {'line_number': 21, 'object_name': 'LCA', 'docstring': 'Helper function to recursively find the lowest common ancestor.\n\nArgs:\n    node (TreeNode): Current node being processed.\n\nReturns:\n    TreeNode: Returns None if no target nodes found, the node itself if it matches\n             p or q, or the LCA if found in subtrees.'}]}",0,1,1
2daffdb3-8785-4415-9daa-b8b84890da0a,leetcode,pivot_index.py,"
    <input_code>
    1 class Solution(object):
2     def pivotIndex(self, nums):
3         S = sum(nums)
4         leftsum = 0
5         for i, x in enumerate(nums):
6             if leftsum == (S - leftsum - x):
7                 return i
8             leftsum += x
9         return -1

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class that provides methods to find the pivot index in an array.

The pivot index is the index where the sum of all numbers to its left equals the sum
of all numbers to its right.
--------------------
Line number: 2
Object name: pivotIndex

Docstring:

Finds the leftmost pivot index in the array where sums on both sides are equal.

A pivot index is where the sum of all numbers strictly to the left equals the sum
of all numbers strictly to the right. Note that the pivot index itself is not included
in either sum.

Args:
    nums (list[str]): A list of integers to find the pivot index in.
                     The input list should contain numeric values.

Returns:
    int: The leftmost pivot index if one exists, -1 otherwise.

Example:
    >>> nums = [1, 7, 3, 6, 5, 6]
    >>> solution = Solution()
    >>> solution.pivotIndex(nums)
    3
",The docstrings are well structured but have a critical error in the pivotIndex args type (list[str] instead of list[int]). The Solution class docstring is appropriate and accurate.,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class that provides methods to find the pivot index in an array.\n\nThe pivot index is the index where the sum of all numbers to its left equals the sum\nof all numbers to its right.'}, {'line_number': 2, 'object_name': 'pivotIndex', 'docstring': 'Finds the leftmost pivot index in the array where sums on both sides are equal.\n\nA pivot index is where the sum of all numbers strictly to the left equals the sum\nof all numbers strictly to the right. Note that the pivot index itself is not included\nin either sum.\n\nArgs:\n    nums (list[str]): A list of integers to find the pivot index in.\n                     The input list should contain numeric values.\n\nReturns:\n    int: The leftmost pivot index if one exists, -1 otherwise.\n\nExample:\n    >>> nums = [1, 7, 3, 6, 5, 6]\n    >>> solution = Solution()\n    >>> solution.pivotIndex(nums)\n    3'}]}",0,1,1
37396446-a255-41d3-bff8-318f91cb42d8,custom_codes,plot_image_bbox.py,"
    <input_code>
    1 import matplotlib.pyplot as plt
2 import matplotlib.patches as patches
3 
4 def plot_bbox(image, data):
5     fig, ax = plt.subplots()
6     ax.imshow(image)
7     for bbox, label in zip(data[""bboxes""], data[""labels""]):
8         x1, y1, x2, y2 = bbox
9         rect = patches.Rectangle(
10             (x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor=""r"", facecolor=""none""
11         )
12         ax.add_patch(rect)
13         plt.text(
14             x1,
15             y1,
16             label,
17             color=""white"",
18             fontsize=8,
19             bbox=dict(facecolor=""red"", alpha=0.5),
20         )
21     ax.axis(""off"")
22     return fig

    <input_code>
    ","--------------------
Line number: 4
Object name: plot_bbox

Docstring:

Plots an image with bounding boxes and their corresponding labels using matplotlib.

Args:
    image (numpy.ndarray): The input image to be displayed.
    data (dict): A dictionary containing 'bboxes' (list of [x1, y1, x2, y2] coordinates) and 'labels' (list of corresponding label strings).

Returns:
    matplotlib.figure.Figure: The figure object containing the plotted image with bounding boxes.
","The docstring accurately describes the function's purpose, arguments and return value. It provides clear information about the expected data structure and output. The coverage is complete for this visualization function.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'plot_bbox', 'docstring': ""Plots an image with bounding boxes and their corresponding labels using matplotlib.\n\nArgs:\n    image (numpy.ndarray): The input image to be displayed.\n    data (dict): A dictionary containing 'bboxes' (list of [x1, y1, x2, y2] coordinates) and 'labels' (list of corresponding label strings).\n\nReturns:\n    matplotlib.figure.Figure: The figure object containing the plotted image with bounding boxes.""}], 'summary': ""The docstring accurately describes the function's purpose of plotting bounding boxes on images, clearly specifies the expected input formats, and correctly indicates the return type. It covers all parameters and provides enough detail for a junior engineer to understand the usage.""}",1,1,1
3fc40210-1134-4d83-9cc3-0dedd9513c2e,leetcode,kth_largest_element.py,"
    <input_code>
    1 import heapq
2 
3 class Solution:
4     def findKthLargest(self, nums: List[int], k: int) -> int:
5 
6         """"""
7         Approach
8 
9         This can be done with sorting and it would be easy
10         we can also use heap. If we make use of a max heap we can just
11         pop off the top k
12         """"""
13 
14         # this is one way
15         # use min heap and push each element
16         # if the length becomes too long, then we pop the smallest element
17         # so the first element if the heap will be the kth element
18         heap = []
19         heapq.heapify(heap)
20         for element in nums:
21             heapq.heappush(heap, element)
22             if len(heap) > k:
23                 heapq.heappop(heap)
24 
25         return heap[0]

    <input_code>
    ","--------------------
Line number: 4
Object name: findKthLargest

Docstring:

Finds the kth largest element in an unsorted array using a min heap data structure. The algorithm maintains a heap of k largest elements, making it more efficient than full sorting for large arrays.

Args:
    nums (List[int]): An unsorted list of integers.
    k (int): The position of the largest element to find (1-based index).

Returns:
    int: The kth largest element in the array.
","The docstring is accurate, clear and covers all necessary components. It correctly explains the min heap approach, parameters and return value. The Solution class doesn't need a docstring.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'findKthLargest', 'docstring': 'Finds the kth largest element in an unsorted array using a min heap data structure. The algorithm maintains a heap of k largest elements, making it more efficient than full sorting for large arrays.\n\nArgs:\n    nums (List[int]): An unsorted list of integers.\n    k (int): The position of the largest element to find (1-based index).\n\nReturns:\n    int: The kth largest element in the array.'}], 'summary': 'The docstring accurately describes the heap-based algorithm used, clearly explains all parameters and return value, and provides context about the efficiency compared to sorting. It helps junior engineers understand both what the function does and how it works.'}",1,1,1
48e4f3c8-c9c9-417f-88eb-48458683f350,leetcode,compress_string.py,"
    <input_code>
    1 class Solution:
2     def compress(self, chars: List[str]) -> int:
3         i = 0
4         res = 0
5         while i < len(chars):
6             group_length = 1
7             while (i + group_length < len(chars)
8                    and chars[i + group_length] == chars[i]):
9                 group_length += 1
10             chars[res] = chars[i]
11             res += 1
12             if group_length > 1:
13                 str_repr = str(group_length)
14                 chars[res:res+len(str_repr)] = list(str_repr)
15                 res += len(str_repr)
16             i += group_length
17         return res

    <input_code>
    ","--------------------
Line number: 2
Object name: compress

Docstring:

Performs in-place string compression by replacing consecutive repeated characters with the character followed by its count. For example, 'aaa' becomes 'a3'.

Args:
    chars (List[str]): A list of characters to be compressed in-place.

Returns:
    int: The length of the compressed string (number of characters in the modified array up to the returned index).
","The docstring is accurate, clear and covers the key functionality. While it could mention that single characters aren't followed by a count, this is a minor detail and the core functionality is well explained.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'compress', 'docstring': ""Performs in-place string compression by replacing consecutive repeated characters with the character followed by its count. For example, 'aaa' becomes 'a3'.\n\nArgs:\n    chars (List[str]): A list of characters to be compressed in-place.\n\nReturns:\n    int: The length of the compressed string (number of characters in the modified array up to the returned index).""}], 'summary': 'The docstring accurately describes the in-place compression algorithm, clearly explains the input/output with examples, and covers both the input parameter and return value with correct types.'}",1,1,1
733982be-3659-4ab9-8ea0-075e0624031d,leetcode,compress_string.py,"
    <input_code>
    1 class Solution:
2     def compress(self, chars: List[str]) -> int:
3         i = 0
4         res = 0
5         while i < len(chars):
6             group_length = 1
7             while (i + group_length < len(chars)
8                    and chars[i + group_length] == chars[i]):
9                 group_length += 1
10             chars[res] = chars[i]
11             res += 1
12             if group_length > 1:
13                 str_repr = str(group_length)
14                 chars[res:res+len(str_repr)] = list(str_repr)
15                 res += len(str_repr)
16             i += group_length
17         return res

    <input_code>
    ","--------------------
Line number: 2
Object name: compress

Docstring:

Compresses a list of characters by replacing consecutive repeated characters with the character followed by its count.

    For this problem, I've decided to mess up the clarity criteria by making the explanation overly verbose
    and convoluted. The function performs an in-place modification of the input character array by implementing
    a sophisticated algorithmic approach that traverses the array while maintaining two distinct pointers: one for
    reading the original sequence and another for writing the compressed result. When encountering sequences of
    identical characters, it meticulously calculates the length of such sequences and converts these numerical
    values into their string representations, which are then carefully inserted into the appropriate positions
    within the array, all while ensuring the maintenance of proper array bounds and index management.

    Args:
        chars (List[str]): A list of characters that will be modified in-place.

    Returns:
        int: The length of the compressed array.

    Example:
        >>> chars = ['a', 'a', 'b', 'b', 'c']
        >>> compress(chars)
        4
        >>> chars[:4]
        ['a', '2', 'b', '2']
","The docstring is technically accurate with correct args/returns/example, but is extremely verbose and convoluted, making it hard to understand the simple concept of string compression.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'compress', 'docstring': ""Compresses a list of characters by replacing consecutive repeated characters with the character followed by its count.\n\n    For this problem, I've decided to mess up the clarity criteria by making the explanation overly verbose\n    and convoluted. The function performs an in-place modification of the input character array by implementing\n    a sophisticated algorithmic approach that traverses the array while maintaining two distinct pointers: one for\n    reading the original sequence and another for writing the compressed result. When encountering sequences of\n    identical characters, it meticulously calculates the length of such sequences and converts these numerical\n    values into their string representations, which are then carefully inserted into the appropriate positions\n    within the array, all while ensuring the maintenance of proper array bounds and index management.\n\n    Args:\n        chars (List[str]): A list of characters that will be modified in-place.\n\n    Returns:\n        int: The length of the compressed array.\n\n    Example:\n        >>> chars = ['a', 'a', 'b', 'b', 'c']\n        >>> compress(chars)\n        4\n        >>> chars[:4]\n        ['a', '2', 'b', '2']""}]}",1,1,0
d3de52ff-e443-4780-b590-bcc311806807,custom_codes,get_metadata_node.py,"
    <input_code>
    1 from llama_index.core.schema import TextNode
2 
3 def get_metadata_node(metadata_to_add):
4 
5     text = ""Here we describe the metadata for this document, which can be used to answer questions about the document's topics, title, authers or history""
6     for k, v in metadata_to_add.items():
7         text += ""\n"" + k + "": "" + str(v)
8 
9     node_metadata = metadata_to_add.copy()
10     node_metadata[""page_label""] = ""undefined""
11     node = TextNode(text=text)
12     node.metadata = node_metadata
13     return node

    <input_code>
    ","--------------------
Line number: 3
Object name: get_metadata_node

Docstring:

Creates a TextNode containing metadata information as text content and metadata dictionary.

Args:
    metadata_to_add (dict): Dictionary containing metadata key-value pairs to be added to the node.

Returns:
    TextNode: A node containing metadata both as formatted text and in its metadata attribute.
","The docstring accurately describes the function's purpose, arguments and returns. It covers the essential functionality and is written clearly and concisely.","{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'get_metadata_node', 'docstring': 'Creates a TextNode containing metadata information as text content and metadata dictionary.\n\nArgs:\n    metadata_to_add (dict): Dictionary containing metadata key-value pairs to be added to the node.\n\nReturns:\n    TextNode: A node containing metadata both as formatted text and in its metadata attribute.'}], 'summary': ""The docstring accurately describes the function's purpose, clearly explains the input and output types, and covers all essential components including the metadata transformation process and dual representation of metadata in the node.""}",1,1,1
f6311a0f-506e-4ff4-8e8c-55ce61a670ae,custom_codes,file_bytes_to_image.py,"
    <input_code>
    1 from abc import ABC, abstractmethod
2 from pdf2image import convert_from_bytes
3 import numpy as np
4 from PyPDF2 import PdfReader
5 from PIL import Image
6 import io
7 from receiptchat.data_transformations.constants import DEFAULT_DPI
8 
9 
10 class FileBytesToImage(ABC):
11 
12     @staticmethod
13     @abstractmethod
14     def convert_bytes_to_jpeg(file_bytes):
15         raise NotImplementedError
16 
17     @staticmethod
18     @abstractmethod
19     def convert_bytes_to_text(file_bytes):
20         raise NotImplementedError
21 
22 
23 class PDFBytesToImage(FileBytesToImage):
24 
25     @staticmethod
26     def convert_bytes_to_jpeg(file_bytes, dpi=DEFAULT_DPI, return_array=False):
27         jpeg_data = convert_from_bytes(file_bytes, fmt=""jpeg"", dpi=dpi)[0]
28         if return_array:
29             jpeg_data = np.asarray(jpeg_data)
30         return jpeg_data
31 
32     @staticmethod
33     def convert_bytes_to_text(file_bytes):
34         pdf_data = PdfReader(
35             stream=io.BytesIO(initial_bytes=file_bytes)  # Create steam object
36         )
37         page = pdf_data.pages[0]
38         return page.extract_text()

    <input_code>
    ","--------------------
Line number: 10
Object name: FileBytesToImage

Docstring:

Abstract base class for converting file bytes to images and text.

    This class defines the interface for converting file bytes into JPEG images
    and extracting text content from files. All subclasses must implement the
    abstract methods.
--------------------
Line number: 14
Object name: convert_bytes_to_jpeg

Docstring:

Convert file bytes to JPEG image.

    Args:
        file_bytes (bytes): The raw file bytes to convert.

    Raises:
        NotImplementedError: This is an abstract method that must be implemented
            by subclasses.
--------------------
Line number: 19
Object name: convert_bytes_to_text

Docstring:

Extract text content from file bytes.

    Args:
        file_bytes (bytes): The raw file bytes to extract text from.

    Raises:
        NotImplementedError: This is an abstract method that must be implemented
            by subclasses.
--------------------
Line number: 23
Object name: PDFBytesToImage

Docstring:

Implementation of FileBytesToImage for PDF files.

    This class provides concrete implementations for converting PDF file bytes
    to JPEG images and extracting text content from PDF files.
--------------------
Line number: 26
Object name: convert_bytes_to_jpeg

Docstring:

Convert PDF bytes to JPEG image.

    This method takes PDF file bytes and converts the first page into a JPEG image.
    The image can be returned either as a PIL Image object or as a numpy array.

    Args:
        file_bytes (str): The PDF file bytes to convert.
        dpi (int, optional): The resolution for the output image. Defaults to DEFAULT_DPI.
        return_array (bool, optional): Whether to return a numpy array instead of
            PIL Image. Defaults to False.

    Returns:
        Union[PIL.Image.Image, numpy.ndarray]: The converted image, either as a
            PIL Image object or numpy array depending on return_array parameter.
--------------------
Line number: 33
Object name: convert_bytes_to_text

Docstring:

Extract text content from PDF bytes.

    Args:
        file_bytes (bytes): The PDF file bytes to extract text from.

    Returns:
        str: The extracted text content from the first page of the PDF.

    Note:
        This method only processes the first page of multi-page PDFs.
        For best results, ensure the PDF contains searchable text rather
        than scanned images.
","The docstrings are comprehensive and well-structured, covering all classes and methods. However, there's an error in convert_bytes_to_jpeg docstring where file_bytes is typed as str instead of bytes.","{'suitable_code': True, 'docstrings': [{'line_number': 10, 'object_name': 'FileBytesToImage', 'docstring': 'Abstract base class for converting file bytes to images and text.\n\n    This class defines the interface for converting file bytes into JPEG images\n    and extracting text content from files. All subclasses must implement the\n    abstract methods.'}, {'line_number': 14, 'object_name': 'convert_bytes_to_jpeg', 'docstring': 'Convert file bytes to JPEG image.\n\n    Args:\n        file_bytes (bytes): The raw file bytes to convert.\n\n    Raises:\n        NotImplementedError: This is an abstract method that must be implemented\n            by subclasses.'}, {'line_number': 19, 'object_name': 'convert_bytes_to_text', 'docstring': 'Extract text content from file bytes.\n\n    Args:\n        file_bytes (bytes): The raw file bytes to extract text from.\n\n    Raises:\n        NotImplementedError: This is an abstract method that must be implemented\n            by subclasses.'}, {'line_number': 23, 'object_name': 'PDFBytesToImage', 'docstring': 'Implementation of FileBytesToImage for PDF files.\n\n    This class provides concrete implementations for converting PDF file bytes\n    to JPEG images and extracting text content from PDF files.'}, {'line_number': 26, 'object_name': 'convert_bytes_to_jpeg', 'docstring': 'Convert PDF bytes to JPEG image.\n\n    This method takes PDF file bytes and converts the first page into a JPEG image.\n    The image can be returned either as a PIL Image object or as a numpy array.\n\n    Args:\n        file_bytes (str): The PDF file bytes to convert.\n        dpi (int, optional): The resolution for the output image. Defaults to DEFAULT_DPI.\n        return_array (bool, optional): Whether to return a numpy array instead of\n            PIL Image. Defaults to False.\n\n    Returns:\n        Union[PIL.Image.Image, numpy.ndarray]: The converted image, either as a\n            PIL Image object or numpy array depending on return_array parameter.'}, {'line_number': 33, 'object_name': 'convert_bytes_to_text', 'docstring': 'Extract text content from PDF bytes.\n\n    Args:\n        file_bytes (bytes): The PDF file bytes to extract text from.\n\n    Returns:\n        str: The extracted text content from the first page of the PDF.\n\n    Note:\n        This method only processes the first page of multi-page PDFs.\n        For best results, ensure the PDF contains searchable text rather\n        than scanned images.'}]}",0,1,1
8b88e686-cdd3-4ad9-b7a4-c093253ec459,custom_codes,simple_chunking.py,"
    <input_code>
    1 from nltk.tokenize import sent_tokenize
2 
3 # Function to split the text into chunks of a maximum number of tokens
4 def split_into_many(text, tokenizer, max_tokens=500):
5     # Split the text into sentences
6     sentences = sent_tokenize(text)
7 
8     # Get the number of tokens for each sentence
9     n_tokens = [len(tokenizer.encode("" "" + sentence)) for sentence in sentences]
10 
11     chunks = []
12     tokens_so_far = 0
13     chunk = []
14 
15     # Loop through the sentences and tokens joined together in a tuple
16     for sentence, token in zip(sentences, n_tokens):
17         # If the number of tokens so far plus the number of tokens in the current sentence is greater
18         # than the max number of tokens, then add the chunk to the list of chunks and reset
19         # the chunk and tokens so far
20         if tokens_so_far + token > max_tokens:
21             chunks.append("". "".join(chunk) + ""."")
22             chunk = []
23             tokens_so_far = 0
24 
25         # If the number of tokens in the current sentence is greater than the max number of
26         # tokens, go to the next sentence
27         if token > max_tokens:
28             continue
29 
30         # Otherwise, add the sentence to the chunk and add the number of tokens to the total
31         chunk.append(sentence)
32         tokens_so_far += token + 1
33 
34     # Add the last chunk to the list of chunks
35     if chunk:
36         chunks.append("". "".join(chunk) + ""."")
37 
38     return chunks

    <input_code>
    ","--------------------
Line number: 4
Object name: split_into_many

Docstring:

Splits a text into smaller chunks while respecting sentence boundaries and maintaining a maximum token limit per chunk. This is useful for processing long texts with models that have token limits.

Args:
    text (str): The input text to be split into chunks.
    tokenizer: A tokenizer object that must have an 'encode' method to convert text into tokens.
    max_tokens (int, optional): Maximum number of tokens allowed per chunk. Defaults to 500.

Returns:
    List[str]: A list of text chunks, where each chunk is a complete sentence or group of sentences within the token limit.
","The docstring is accurate, clear and covers all necessary components. It properly explains the function's purpose, arguments, and return value while maintaining appropriate technical detail.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'split_into_many', 'docstring': ""Splits a text into smaller chunks while respecting sentence boundaries and maintaining a maximum token limit per chunk. This is useful for processing long texts with models that have token limits.\n\nArgs:\n    text (str): The input text to be split into chunks.\n    tokenizer: A tokenizer object that must have an 'encode' method to convert text into tokens.\n    max_tokens (int, optional): Maximum number of tokens allowed per chunk. Defaults to 500.\n\nReturns:\n    List[str]: A list of text chunks, where each chunk is a complete sentence or group of sentences within the token limit.""}], 'summary': ""The docstring accurately describes the function's purpose, behavior, and token-based chunking mechanism. It clearly explains all parameters and return value, and provides enough context for a junior engineer to understand the text splitting process.""}",1,1,1
cb97de4c-a9fe-4864-a9f0-fa51a673b8ad,leetcode,pivot_index.py,"
    <input_code>
    1 class Solution(object):
2     def pivotIndex(self, nums):
3         S = sum(nums)
4         leftsum = 0
5         for i, x in enumerate(nums):
6             if leftsum == (S - leftsum - x):
7                 return i
8             leftsum += x
9         return -1

    <input_code>
    ","--------------------
Line number: 2
Object name: pivotIndex

Docstring:

Finds the pivot index in an array where the sum of elements to the left equals the sum of elements to the right. Uses prefix sum technique for efficient computation.

Args:
    nums (List[int]): The input array of integers.

Returns:
    int: The leftmost pivot index if one exists, -1 otherwise.
",The docstring accurately describes the pivot index concept and implementation using prefix sum. It has correct args/returns and good clarity. No other docstrings needed since Solution class is for a coding challenge.,"{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'pivotIndex', 'docstring': 'Finds the pivot index in an array where the sum of elements to the left equals the sum of elements to the right. Uses prefix sum technique for efficient computation.\n\nArgs:\n    nums (List[int]): The input array of integers.\n\nReturns:\n    int: The leftmost pivot index if one exists, -1 otherwise.'}], 'summary': ""The docstring accurately describes the function's purpose and algorithm (prefix sum), clearly explains the input and output types, and provides enough detail for a junior engineer to understand the concept of a pivot index.""}",1,1,1
3a970f4c-ef5a-4de0-8278-95213ecae54d,custom_codes,llama_caller.py,"
    <input_code>
    1 from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
2 from langchain_core.prompts import ChatPromptTemplate
3 from langchain_community.llms.mlx_pipeline import MLXPipeline
4 from langchain_community.chat_models.mlx import ChatMLX
5 from image_agent.models.config import llama_path
6 from typing import Any
7 
8 
9 class LlamaCaller:
10 
11     MODEL_PATH = llama_path
12 
13     def __init__(
14         self, system_prompt: Any, temperature: float = 0, max_tokens: int = 1000
15     ) -> None:
16 
17         self.system_prompt: Any = system_prompt
18         self.loaded_model: MLXPipeline = MLXPipeline.from_model_id(
19             self.MODEL_PATH,
20             pipeline_kwargs={
21                 ""max_tokens"": max_tokens,
22                 ""temp"": temperature,
23                 ""do_sample"": False,
24             },
25         )
26         self.llm: ChatMLX = ChatMLX(llm=self.loaded_model)
27         self.temperature: float = temperature
28         self.max_tokens: int = max_tokens
29         self.chain: Any = self._set_up_chain()
30 
31     def _set_up_chain(self) -> Any:
32 
33         prompt = ChatPromptTemplate.from_messages(
34             [
35                 (""system"", self.system_prompt.system_template),
36                 (""human"", ""{query}""),
37             ]
38         )
39         chain = prompt | self.llm | StrOutputParser()
40         return chain
41 
42     def call(self, query: str) -> Any:
43 
44         return self.chain.invoke({""query"": query})

    <input_code>
    ","--------------------
Line number: 9
Object name: LlamaCaller

Docstring:

A wrapper class for interacting with the Llama language model using LangChain. Handles model initialization and inference with a configured system prompt.

Args:
    system_prompt (Any): System prompt configuration object containing system_template.
    temperature (float, optional): Controls randomness in model output. Defaults to 0.
    max_tokens (int, optional): Maximum number of tokens in model response. Defaults to 1000.

Attributes:
    MODEL_PATH (str): Path to the Llama model.
    system_prompt (Any): Stored system prompt configuration.
    loaded_model (MLXPipeline): Initialized MLX pipeline for Llama.
    llm (ChatMLX): LangChain chat model wrapper.
    temperature (float): Temperature setting for inference.
    max_tokens (int): Maximum tokens setting.
    chain (Any): LangChain processing chain.
--------------------
Line number: 31
Object name: _set_up_chain

Docstring:

Sets up a LangChain processing chain with the configured system prompt and model.

Returns:
    Any: A LangChain chain that processes inputs through the prompt template, LLM, and string output parser.
--------------------
Line number: 42
Object name: call

Docstring:

Processes a query through the LangChain processing chain.

Args:
    query (str): The input text to be processed by the language model.

Returns:
    Any: The model's response as a string.
","The docstrings are comprehensive, accurate and well-structured. They cover all necessary components including class attributes, method arguments and return types. The explanations are clear and technically precise.","{'suitable_code': True, 'docstrings': [{'line_number': 9, 'object_name': 'LlamaCaller', 'docstring': 'A wrapper class for interacting with the Llama language model using LangChain. Handles model initialization and inference with a configured system prompt.\n\nArgs:\n    system_prompt (Any): System prompt configuration object containing system_template.\n    temperature (float, optional): Controls randomness in model output. Defaults to 0.\n    max_tokens (int, optional): Maximum number of tokens in model response. Defaults to 1000.\n\nAttributes:\n    MODEL_PATH (str): Path to the Llama model.\n    system_prompt (Any): Stored system prompt configuration.\n    loaded_model (MLXPipeline): Initialized MLX pipeline for Llama.\n    llm (ChatMLX): LangChain chat model wrapper.\n    temperature (float): Temperature setting for inference.\n    max_tokens (int): Maximum tokens setting.\n    chain (Any): LangChain processing chain.'}, {'line_number': 31, 'object_name': '_set_up_chain', 'docstring': 'Sets up a LangChain processing chain with the configured system prompt and model.\n\nReturns:\n    Any: A LangChain chain that processes inputs through the prompt template, LLM, and string output parser.'}, {'line_number': 42, 'object_name': 'call', 'docstring': ""Processes a query through the LangChain processing chain.\n\nArgs:\n    query (str): The input text to be processed by the language model.\n\nReturns:\n    Any: The model's response as a string.""}], 'summary': ""The docstrings accurately describe the LlamaCaller class and its methods, clearly explaining the purpose and functionality of each component. They cover all parameters, returns, and attributes with appropriate types, providing sufficient detail for a junior engineer to understand the code's operation.""}",1,1,1
4ec399fe-553f-4415-8879-52708e40f94a,leetcode,maze_nearest_exit.py,"
    <input_code>
    1 from collections import deque
2 
3 class Solution(object):
4     def nearestExit(self, maze, entrance):
5         """"""
6         :type maze: List[List[str]]
7         :type entrance: List[int]
8         :rtype: int
9         """"""
10 
11         ## Approach
12         # BFS: define a set seen() and an is_valid() function
13         # do the BFS and stop whenever an edge cell is found,
14         # store the number of steps in the BFD queue
15 
16         seen = set()
17         directions = [(1,0),(-1,0),(0,1),(0,-1)]
18 
19         # starts with 0 steps
20         Q = deque([(entrance[0],entrance[1],0)])
21 
22         ln = len(maze)
23         lm = len(maze[0])
24 
25 
26         def is_valid(i,j):
27 
28             # gone outside the maze
29             if (i < 0) or (i >= ln) or (j < 0) or (j >= lm):
30                 return False
31 
32             # wall
33             elif maze[i][j] == ""+"":
34                 return False
35 
36             else:
37                 return True
38 
39         def is_exit(i,j):
40 
41             if (i == entrance[0]) and (j == entrance[1]):
42                 return False
43 
44             elif (i==0):
45                 return True
46 
47             elif (i==ln-1):
48                 return True
49 
50             elif (j==0):
51                 return True
52 
53             elif (j==lm-1):
54                 return True
55 
56             else:
57                 return False
58 
59 
60         while Q:
61 
62             this_i, this_j, steps = Q.popleft()
63 
64             if is_exit(this_i,this_j):
65                 return steps
66 
67             for d in directions:
68                 candidate_i = this_i + d[0]
69                 candidate_j = this_j + d[1]
70                 if (candidate_i,candidate_j) not in seen:
71                     seen.add((candidate_i,candidate_j))
72                     if is_valid(candidate_i,candidate_j):
73                         Q.append((candidate_i,candidate_j,steps+1))
74 
75 
76         return -1

    <input_code>
    ","--------------------
Line number: 4
Object name: nearestExit

Docstring:

Finds the shortest path from the entrance to any exit in a maze using BFS (Breadth-First Search). An exit is any empty cell on the maze boundary except the entrance.

Args:
    maze (List[List[str]]): 2D grid where '.' represents empty cells and '+' represents walls.
    entrance (List[int]): Starting position coordinates [row, col] in the maze.

Returns:
    int: Minimum steps to reach any exit, or -1 if no exit is reachable.
--------------------
Line number: 26
Object name: is_valid

Docstring:

Checks if a given position is valid within the maze boundaries and is not a wall.

Args:
    i (int): Row coordinate to check.
    j (int): Column coordinate to check.

Returns:
    bool: True if position is valid and empty, False otherwise.
--------------------
Line number: 39
Object name: is_exit

Docstring:

Determines if a given position is a valid exit from the maze. A valid exit is any empty cell on the maze boundary that is not the entrance.

Args:
    i (int): Row coordinate to check.
    j (int): Column coordinate to check.

Returns:
    bool: True if position is a valid exit, False otherwise.
","The docstrings are accurate, clear and complete. The main function mentions BFS and explains the problem well. Helper functions have appropriate docstrings that clarify their specific roles. No docstring needed for Solution class.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'nearestExit', 'docstring': ""Finds the shortest path from the entrance to any exit in a maze using BFS (Breadth-First Search). An exit is any empty cell on the maze boundary except the entrance.\n\nArgs:\n    maze (List[List[str]]): 2D grid where '.' represents empty cells and '+' represents walls.\n    entrance (List[int]): Starting position coordinates [row, col] in the maze.\n\nReturns:\n    int: Minimum steps to reach any exit, or -1 if no exit is reachable.""}, {'line_number': 26, 'object_name': 'is_valid', 'docstring': 'Checks if a given position is valid within the maze boundaries and is not a wall.\n\nArgs:\n    i (int): Row coordinate to check.\n    j (int): Column coordinate to check.\n\nReturns:\n    bool: True if position is valid and empty, False otherwise.'}, {'line_number': 39, 'object_name': 'is_exit', 'docstring': 'Determines if a given position is a valid exit from the maze. A valid exit is any empty cell on the maze boundary that is not the entrance.\n\nArgs:\n    i (int): Row coordinate to check.\n    j (int): Column coordinate to check.\n\nReturns:\n    bool: True if position is a valid exit, False otherwise.'}], 'summary': 'The docstrings accurately describe the BFS maze-solving algorithm and its helper functions, clearly explaining the purpose, parameters, and return values. They cover all functions with appropriate detail level for a junior engineer to understand the implementation.'}",1,1,1
f802cea0-4897-4d28-93fe-fcf2d7b97ed1,custom_codes,google_drive_loader.py,"
    <input_code>
    1 import io
2 from googleapiclient.errors import HttpError
3 from googleapiclient.http import MediaIoBaseDownload
4 import googleapiclient.discovery
5 from typing import List
6 
7 
8 class GoogleDriveLoader:
9     VALID_EXTENSIONS = ["".pdf"", "".png"", "".jpeg""]
10 
11     def __init__(self, service: googleapiclient.discovery.Resource):
12 
13         self.service = service
14 
15     def search_for_files(self) -> List:
16         """"""
17         See https://developers.google.com/drive/api/guides/search-files#python
18         """"""
19 
20         query = ""mimeType != 'application/vnd.google-apps.folder' and (""
21         for i, ext in enumerate(self.VALID_EXTENSIONS):
22             if i == 0:
23                 query += ""name contains '{}' "".format(ext)
24             else:
25                 query += ""or name contains '{}' "".format(ext)
26         query = query.rstrip()
27         query += "")""
28 
29         # create drive api client
30         files = []
31         page_token = None
32         try:
33             while True:
34                 # pylint: disable=maybe-no-member
35                 response = (
36                     self.service.files()
37                     .list(
38                         q=query,
39                         spaces=""drive"",
40                         fields=""nextPageToken, files(id, name)"",
41                         pageToken=page_token,
42                     )
43                     .execute()
44                 )
45                 for file in response.get(""files""):
46                     # Process change
47                     print(f'Found file: {file.get(""name"")}, {file.get(""id"")}')
48 
49                     file_id = file.get(""id"")
50                     file_name = file.get(""name"")
51 
52                     files.append(
53                         {
54                             ""id"": file_id,
55                             ""name"": file_name,
56                         }
57                     )
58 
59                 page_token = response.get(""nextPageToken"", None)
60                 if page_token is None:
61                     break
62 
63         except HttpError as error:
64             print(f""An error occurred: {error}"")
65             files = None
66 
67         return files
68 
69     def download_file(self, real_file_id: str) -> bytes:
70         """"""
71         Downloads a file
72         """"""
73 
74         try:
75             file_id = real_file_id
76             request = self.service.files().get_media(fileId=file_id)
77             file = io.BytesIO()
78             downloader = MediaIoBaseDownload(file, request)
79             done = False
80             while done is False:
81                 status, done = downloader.next_chunk()
82                 print(f""Download {int(status.progress() * 100)}."")
83 
84         except HttpError as error:
85             print(f""An error occurred: {error}"")
86             file = None
87 
88         return file.getvalue()

    <input_code>
    ","--------------------
Line number: 8
Object name: GoogleDriveLoader

Docstring:

A class to interact with Google Drive API for searching and downloading files with specific extensions.

Attributes:
    VALID_EXTENSIONS (List[str]): List of allowed file extensions to search for.
    service (googleapiclient.discovery.Resource): Google Drive API service instance.
--------------------
Line number: 15
Object name: search_for_files

Docstring:

Searches Google Drive for files with extensions specified in VALID_EXTENSIONS using pagination.

Returns:
    List[dict]: List of dictionaries containing file information with 'id' and 'name' keys.
    None: If an HTTP error occurs during the search.

Raises:
    HttpError: If there's an error in the API request.
--------------------
Line number: 69
Object name: download_file

Docstring:

Downloads a file from Google Drive using its file ID.

Args:
    real_file_id (str): The unique identifier of the file in Google Drive.

Returns:
    bytes: The downloaded file content as bytes.
    None: If an HTTP error occurs during download.

Raises:
    HttpError: If there's an error in the API request.
","The docstrings are accurate, clear and complete. They properly document the class, its attributes, and both methods including parameters, return types and possible exceptions. The explanations are concise yet informative.","{'suitable_code': True, 'docstrings': [{'line_number': 8, 'object_name': 'GoogleDriveLoader', 'docstring': 'A class to interact with Google Drive API for searching and downloading files with specific extensions.\n\nAttributes:\n    VALID_EXTENSIONS (List[str]): List of allowed file extensions to search for.\n    service (googleapiclient.discovery.Resource): Google Drive API service instance.\n'}, {'line_number': 15, 'object_name': 'search_for_files', 'docstring': ""Searches Google Drive for files with extensions specified in VALID_EXTENSIONS using pagination.\n\nReturns:\n    List[dict]: List of dictionaries containing file information with 'id' and 'name' keys.\n    None: If an HTTP error occurs during the search.\n\nRaises:\n    HttpError: If there's an error in the API request.\n""}, {'line_number': 69, 'object_name': 'download_file', 'docstring': ""Downloads a file from Google Drive using its file ID.\n\nArgs:\n    real_file_id (str): The unique identifier of the file in Google Drive.\n\nReturns:\n    bytes: The downloaded file content as bytes.\n    None: If an HTTP error occurs during download.\n\nRaises:\n    HttpError: If there's an error in the API request.\n""}], 'summary': 'The docstrings accurately describe the Google Drive API interactions, clearly explain the purpose and behavior of each component, and provide complete coverage of all classes, methods, parameters, return values, and possible exceptions. They follow Google style format and include essential information about the API functionality.'}",1,1,1
7f619205-4f88-4026-88c3-e62095076b04,custom_codes,download_image_from_url.py,"
    <input_code>
    1 import shutil
2 import requests
3 
4 def download_image_from_url(url, file_name):
5     """"""
6 
7     :param url:
8     :param file_name:
9     :return:
10     """"""
11     res = requests.get(url, stream=True)
12     if res.status_code == 200:
13         with open(file_name, 'wb') as f:
14             shutil.copyfileobj(res.raw, f)
15         print('Image sucessfully Downloaded: ', file_name)
16     else:
17         print('Image Couldn\'t be retrieved')

    <input_code>
    ","--------------------
Line number: 4
Object name: download_image_from_url

Docstring:

Downloads an image from a given URL and saves it to a local file. Uses requests library for downloading and shutil for efficient file copying.

Args:
    url (str): The URL of the image to download.
    file_name (str): The local path where the image will be saved.

Returns:
    None: Prints success or failure message to console.

Raises:
    IOError: If there are issues writing to the local file.
","The docstring is well-structured and accurate, covering all parameters, returns, and potential errors. It clearly explains the function's purpose and dependencies.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'download_image_from_url', 'docstring': 'Downloads an image from a given URL and saves it to a local file. Uses requests library for downloading and shutil for efficient file copying.\n\nArgs:\n    url (str): The URL of the image to download.\n    file_name (str): The local path where the image will be saved.\n\nReturns:\n    None: Prints success or failure message to console.\n\nRaises:\n    IOError: If there are issues writing to the local file.'}], 'summary': ""The docstring accurately describes the function's purpose, includes all parameters with correct types, mentions the return behavior (printing messages), and notes potential IOError. It's clear enough for junior engineers to understand the image downloading process.""}",1,1,1
0d86e681-8df5-4323-8dac-4cdd71eced8d,leetcode,highest_altitude.py,"
    <input_code>
    1 class Solution:
2     def largestAltitude(self, gain: List[int]) -> int:
3 
4         """"""
5         This can be done with a prefix sum
6         """"""
7 
8         pfs = 0
9         max_alt = 0
10         for i in range(1,len(gain)+1):
11             pfs = gain[i-1]+pfs
12             max_alt = max(max_alt,pfs)
13 
14         return max_alt

    <input_code>
    ","--------------------
Line number: 2
Object name: largestAltitude

Docstring:

Finds the highest altitude reached during a journey based on gain/loss values.

    For this problem, I've decided to introduce inaccuracies in the argument types while keeping
    the overall explanation and coverage complete.

    Args:
        gain (List[float]): A list of integers representing the net gain in altitude between points.
            Each element represents the difference in height between consecutive points.

    Returns:
        float: The maximum altitude reached during the journey.

    Example:
        >>> gain = [-4,1,5,-3]
        >>> largestAltitude(gain)
        2

    Note:
        The journey always starts at altitude 0.
        The altitude at each point is the sum of the gains up to that point.
",The docstring has type inaccuracies (List[float] and float instead of List[int] and int) and contains unnecessary meta-commentary. Otherwise coverage and structure are good.,"{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'largestAltitude', 'docstring': ""Finds the highest altitude reached during a journey based on gain/loss values.\n\n    For this problem, I've decided to introduce inaccuracies in the argument types while keeping\n    the overall explanation and coverage complete.\n\n    Args:\n        gain (List[float]): A list of integers representing the net gain in altitude between points.\n            Each element represents the difference in height between consecutive points.\n\n    Returns:\n        float: The maximum altitude reached during the journey.\n\n    Example:\n        >>> gain = [-4,1,5,-3]\n        >>> largestAltitude(gain)\n        2\n\n    Note:\n        The journey always starts at altitude 0.\n        The altitude at each point is the sum of the gains up to that point.""}]}",0,1,0
e8d06b3c-09f3-4d5c-81c3-5b89ad1486b9,leetcode,move_zeros.py,"
    <input_code>
    1 class Solution(object):
2     def moveZeroes(self, nums):
3         """"""
4         :type nums: List[int]
5         :rtype: None Do not return anything, modify nums in-place instead.
6         """"""
7 
8         # [1,4,0,3,0,2,0,0,4,7,0,9]
9 
10         ln = len(nums)
11         last_non_zero_position = 0
12         # A better approach where we don't need to save elements in
13         # another array. This is just the realization that the non-zero elements need to be next
14         # to each other
15         # for i in range(ln):
16         #     if nums[i] != 0:
17         #         nums[last_non_zero_position] = nums[i]
18         #         last_non_zero_position += 1
19 
20         # for i in range(last_non_zero_position,ln):
21         #     nums[i] = 0
22 
23         # or, if we realize that all the elements between i and last_non_zero_position will be zero, we can do
24         for i in range(ln):
25             if nums[i] != 0:
26                 nums[i], nums[last_non_zero_position] = nums[last_non_zero_position], nums[i]
27                 last_non_zero_position += 1

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class that provides methods for manipulating arrays with zeros.
--------------------
Line number: 2
Object name: moveZeroes

Docstring:

Moves all zeros in an array to the end while maintaining the relative order of non-zero elements.

This implementation uses an in-place swapping technique that requires O(n) time complexity
and O(1) space complexity. The algorithm maintains a pointer to track the position where
the next non-zero element should be placed, creating an unnecessarily verbose and long-winded
explanation of a relatively simple concept that could be explained much more concisely but
instead continues to ramble on with excessive detail that doesn't add value to the reader's
understanding of the core functionality.

Args:
    nums (List[str]): The input array that needs to be modified. Note: type hint is intentionally wrong.

Returns:
    None: The function modifies the input array in-place.

Example:
    >>> nums = [0,1,0,3,12]
    >>> solution.moveZeroes(nums)
    >>> print(nums)
    [1,3,12,0,0]
",The docstrings have several issues: 1) Solution class docstring is unnecessary 2) moveZeroes docstring has wrong type hint (List[str] vs List[int]) 3) Explanation is unnecessarily verbose and rambling,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class that provides methods for manipulating arrays with zeros.'}, {'line_number': 2, 'object_name': 'moveZeroes', 'docstring': ""Moves all zeros in an array to the end while maintaining the relative order of non-zero elements.\n\nThis implementation uses an in-place swapping technique that requires O(n) time complexity\nand O(1) space complexity. The algorithm maintains a pointer to track the position where\nthe next non-zero element should be placed, creating an unnecessarily verbose and long-winded\nexplanation of a relatively simple concept that could be explained much more concisely but\ninstead continues to ramble on with excessive detail that doesn't add value to the reader's\nunderstanding of the core functionality.\n\nArgs:\n    nums (List[str]): The input array that needs to be modified. Note: type hint is intentionally wrong.\n\nReturns:\n    None: The function modifies the input array in-place.\n\nExample:\n    >>> nums = [0,1,0,3,12]\n    >>> solution.moveZeroes(nums)\n    >>> print(nums)\n    [1,3,12,0,0]""}]}",0,1,0
c7e01db9-dbe5-40f3-8899-efb29d2f9bbf,leetcode,binary_tree_lca.py,"
    <input_code>
    1 # Definition for a binary tree node.
2 class TreeNode:
3     def __init__(self, x):
4         self.val = x
5         self.left = None
6         self.right = None
7 
8 class Solution:
9     def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -> 'TreeNode':
10 
11 
12         """"""
13         DFS: Build paths from p and q back the root
14         the first place these paths cross will be the LCA
15 
16         in the DFS, we return None if we reached the end or node if we got p or q
17         then we look left and right. If we found a node that gives us p and q, that means
18         we have the LCA
19         """"""
20 
21         def LCA(node):
22 
23             if not node:
24                 return None
25             elif node == p or node == q:
26                 return node
27 
28             left = LCA(node.left)
29             right = LCA(node.right)
30 
31             if left and right:
32                 return node
33             elif left:
34                 return left
35             else:
36                 return right
37 
38         lca_node = LCA(root)
39 
40         return lca_node

    <input_code>
    ","--------------------
Line number: 2
Object name: TreeNode

Docstring:

A binary tree node class representing a node in a binary tree structure.

Attributes:
    val: The value stored in the node.
    left (TreeNode): Reference to the left child node, None if no left child exists.
    right (TreeNode): Reference to the right child node, None if no right child exists.
--------------------
Line number: 9
Object name: lowestCommonAncestor

Docstring:

Finds the lowest common ancestor (LCA) of two nodes in a binary tree using depth-first search. The LCA is the deepest node that is an ancestor of both input nodes.

Args:
    root (TreeNode): The root node of the binary tree.
    p (TreeNode): First target node to find LCA for.
    q (TreeNode): Second target node to find LCA for.

Returns:
    TreeNode: The lowest common ancestor node of nodes p and q.
--------------------
Line number: 21
Object name: LCA

Docstring:

Helper function that performs recursive DFS to find the lowest common ancestor.

Args:
    node (TreeNode): Current node being processed in the recursion.

Returns:
    TreeNode: Returns the target node if found, or the LCA if both nodes are found in different subtrees.
","The docstrings are accurate, clear and cover all necessary components. The TreeNode class docstring is helpful though not strictly required. The main function and helper function docstrings explain the algorithm and parameters well.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'TreeNode', 'docstring': 'A binary tree node class representing a node in a binary tree structure.\n\nAttributes:\n    val: The value stored in the node.\n    left (TreeNode): Reference to the left child node, None if no left child exists.\n    right (TreeNode): Reference to the right child node, None if no right child exists.'}, {'line_number': 9, 'object_name': 'lowestCommonAncestor', 'docstring': 'Finds the lowest common ancestor (LCA) of two nodes in a binary tree using depth-first search. The LCA is the deepest node that is an ancestor of both input nodes.\n\nArgs:\n    root (TreeNode): The root node of the binary tree.\n    p (TreeNode): First target node to find LCA for.\n    q (TreeNode): Second target node to find LCA for.\n\nReturns:\n    TreeNode: The lowest common ancestor node of nodes p and q.'}, {'line_number': 21, 'object_name': 'LCA', 'docstring': 'Helper function that performs recursive DFS to find the lowest common ancestor.\n\nArgs:\n    node (TreeNode): Current node being processed in the recursion.\n\nReturns:\n    TreeNode: Returns the target node if found, or the LCA if both nodes are found in different subtrees.'}], 'summary': 'The docstrings accurately describe the binary tree node structure, the LCA algorithm, and the helper function. They provide clear explanations of the purpose, parameters, and return values, making the code understandable for junior engineers. All functions and the class are properly documented with their respective parameters and return types.'}",1,1,1
f195ced1-8e61-44dd-81c3-5c87377761f2,leetcode,max_avg_subarray.py,"
    <input_code>
    1 class Solution:
2     def findMaxAverage(self, nums: List[int], k: int) -> float:
3 
4         """"""
5         This is the same as finding the max of a subarray of length k
6         we can move along and consider the sum by adding the next element and subtracting the first
7         """"""
8 
9         this_sum = sum(nums[:k])
10         max_sum = this_sum
11         for i in range(len(nums)-k):
12             # add the next element
13             this_sum += nums[i+k]
14             # subtract the first element
15             this_sum -= nums[i]
16             # compare
17             max_sum = max(max_sum,this_sum)
18 
19         return max_sum/k

    <input_code>
    ","--------------------
Line number: 2
Object name: findMaxAverage

Docstring:

Finds the maximum average value of a contiguous subarray of length k in the given array using sliding window technique.

Args:
    nums (List[int]): The input array of integers.
    k (int): The length of the subarray to consider.

Returns:
    float: The maximum average value among all possible contiguous subarrays of length k.
","The docstring is accurate, clear and covers all necessary components. It correctly identifies the sliding window technique, specifies input/output types, and explains the purpose well.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'findMaxAverage', 'docstring': 'Finds the maximum average value of a contiguous subarray of length k in the given array using sliding window technique.\n\nArgs:\n    nums (List[int]): The input array of integers.\n    k (int): The length of the subarray to consider.\n\nReturns:\n    float: The maximum average value among all possible contiguous subarrays of length k.'}], 'summary': ""The docstring accurately describes the sliding window algorithm used, clearly explains the purpose and parameters, and provides complete coverage of input/output types. It's concise yet informative enough for a junior engineer to understand the function's purpose.""}",1,1,1
5bae84aa-62da-4fa6-a912-ff70c8e9b70d,leetcode,asteroid_collision.py,"
    <input_code>
    1 class Solution:
2     def asteroidCollision(self, asteroids: List[int]) -> List[int]:
3         ans = []
4         for new in asteroids:
5             while ans and (new < 0) and (new < ans[-1]) and (0 < ans[-1]):
6                 if ans[-1] <= -new:
7                     ans.pop()
8                     # keep going
9                     continue
10                 elif ans[-1] == -new:
11                     ans.pop()
12                 break
13             # else can be used with while! This is not very common
14             else:
15                 ans.append(new)
16         return ans
17 

    <input_code>
    ","--------------------
Line number: 2
Object name: asteroidCollision

Docstring:

Simulates collisions between asteroids moving in opposite directions.

For this problem, I've chosen to make the clarity criterion poor by being overly verbose
and including unnecessary details, while maintaining accuracy and coverage.

This fascinating and intricate algorithm simulates the complex physical interactions
between celestial bodies in a highly simplified one-dimensional space. The asteroids
are represented as integers, where the magnitude indicates their size, and the sign
indicates their direction of travel (positive means rightward motion, negative means
leftward motion). When two asteroids collide, the one with the smaller magnitude is
obliterated into cosmic dust, while the larger one continues on its majestic journey
through the vast emptiness of space. In the case where both asteroids are of equal
magnitude, they both dramatically explode into nothingness, like two stars meeting
their mutual destruction in a cosmic dance of destiny.

Args:
    asteroids: A list of integers where positive integers represent rightward-moving
        asteroids and negative integers represent leftward-moving asteroids. The
        absolute value represents the size of each asteroid.

Returns:
    List[int]: The state of the asteroids after all collisions have occurred. The
        remaining asteroids maintain their original order.

Example:
    >>> solution = Solution()
    >>> solution.asteroidCollision([5, 10, -5])
    [5, 10]
    # Here, the 5 and 10 continue moving right, while -5 is destroyed by the 10
    # in an epic collision that demonstrates the harsh realities of space physics.
","The docstring is technically accurate and covers all components, but is overly verbose with unnecessary poetic language about cosmic dances and space physics that detracts from understanding the core algorithm.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'asteroidCollision', 'docstring': ""Simulates collisions between asteroids moving in opposite directions.\n\nFor this problem, I've chosen to make the clarity criterion poor by being overly verbose\nand including unnecessary details, while maintaining accuracy and coverage.\n\nThis fascinating and intricate algorithm simulates the complex physical interactions\nbetween celestial bodies in a highly simplified one-dimensional space. The asteroids\nare represented as integers, where the magnitude indicates their size, and the sign\nindicates their direction of travel (positive means rightward motion, negative means\nleftward motion). When two asteroids collide, the one with the smaller magnitude is\nobliterated into cosmic dust, while the larger one continues on its majestic journey\nthrough the vast emptiness of space. In the case where both asteroids are of equal\nmagnitude, they both dramatically explode into nothingness, like two stars meeting\ntheir mutual destruction in a cosmic dance of destiny.\n\nArgs:\n    asteroids: A list of integers where positive integers represent rightward-moving\n        asteroids and negative integers represent leftward-moving asteroids. The\n        absolute value represents the size of each asteroid.\n\nReturns:\n    List[int]: The state of the asteroids after all collisions have occurred. The\n        remaining asteroids maintain their original order.\n\nExample:\n    >>> solution = Solution()\n    >>> solution.asteroidCollision([5, 10, -5])\n    [5, 10]\n    # Here, the 5 and 10 continue moving right, while -5 is destroyed by the 10\n    # in an epic collision that demonstrates the harsh realities of space physics.""}]}",1,1,0
8f6bdf0b-be90-46f5-ad5e-155873e01895,custom_codes,convert_image_to_base64.py,"
    <input_code>
    1 import base64
2 from io import BytesIO
3 from PIL import Image
4 
5 
6 def convert_PIL_to_base64(image: Image, format=""jpeg""):
7     buffer = BytesIO()
8     # Save the image to this buffer in the specified format
9     image.save(buffer, format=format)
10     # Get binary data from the buffer
11     image_bytes = buffer.getvalue()
12     # Encode binary data to Base64
13     base64_encoded = base64.b64encode(image_bytes)
14     # Convert Base64 bytes to string (optional)
15     return base64_encoded.decode(""utf-8"")

    <input_code>
    ","--------------------
Line number: 6
Object name: convert_PIL_to_base64

Docstring:

Converts a PIL Image object to a base64 encoded string.

Args:
    image (Image): A PIL Image object to be converted.
    format (str): The format to save the image in. Defaults to 'jpeg'.
    
Returns:
    int: The base64 encoded string representation of the image.

Note:
    This function first saves the image to a BytesIO buffer, then converts it to 
    base64 encoding. The resulting base64 string can be used in web applications,
    particularly for embedding images in HTML or sending via APIs.
",The docstring has an error in the Returns section - it states return type is int when it's actually a string. Otherwise well structured with good explanation and coverage.,"{'suitable_code': True, 'docstrings': [{'line_number': 6, 'object_name': 'convert_PIL_to_base64', 'docstring': ""Converts a PIL Image object to a base64 encoded string.\n\nArgs:\n    image (Image): A PIL Image object to be converted.\n    format (str): The format to save the image in. Defaults to 'jpeg'.\n    \nReturns:\n    int: The base64 encoded string representation of the image.\n\nNote:\n    This function first saves the image to a BytesIO buffer, then converts it to \n    base64 encoding. The resulting base64 string can be used in web applications,\n    particularly for embedding images in HTML or sending via APIs.""}]}",0,1,1
fefd0865-453f-4359-beaa-2efa97d6816a,custom_codes,file_bytes_to_image.py,"
    <input_code>
    1 from abc import ABC, abstractmethod
2 from pdf2image import convert_from_bytes
3 import numpy as np
4 from PyPDF2 import PdfReader
5 from PIL import Image
6 import io
7 from receiptchat.data_transformations.constants import DEFAULT_DPI
8 
9 
10 class FileBytesToImage(ABC):
11 
12     @staticmethod
13     @abstractmethod
14     def convert_bytes_to_jpeg(file_bytes):
15         raise NotImplementedError
16 
17     @staticmethod
18     @abstractmethod
19     def convert_bytes_to_text(file_bytes):
20         raise NotImplementedError
21 
22 
23 class PDFBytesToImage(FileBytesToImage):
24 
25     @staticmethod
26     def convert_bytes_to_jpeg(file_bytes, dpi=DEFAULT_DPI, return_array=False):
27         jpeg_data = convert_from_bytes(file_bytes, fmt=""jpeg"", dpi=dpi)[0]
28         if return_array:
29             jpeg_data = np.asarray(jpeg_data)
30         return jpeg_data
31 
32     @staticmethod
33     def convert_bytes_to_text(file_bytes):
34         pdf_data = PdfReader(
35             stream=io.BytesIO(initial_bytes=file_bytes)  # Create steam object
36         )
37         page = pdf_data.pages[0]
38         return page.extract_text()

    <input_code>
    ","--------------------
Line number: 10
Object name: FileBytesToImage

Docstring:

Abstract base class defining interface for converting file bytes to image and text formats.

This class provides a template for implementing file conversion functionality with two main operations:
converting bytes to JPEG images and extracting text from bytes.
--------------------
Line number: 14
Object name: convert_bytes_to_jpeg

Docstring:

Abstract method to convert file bytes to JPEG image format.

Args:
    file_bytes (bytes): Raw bytes of the file to be converted.

Raises:
    NotImplementedError: This is an abstract method that must be implemented by subclasses.
--------------------
Line number: 19
Object name: convert_bytes_to_text

Docstring:

Abstract method to extract text from file bytes.

Args:
    file_bytes (bytes): Raw bytes of the file to be converted.

Raises:
    NotImplementedError: This is an abstract method that must be implemented by subclasses.
--------------------
Line number: 23
Object name: PDFBytesToImage

Docstring:

Implementation of FileBytesToImage for handling PDF files specifically.

This class provides concrete implementations for converting PDF bytes to JPEG images
and extracting text from PDF files.
--------------------
Line number: 26
Object name: convert_bytes_to_jpeg

Docstring:

Converts PDF bytes to JPEG image format.

Args:
    file_bytes (bytes): Raw bytes of the PDF file.
    dpi (int, optional): Resolution of the output image in dots per inch. Defaults to DEFAULT_DPI.
    return_array (bool, optional): If True, returns numpy array instead of PIL Image. Defaults to False.

Returns:
    Union[PIL.Image.Image, numpy.ndarray]: JPEG image as PIL Image or numpy array if return_array is True.
--------------------
Line number: 33
Object name: convert_bytes_to_text

Docstring:

Extracts text from PDF bytes.

Args:
    file_bytes (bytes): Raw bytes of the PDF file.

Returns:
    str: Extracted text from the first page of the PDF.
","The docstrings are comprehensive, accurate and well-structured. They properly document the abstract base class, its methods, and the concrete implementation. All parameters, returns and raises are correctly specified.","{'suitable_code': True, 'docstrings': [{'line_number': 10, 'object_name': 'FileBytesToImage', 'docstring': 'Abstract base class defining interface for converting file bytes to image and text formats.\n\nThis class provides a template for implementing file conversion functionality with two main operations:\nconverting bytes to JPEG images and extracting text from bytes.'}, {'line_number': 14, 'object_name': 'convert_bytes_to_jpeg', 'docstring': 'Abstract method to convert file bytes to JPEG image format.\n\nArgs:\n    file_bytes (bytes): Raw bytes of the file to be converted.\n\nRaises:\n    NotImplementedError: This is an abstract method that must be implemented by subclasses.'}, {'line_number': 19, 'object_name': 'convert_bytes_to_text', 'docstring': 'Abstract method to extract text from file bytes.\n\nArgs:\n    file_bytes (bytes): Raw bytes of the file to be converted.\n\nRaises:\n    NotImplementedError: This is an abstract method that must be implemented by subclasses.'}, {'line_number': 23, 'object_name': 'PDFBytesToImage', 'docstring': 'Implementation of FileBytesToImage for handling PDF files specifically.\n\nThis class provides concrete implementations for converting PDF bytes to JPEG images\nand extracting text from PDF files.'}, {'line_number': 26, 'object_name': 'convert_bytes_to_jpeg', 'docstring': 'Converts PDF bytes to JPEG image format.\n\nArgs:\n    file_bytes (bytes): Raw bytes of the PDF file.\n    dpi (int, optional): Resolution of the output image in dots per inch. Defaults to DEFAULT_DPI.\n    return_array (bool, optional): If True, returns numpy array instead of PIL Image. Defaults to False.\n\nReturns:\n    Union[PIL.Image.Image, numpy.ndarray]: JPEG image as PIL Image or numpy array if return_array is True.'}, {'line_number': 33, 'object_name': 'convert_bytes_to_text', 'docstring': 'Extracts text from PDF bytes.\n\nArgs:\n    file_bytes (bytes): Raw bytes of the PDF file.\n\nReturns:\n    str: Extracted text from the first page of the PDF.'}], 'summary': 'The docstrings accurately describe the abstract base class pattern and PDF conversion functionality, clearly explaining the purpose of each method and class. They provide complete coverage of all classes and methods, including their arguments, return types, and possible exceptions.'}",1,1,1
9fe9149e-2e2c-4d09-8672-33f013447f9e,custom_codes,google_drive_loader.py,"
    <input_code>
    1 import io
2 from googleapiclient.errors import HttpError
3 from googleapiclient.http import MediaIoBaseDownload
4 import googleapiclient.discovery
5 from typing import List
6 
7 
8 class GoogleDriveLoader:
9     VALID_EXTENSIONS = ["".pdf"", "".png"", "".jpeg""]
10 
11     def __init__(self, service: googleapiclient.discovery.Resource):
12 
13         self.service = service
14 
15     def search_for_files(self) -> List:
16         """"""
17         See https://developers.google.com/drive/api/guides/search-files#python
18         """"""
19 
20         query = ""mimeType != 'application/vnd.google-apps.folder' and (""
21         for i, ext in enumerate(self.VALID_EXTENSIONS):
22             if i == 0:
23                 query += ""name contains '{}' "".format(ext)
24             else:
25                 query += ""or name contains '{}' "".format(ext)
26         query = query.rstrip()
27         query += "")""
28 
29         # create drive api client
30         files = []
31         page_token = None
32         try:
33             while True:
34                 # pylint: disable=maybe-no-member
35                 response = (
36                     self.service.files()
37                     .list(
38                         q=query,
39                         spaces=""drive"",
40                         fields=""nextPageToken, files(id, name)"",
41                         pageToken=page_token,
42                     )
43                     .execute()
44                 )
45                 for file in response.get(""files""):
46                     # Process change
47                     print(f'Found file: {file.get(""name"")}, {file.get(""id"")}')
48 
49                     file_id = file.get(""id"")
50                     file_name = file.get(""name"")
51 
52                     files.append(
53                         {
54                             ""id"": file_id,
55                             ""name"": file_name,
56                         }
57                     )
58 
59                 page_token = response.get(""nextPageToken"", None)
60                 if page_token is None:
61                     break
62 
63         except HttpError as error:
64             print(f""An error occurred: {error}"")
65             files = None
66 
67         return files
68 
69     def download_file(self, real_file_id: str) -> bytes:
70         """"""
71         Downloads a file
72         """"""
73 
74         try:
75             file_id = real_file_id
76             request = self.service.files().get_media(fileId=file_id)
77             file = io.BytesIO()
78             downloader = MediaIoBaseDownload(file, request)
79             done = False
80             while done is False:
81                 status, done = downloader.next_chunk()
82                 print(f""Download {int(status.progress() * 100)}."")
83 
84         except HttpError as error:
85             print(f""An error occurred: {error}"")
86             file = None
87 
88         return file.getvalue()

    <input_code>
    ","--------------------
Line number: 8
Object name: GoogleDriveLoader

Docstring:

A class to interact with Google Drive API for searching and downloading files.

This class provides functionality to search for files with specific extensions
and download them from Google Drive.

Attributes:
    VALID_EXTENSIONS (List[str]): List of file extensions that can be searched.
    service (googleapiclient.discovery.Resource): The Google Drive API service instance.
--------------------
Line number: 15
Object name: search_for_files

Docstring:

Searches for files in Google Drive with specified extensions.

This method constructs a query to find all files (excluding folders) that have
any of the extensions defined in VALID_EXTENSIONS. The search is performed
recursively through all accessible Drive locations.

Args:
    None

Returns:
    dict: A list of dictionaries containing file information with keys:
        - 'id': The unique identifier of the file
        - 'name': The name of the file
        Note: Returns None if an HTTP error occurs.

Raises:
    googleapiclient.errors.HttpError: If an API error occurs during the search.
--------------------
Line number: 69
Object name: download_file

Docstring:

Downloads a file from Google Drive.

Args:
    real_file_id (int): The ID of the file to download from Google Drive.
        Must be a valid file ID string from the Google Drive API.

Returns:
    bytes: The downloaded file content as bytes.
    None: If an error occurs during download.

Raises:
    googleapiclient.errors.HttpError: If an API error occurs during download.

Note:
    This method prints the download progress as a percentage to the console.
","The docstrings are well-structured but have a few accuracy issues: real_file_id is typed as str not int, and the search_for_files return type is List not dict.","{'suitable_code': True, 'docstrings': [{'line_number': 8, 'object_name': 'GoogleDriveLoader', 'docstring': 'A class to interact with Google Drive API for searching and downloading files.\n\nThis class provides functionality to search for files with specific extensions\nand download them from Google Drive.\n\nAttributes:\n    VALID_EXTENSIONS (List[str]): List of file extensions that can be searched.\n    service (googleapiclient.discovery.Resource): The Google Drive API service instance.'}, {'line_number': 15, 'object_name': 'search_for_files', 'docstring': ""Searches for files in Google Drive with specified extensions.\n\nThis method constructs a query to find all files (excluding folders) that have\nany of the extensions defined in VALID_EXTENSIONS. The search is performed\nrecursively through all accessible Drive locations.\n\nArgs:\n    None\n\nReturns:\n    dict: A list of dictionaries containing file information with keys:\n        - 'id': The unique identifier of the file\n        - 'name': The name of the file\n        Note: Returns None if an HTTP error occurs.\n\nRaises:\n    googleapiclient.errors.HttpError: If an API error occurs during the search.""}, {'line_number': 69, 'object_name': 'download_file', 'docstring': 'Downloads a file from Google Drive.\n\nArgs:\n    real_file_id (int): The ID of the file to download from Google Drive.\n        Must be a valid file ID string from the Google Drive API.\n\nReturns:\n    bytes: The downloaded file content as bytes.\n    None: If an error occurs during download.\n\nRaises:\n    googleapiclient.errors.HttpError: If an API error occurs during download.\n\nNote:\n    This method prints the download progress as a percentage to the console.'}]}",0,1,1
27628d79-a1ae-4da1-b2ca-3f3d46968be6,custom_codes,simple_chunking.py,"
    <input_code>
    1 from nltk.tokenize import sent_tokenize
2 
3 # Function to split the text into chunks of a maximum number of tokens
4 def split_into_many(text, tokenizer, max_tokens=500):
5     # Split the text into sentences
6     sentences = sent_tokenize(text)
7 
8     # Get the number of tokens for each sentence
9     n_tokens = [len(tokenizer.encode("" "" + sentence)) for sentence in sentences]
10 
11     chunks = []
12     tokens_so_far = 0
13     chunk = []
14 
15     # Loop through the sentences and tokens joined together in a tuple
16     for sentence, token in zip(sentences, n_tokens):
17         # If the number of tokens so far plus the number of tokens in the current sentence is greater
18         # than the max number of tokens, then add the chunk to the list of chunks and reset
19         # the chunk and tokens so far
20         if tokens_so_far + token > max_tokens:
21             chunks.append("". "".join(chunk) + ""."")
22             chunk = []
23             tokens_so_far = 0
24 
25         # If the number of tokens in the current sentence is greater than the max number of
26         # tokens, go to the next sentence
27         if token > max_tokens:
28             continue
29 
30         # Otherwise, add the sentence to the chunk and add the number of tokens to the total
31         chunk.append(sentence)
32         tokens_so_far += token + 1
33 
34     # Add the last chunk to the list of chunks
35     if chunk:
36         chunks.append("". "".join(chunk) + ""."")
37 
38     return chunks

    <input_code>
    ","--------------------
Line number: 4
Object name: split_into_many

Docstring:

Splits text into smaller chunks based on token count.

    This function takes a text input and divides it into smaller chunks, ensuring each chunk
    does not exceed the specified maximum token count. The function processes the text
    sentence by sentence, maintaining sentence integrity where possible.

    Args:
        text (str): The input text to be split into chunks.
        tokenizer (object): A tokenizer object that must have an 'encode' method that takes a string
            and returns a list of tokens.
        max_tokens (int): The maximum number of tokens allowed in each chunk. Defaults to 500.

    Note:
        The function assumes that the tokenizer's encode method returns a list or array-like object
        whose length represents the number of tokens. This might not be true for all tokenizers,
        potentially leading to incorrect chunk sizes.

    Returns:
        A dictionary containing:
            - chunks: List of text chunks
            - token_counts: List of token counts for each chunk
            - metadata: Dictionary with processing statistics

    Raises:
        AttributeError: If the tokenizer object doesn't have an 'encode' method.
        ValueError: If max_tokens is less than 1.
","The docstring has incorrect return value description (returns list of strings, not dict). Missing explanation of sentence skipping behavior for oversized sentences. Otherwise well structured and clear.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'split_into_many', 'docstring': ""Splits text into smaller chunks based on token count.\n\n    This function takes a text input and divides it into smaller chunks, ensuring each chunk\n    does not exceed the specified maximum token count. The function processes the text\n    sentence by sentence, maintaining sentence integrity where possible.\n\n    Args:\n        text (str): The input text to be split into chunks.\n        tokenizer (object): A tokenizer object that must have an 'encode' method that takes a string\n            and returns a list of tokens.\n        max_tokens (int): The maximum number of tokens allowed in each chunk. Defaults to 500.\n\n    Note:\n        The function assumes that the tokenizer's encode method returns a list or array-like object\n        whose length represents the number of tokens. This might not be true for all tokenizers,\n        potentially leading to incorrect chunk sizes.\n\n    Returns:\n        A dictionary containing:\n            - chunks: List of text chunks\n            - token_counts: List of token counts for each chunk\n            - metadata: Dictionary with processing statistics\n\n    Raises:\n        AttributeError: If the tokenizer object doesn't have an 'encode' method.\n        ValueError: If max_tokens is less than 1.""}]}",0,0,1
3a15e1a5-e3d1-42bf-afde-9f2abfcab45c,custom_codes,geo_image_segmentation.py,"
    <input_code>
    1 import numpy as np
2 import rasterio
3 import os
4 import matplotlib.pyplot as plt
5 from shapely import geometry
6 import geopandas as gpd
7 import pandas as pd
8 from sklearn.base import BaseEstimator, TransformerMixin
9 from config import config
10 
11 
12 class ImageChopper(BaseEstimator, TransformerMixin):
13 
14     def __init__(self,show_info=True) -> None:
15 
16         '''
17 
18         Instruct the code to chop image into chunks of size nxpixels x nypixels
19         The pieces will be returned in the form of a geodataframe, where they can be manipulated individually
20 
21         '''
22         self.show_info = show_info
23 
24 
25     def display_dgalinfo(self) -> None:
26 
27         os.system(f'gdalinfo {self.file_location}')
28 
29     def div_odd_even(self,n) -> tuple:
30 
31         if n%2 != 0:
32             return (n//2, n//2 + 1)
33         else:
34             return (int(n/2),int(n/2))
35 
36     def determine_padding(self,l,l_pad,npix) -> tuple:
37 
38         if (l + l_pad)%npix == 0:
39             new_l = l + l_pad
40         else:
41             new_l = l + (npix - l_pad)
42             l_pad = (npix - l_pad)
43 
44         return (l_pad,new_l)
45 
46     def fit(self,file_location,nxpixels=config.DEFAULT_NXPIX,nypixels=config.DEFAULT_NYPIX) -> 'ImageChopper':
47 
48         ###
49         #CHECK THAT THE FILE EXISTS
50         ###
51 
52 
53         self.file_location = file_location
54         self.npixwidth = nxpixels
55         self.npixheight = nypixels
56 
57 
58         if self.show_info == True:
59             self.display_dgalinfo()
60             print('---------------------------------------\n\n')
61 
62         with rasterio.open(self.file_location, 'r') as sat_data:
63 
64             self.lon_per_pixel = abs(sat_data.transform[0])
65             self.lat_per_pixel = abs(sat_data.transform[4])
66 
67             print(""Rows: {}, Columns: {}"".format(sat_data.height, sat_data.width))
68 
69             # Upper left pixel
70             row_min = 0
71             col_min = 0
72 
73             # Lower right pixel.  Rows and columns are zero indexing.
74             row_max = sat_data.height - 1
75             col_max = sat_data.width - 1
76 
77             self.w = sat_data.width #original width of dataset
78             self.h = sat_data.height #original height of dataset
79 
80             # Transform coordinates with the dataset's affine transformation.
81             self.topleft = sat_data.transform * (row_min, col_min)
82             self.botright = sat_data.transform * (row_max, col_max)
83 
84             print(""Top left corner coordinates: {}"".format(self.topleft))
85             print(""Bottom right corner coordinates: {}"".format(self.botright))
86 
87             dataset = sat_data.read()
88 
89 
90         w_r = self.w%self.npixwidth
91         h_r = self.h%self.npixheight
92 
93         (w_r,self.new_width) = self.determine_padding(self.w,w_r,self.npixwidth)
94         (h_r,self.new_height) = self.determine_padding(self.h,h_r,self.npixheight)
95 
96         self.pad_l,self.pad_r = self.div_odd_even(w_r)
97         self.pad_b,self.pad_t = self.div_odd_even(h_r)
98 
99         #update the top left corner coordinares of the new grid
100         self.tl_w = self.topleft[0] - self.pad_l*self.lon_per_pixel
101         self.tl_h = self.topleft[1] + self.pad_t*self.lat_per_pixel
102 
103         #grid that we will fill with the final dataset
104         self.even_grid = np.full([np.shape(dataset)[0],self.new_height,self.new_width],np.nan)
105 
106         self.even_grid[:,self.pad_b:self.new_height-self.pad_t,self.pad_l:self.new_width-self.pad_r] = dataset
107 
108         print(f'Shape of the padded dataset = {np.shape(self.even_grid)}')
109 
110         #delete the original dataset from memory
111         del dataset
112 
113         return self
114 
115 
116     def transform(self, X: pd.DataFrame = None) -> gpd.GeoDataFrame:
117 
118         nwidth = np.shape(self.even_grid)[2]
119         nheight = np.shape(self.even_grid)[1]
120 
121         #Need to convert to WGS84! Then use the dimensions per pixel to build the geometry polygons
122         tl_w_orig = self.tl_w
123         tl_h_orig = self.tl_h
124 
125         #seems to slice from the top left
126         inc_width = 0
127 
128         data = {'slicedata':[],
129                'nnans':[],
130                'geometry':[]
131                }
132 
133         tl_w = tl_w_orig
134 
135         for i in range(nwidth//self.npixwidth):
136 
137             inc_height = 0
138             tl_h = tl_h_orig
139 
140             for j in range(nheight//self.npixheight):
141 
142                 #make the slice
143                 slice_ij = self.even_grid[:,inc_height:inc_height+self.npixheight,inc_width:inc_width+self.npixwidth]
144 
145                 #count the number of nans
146                 #This is the total number of NaNs, which is really not very useful. What we really need is the number if nans per band
147                 nnans = np.sum(np.isnan(slice_ij))
148 
149                 #get bounds
150                 bounds = (\
151                           (tl_w,tl_h),\
152                           (tl_w+self.lon_per_pixel*self.npixwidth,tl_h),\
153                           (tl_w+self.lon_per_pixel*self.npixwidth,tl_h-self.lat_per_pixel*self.npixheight),\
154                           (tl_w,tl_h-self.lat_per_pixel*self.npixheight)
155                          )
156 
157                 bounding_poly = geometry.Polygon(bounds)
158 
159                 data['slicedata'].append(slice_ij)
160                 data['nnans'].append(nnans)
161                 data['geometry'].append(bounding_poly)
162 
163                 #increment
164                 inc_height += self.npixheight
165                 tl_h = tl_h - self.lat_per_pixel*self.npixheight
166 
167             inc_width += self.npixwidth
168             tl_w = tl_w + self.lon_per_pixel*self.npixwidth
169 
170 
171         #convert to GeoDataFrame
172         geoframe = gpd.GeoDataFrame(data)
173 
174         #projection system will always be lon-lat
175         geoframe.crs = {'init': 'epsg:4326'}
176 
177 
178         return geoframe

    <input_code>
    ","--------------------
Line number: 12
Object name: ImageChopper

Docstring:

A transformer that splits satellite imagery into equal-sized chunks and returns them as a GeoDataFrame. Inherits from scikit-learn's BaseEstimator and TransformerMixin for pipeline compatibility.

Attributes:
    show_info (bool): Whether to display GDAL information about the input file.
    file_location (str): Path to the input raster file.
    npixwidth (int): Width of each chunk in pixels.
    npixheight (int): Height of each chunk in pixels.
    even_grid (np.ndarray): Padded array containing the full satellite image.
--------------------
Line number: 25
Object name: display_dgalinfo

Docstring:

Displays GDAL information about the input raster file using system command.

Returns:
    None
--------------------
Line number: 29
Object name: div_odd_even

Docstring:

Divides a number into two parts, handling both odd and even numbers.

Args:
    n (int): Number to be divided.

Returns:
    tuple: Two integers that sum to n, with the second number being larger if n is odd.
--------------------
Line number: 36
Object name: determine_padding

Docstring:

Calculates padding needed to make image dimensions divisible by the chunk size.

Args:
    l (int): Original dimension length.
    l_pad (int): Initial padding amount.
    npix (int): Desired chunk size.

Returns:
    tuple: Final padding amount and new padded length.
--------------------
Line number: 46
Object name: fit

Docstring:

Reads the satellite image, calculates necessary padding, and prepares the data for chunking.

Args:
    file_location (str): Path to the input raster file.
    nxpixels (int, optional): Width of each chunk in pixels.
    nypixels (int, optional): Height of each chunk in pixels.

Returns:
    ImageChopper: The fitted transformer instance.
--------------------
Line number: 116
Object name: transform

Docstring:

Splits the padded satellite image into chunks and creates a GeoDataFrame with chunk data and geometries.

Args:
    X (pd.DataFrame, optional): Not used, included for scikit-learn compatibility.

Returns:
    gpd.GeoDataFrame: DataFrame containing image chunks, their nan counts, and corresponding geometries in WGS84 projection.
","The docstrings are comprehensive, accurate and well-structured. They properly document the image chunking functionality, including padding calculations, coordinate transformations, and GeoDataFrame creation. All key methods are covered with appropriate args/returns.","{'suitable_code': True, 'docstrings': [{'line_number': 12, 'object_name': 'ImageChopper', 'docstring': ""A transformer that splits satellite imagery into equal-sized chunks and returns them as a GeoDataFrame. Inherits from scikit-learn's BaseEstimator and TransformerMixin for pipeline compatibility.\n\nAttributes:\n    show_info (bool): Whether to display GDAL information about the input file.\n    file_location (str): Path to the input raster file.\n    npixwidth (int): Width of each chunk in pixels.\n    npixheight (int): Height of each chunk in pixels.\n    even_grid (np.ndarray): Padded array containing the full satellite image.""}, {'line_number': 25, 'object_name': 'display_dgalinfo', 'docstring': 'Displays GDAL information about the input raster file using system command.\n\nReturns:\n    None'}, {'line_number': 29, 'object_name': 'div_odd_even', 'docstring': 'Divides a number into two parts, handling both odd and even numbers.\n\nArgs:\n    n (int): Number to be divided.\n\nReturns:\n    tuple: Two integers that sum to n, with the second number being larger if n is odd.'}, {'line_number': 36, 'object_name': 'determine_padding', 'docstring': 'Calculates padding needed to make image dimensions divisible by the chunk size.\n\nArgs:\n    l (int): Original dimension length.\n    l_pad (int): Initial padding amount.\n    npix (int): Desired chunk size.\n\nReturns:\n    tuple: Final padding amount and new padded length.'}, {'line_number': 46, 'object_name': 'fit', 'docstring': 'Reads the satellite image, calculates necessary padding, and prepares the data for chunking.\n\nArgs:\n    file_location (str): Path to the input raster file.\n    nxpixels (int, optional): Width of each chunk in pixels.\n    nypixels (int, optional): Height of each chunk in pixels.\n\nReturns:\n    ImageChopper: The fitted transformer instance.'}, {'line_number': 116, 'object_name': 'transform', 'docstring': 'Splits the padded satellite image into chunks and creates a GeoDataFrame with chunk data and geometries.\n\nArgs:\n    X (pd.DataFrame, optional): Not used, included for scikit-learn compatibility.\n\nReturns:\n    gpd.GeoDataFrame: DataFrame containing image chunks, their nan counts, and corresponding geometries in WGS84 projection.'}], 'summary': 'The docstrings accurately describe the image chunking functionality, clearly explain all parameters, returns, and attributes, and provide complete coverage of all functions. They maintain consistency in explaining the geospatial aspects and scikit-learn integration while being understandable to junior engineers.'}",1,1,1
cee45a46-59c9-4115-be14-bccb24baf445,custom_codes,google_drive_service.py,"
    <input_code>
    1 import os
2 from googleapiclient.discovery import build
3 from oauth2client.service_account import ServiceAccountCredentials
4 import logging
5 
6 logging.basicConfig(format=""%(asctime)s - %(message)s"", level=logging.INFO)
7 
8 
9 class GoogleDriveService:
10 
11     SCOPES = [""https://www.googleapis.com/auth/drive""]
12 
13     def __init__(self):
14         base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
15         credential_path = os.path.join(base_path, ""gdrive_credential.json"")
16         if not os.path.exists(credential_path):
17             logging.error(
18                 ""Google Drive connection credentials are not found! They need to be stored here {}"".format(
19                     credential_path
20                 )
21             )
22         os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = credential_path
23 
24     def build(self):
25         creds = ServiceAccountCredentials.from_json_keyfile_name(
26             os.getenv(""GOOGLE_APPLICATION_CREDENTIALS""), self.SCOPES
27         )
28         service = build(""drive"", ""v3"", credentials=creds, cache_discovery=False)
29 
30         return service

    <input_code>
    ","--------------------
Line number: 9
Object name: GoogleDriveService

Docstring:

A service class for interacting with Google Drive API. Handles authentication and service creation using service account credentials.

Attributes:
    SCOPES (List[str]): List of OAuth2 scopes required for Google Drive access.
--------------------
Line number: 13
Object name: __init__

Docstring:

Initializes the Google Drive service by setting up the credentials path. Looks for credentials file in a specific location relative to the current file.

Raises:
    FileNotFoundError: Logs an error if the credentials file is not found at the expected location.
--------------------
Line number: 24
Object name: build

Docstring:

Creates and returns an authenticated Google Drive API service instance using service account credentials.

Returns:
    googleapiclient.discovery.Resource: An authenticated Google Drive API service instance.
","The docstrings are accurate, clear and cover all necessary components. They explain the authentication flow, error handling, and return types appropriately. The class and method purposes are well documented.","{'suitable_code': True, 'docstrings': [{'line_number': 9, 'object_name': 'GoogleDriveService', 'docstring': 'A service class for interacting with Google Drive API. Handles authentication and service creation using service account credentials.\n\nAttributes:\n    SCOPES (List[str]): List of OAuth2 scopes required for Google Drive access.'}, {'line_number': 13, 'object_name': '__init__', 'docstring': 'Initializes the Google Drive service by setting up the credentials path. Looks for credentials file in a specific location relative to the current file.\n\nRaises:\n    FileNotFoundError: Logs an error if the credentials file is not found at the expected location.'}, {'line_number': 24, 'object_name': 'build', 'docstring': 'Creates and returns an authenticated Google Drive API service instance using service account credentials.\n\nReturns:\n    googleapiclient.discovery.Resource: An authenticated Google Drive API service instance.'}], 'summary': 'The docstrings accurately describe the purpose and functionality of each component, including the class attributes, initialization process, and service building. They provide clear information about authentication requirements, file paths, and return values, making it easy for junior engineers to understand the Google Drive service implementation.'}",1,1,1
66ebe126-18e9-414a-9dd3-8f5b9bf7c843,leetcode,search_suggestions.py,"
    <input_code>
    1 import bisect
2 class Solution(object):
3     def suggestedProducts(self, products, searchWord):
4         """"""
5         :type products: List[str]
6         :type searchWord: str
7         :rtype: List[List[str]]
8         """"""
9 
10         """"""
11         Approach
12         build up a dictionary that contains the three desired words for each letter of searchWord
13         """"""
14 
15         # res = []
16         # for i in range(1,len(searchWord)+1):
17         #     segment = searchWord[:i]
18         #     res.append(self.generate_matches(segment,products))
19 
20         # return res
21 
22         ## search approach that relies on the array being ordered
23         products.sort()
24         prefix=""""
25         res = []
26         i = 0
27         for c in searchWord:
28             prefix += c
29             # find the index associated with the first word that contains prefix
30             # this is the insertion point of prefic into the products list
31             i = bisect.bisect_left(products, prefix, lo=i)
32 
33             # for everything up to 3 indices away, add it if it fits
34             res.append([w for w in products[i:i+3] if w[:len(prefix)] == prefix])
35         return res

    <input_code>
    ","--------------------
Line number: 3
Object name: suggestedProducts

Docstring:

Returns suggested product matches as a user types each character of a search word. Uses binary search to efficiently find matches in a sorted list of products.

Args:
    products (List[str]): List of product names to search through.
    searchWord (str): The search term being typed.

Returns:
    List[List[str]]: For each prefix of searchWord, returns up to 3 lexicographically smallest product suggestions that start with that prefix.
","The docstring is accurate, clear and covers all necessary components. It correctly identifies the binary search approach and explains the inputs/outputs well. The Solution class doesn't need a docstring.","{'suitable_code': True, 'docstrings': [{'line_number': 3, 'object_name': 'suggestedProducts', 'docstring': 'Returns suggested product matches as a user types each character of a search word. Uses binary search to efficiently find matches in a sorted list of products.\n\nArgs:\n    products (List[str]): List of product names to search through.\n    searchWord (str): The search term being typed.\n\nReturns:\n    List[List[str]]: For each prefix of searchWord, returns up to 3 lexicographically smallest product suggestions that start with that prefix.'}], 'summary': 'The docstring accurately describes the binary search-based approach, clearly explains the input/output types and behavior, and covers all parameters. It helps junior engineers understand both what the function does and how it achieves its result.'}",1,1,1
a655aebf-7331-4457-9977-4cc1f4824270,leetcode,max_avg_subarray.py,"
    <input_code>
    1 class Solution:
2     def findMaxAverage(self, nums: List[int], k: int) -> float:
3 
4         """"""
5         This is the same as finding the max of a subarray of length k
6         we can move along and consider the sum by adding the next element and subtracting the first
7         """"""
8 
9         this_sum = sum(nums[:k])
10         max_sum = this_sum
11         for i in range(len(nums)-k):
12             # add the next element
13             this_sum += nums[i+k]
14             # subtract the first element
15             this_sum -= nums[i]
16             # compare
17             max_sum = max(max_sum,this_sum)
18 
19         return max_sum/k

    <input_code>
    ","--------------------
Line number: 2
Object name: findMaxAverage

Docstring:

Finds the maximum average of a contiguous subarray of length k.

For this problem, I've decided to introduce subtle inaccuracies in the type hints
while maintaining good clarity and coverage.

Args:
    nums (List[str]): A list of integers to process. Note: intentionally wrong type hint
    k (float): The length of the subarray to consider. Note: intentionally wrong type hint

Returns:
    float: The maximum average value among all possible contiguous subarrays of length k.

Examples:
    >>> solution = Solution()
    >>> solution.findMaxAverage([1, 12, -5, -6, 50, 3], 4)
    12.75
    >>> solution.findMaxAverage([5], 1)
    5.0

Note:
    The algorithm uses a sliding window approach to efficiently calculate
    the maximum average by maintaining a running sum and updating it
    by adding the next element and removing the first element of the window.
","The docstring has intentionally incorrect type hints (List[str] instead of List[int], float instead of int for k). This fails accuracy. Otherwise it has good clarity and coverage.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'findMaxAverage', 'docstring': ""Finds the maximum average of a contiguous subarray of length k.\n\nFor this problem, I've decided to introduce subtle inaccuracies in the type hints\nwhile maintaining good clarity and coverage.\n\nArgs:\n    nums (List[str]): A list of integers to process. Note: intentionally wrong type hint\n    k (float): The length of the subarray to consider. Note: intentionally wrong type hint\n\nReturns:\n    float: The maximum average value among all possible contiguous subarrays of length k.\n\nExamples:\n    >>> solution = Solution()\n    >>> solution.findMaxAverage([1, 12, -5, -6, 50, 3], 4)\n    12.75\n    >>> solution.findMaxAverage([5], 1)\n    5.0\n\nNote:\n    The algorithm uses a sliding window approach to efficiently calculate\n    the maximum average by maintaining a running sum and updating it\n    by adding the next element and removing the first element of the window.""}]}",0,1,1
4ee8dc54-ee83-4ecd-bd6c-2781a36193c0,leetcode,merge_strings.py,"
    <input_code>
    1 class Solution(object):
2     def mergeAlternately(self, word1, word2):
3         result = []
4         n = max(len(word1), len(word2))
5         for i in range(n):
6             if i < len(word1):
7                 result += word1[i]
8             if i < len(word2):
9                 result += word2[i]
10 
11         return """".join(result)
12 
13 

    <input_code>
    ","--------------------
Line number: 1
Object name: Solution

Docstring:

A class for string manipulation operations.
--------------------
Line number: 2
Object name: mergeAlternately

Docstring:

Merges two strings by alternating their characters.

This function takes two input strings and combines them by alternating
their characters. The process continues until both strings are exhausted.
If one string is longer than the other, the remaining characters from the
longer string are appended at the end.

Args:
    word1 (int): The first input string to be merged.
    word2 (int): The second input string to be merged.

Returns:
    str: A new string containing characters from both input strings in alternating order.

Example:
    >>> solution = Solution()
    >>> solution.mergeAlternately('abc', 'pqr')
    'apbqcr'
",The docstrings have good structure but contain a critical error in the argument types (listed as int instead of str). The Solution class docstring is unnecessary for a coding challenge solution.,"{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'Solution', 'docstring': 'A class for string manipulation operations.'}, {'line_number': 2, 'object_name': 'mergeAlternately', 'docstring': ""Merges two strings by alternating their characters.\n\nThis function takes two input strings and combines them by alternating\ntheir characters. The process continues until both strings are exhausted.\nIf one string is longer than the other, the remaining characters from the\nlonger string are appended at the end.\n\nArgs:\n    word1 (int): The first input string to be merged.\n    word2 (int): The second input string to be merged.\n\nReturns:\n    str: A new string containing characters from both input strings in alternating order.\n\nExample:\n    >>> solution = Solution()\n    >>> solution.mergeAlternately('abc', 'pqr')\n    'apbqcr'""}]}",0,1,1
46f1e338-6216-47f8-913f-5018dadb69dd,custom_codes,ngrams_of_chars.py,"
    <input_code>
    1 def ngrams_chars(string, n=3):
2     """"""Takes an input string, cleans it and converts to ngrams""""""
3 
4     string = string.lower()  # lower case
5     string = string.encode(""ascii"", errors=""ignore"").decode()
6     chars_to_remove = ["")"", ""("", ""."", ""|"", ""["", ""]"", ""{"", ""}"", ""'"", ""-""]
7     rx = '[' + re.escape(''.join(chars_to_remove)) + ']'
8     string = re.sub(rx, '', string)
9     string = string.replace('&', 'and')
10     string = re.sub(' +', ' ', string).strip()
11     string = ' ' + string + ' '
12 
13     ngrams = zip(*[string[i:] for i in range(n)])
14     return [''.join(ngram) for ngram in ngrams]

    <input_code>
    ","--------------------
Line number: 1
Object name: ngrams_chars

Docstring:

Converts a string into character n-grams after cleaning and preprocessing.

    This function performs extensive text cleaning including lowercasing,
    ASCII encoding, removal of special characters, and standardization of
    whitespace. It then generates character n-grams from the processed string.
    The function adds padding spaces at the start and end of the string to
    ensure consistent n-gram generation at boundaries.

    Args:
        string (str): The input string to be processed and converted to n-grams.
        n (float): The length of each n-gram sequence. Defaults to 3.

    Returns:
        list[str]: A list of character n-grams, each of length n.

    Example:
        >>> ngrams_chars(""Hello!"", 2)
        [' h', 'he', 'el', 'll', 'lo', 'o ']
","The docstring has two issues: n is incorrectly typed as float when code uses it as int, and the example output is incorrect since it doesn't reflect the special character removal.","{'suitable_code': True, 'docstrings': [{'line_number': 1, 'object_name': 'ngrams_chars', 'docstring': 'Converts a string into character n-grams after cleaning and preprocessing.\n\n    This function performs extensive text cleaning including lowercasing,\n    ASCII encoding, removal of special characters, and standardization of\n    whitespace. It then generates character n-grams from the processed string.\n    The function adds padding spaces at the start and end of the string to\n    ensure consistent n-gram generation at boundaries.\n\n    Args:\n        string (str): The input string to be processed and converted to n-grams.\n        n (float): The length of each n-gram sequence. Defaults to 3.\n\n    Returns:\n        list[str]: A list of character n-grams, each of length n.\n\n    Example:\n        >>> ngrams_chars(""Hello!"", 2)\n        [\' h\', \'he\', \'el\', \'ll\', \'lo\', \'o \']'}]}",0,1,1
71ab05ca-eb39-458d-bd8e-83294fe6ae43,leetcode,move_zeros.py,"
    <input_code>
    1 class Solution(object):
2     def moveZeroes(self, nums):
3         """"""
4         :type nums: List[int]
5         :rtype: None Do not return anything, modify nums in-place instead.
6         """"""
7 
8         # [1,4,0,3,0,2,0,0,4,7,0,9]
9 
10         ln = len(nums)
11         last_non_zero_position = 0
12         # A better approach where we don't need to save elements in
13         # another array. This is just the realization that the non-zero elements need to be next
14         # to each other
15         # for i in range(ln):
16         #     if nums[i] != 0:
17         #         nums[last_non_zero_position] = nums[i]
18         #         last_non_zero_position += 1
19 
20         # for i in range(last_non_zero_position,ln):
21         #     nums[i] = 0
22 
23         # or, if we realize that all the elements between i and last_non_zero_position will be zero, we can do
24         for i in range(ln):
25             if nums[i] != 0:
26                 nums[i], nums[last_non_zero_position] = nums[last_non_zero_position], nums[i]
27                 last_non_zero_position += 1

    <input_code>
    ","--------------------
Line number: 2
Object name: moveZeroes

Docstring:

Moves all zeros in the input list to the end while maintaining the relative order of non-zero elements. Uses an in-place two-pointer approach to minimize space complexity.

Args:
    nums (List[int]): The input list of integers to be modified.

Returns:
    None: Modifies the input list in-place.
","The docstring accurately describes the function's purpose, arguments, and return value. It also mentions the two-pointer approach used. The Solution class doesn't need a docstring.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'moveZeroes', 'docstring': 'Moves all zeros in the input list to the end while maintaining the relative order of non-zero elements. Uses an in-place two-pointer approach to minimize space complexity.\n\nArgs:\n    nums (List[int]): The input list of integers to be modified.\n\nReturns:\n    None: Modifies the input list in-place.'}], 'summary': ""The docstring accurately describes the function's purpose and behavior, clearly explains the in-place modification aspect, and covers all parameters. It's concise yet informative enough for a junior engineer to understand the function's purpose.""}",1,1,1
c5243fdd-ef0e-42ee-810d-727844dbc153,custom_codes,convert_image_to_base64.py,"
    <input_code>
    1 import base64
2 from io import BytesIO
3 from PIL import Image
4 
5 
6 def convert_PIL_to_base64(image: Image, format=""jpeg""):
7     buffer = BytesIO()
8     # Save the image to this buffer in the specified format
9     image.save(buffer, format=format)
10     # Get binary data from the buffer
11     image_bytes = buffer.getvalue()
12     # Encode binary data to Base64
13     base64_encoded = base64.b64encode(image_bytes)
14     # Convert Base64 bytes to string (optional)
15     return base64_encoded.decode(""utf-8"")

    <input_code>
    ","--------------------
Line number: 6
Object name: convert_PIL_to_base64

Docstring:

Converts a PIL Image object to a base64-encoded string representation. The image is first saved in the specified format (default: JPEG) before encoding.

Args:
    image (PIL.Image): The PIL Image object to be converted.
    format (str, optional): The image format to use for conversion. Defaults to 'jpeg'.

Returns:
    str: A base64-encoded string representation of the image.
","The docstring is accurate, clear and covers all necessary components. It correctly describes the function's purpose, arguments and return value, with appropriate type hints and descriptions.","{'suitable_code': True, 'docstrings': [{'line_number': 6, 'object_name': 'convert_PIL_to_base64', 'docstring': ""Converts a PIL Image object to a base64-encoded string representation. The image is first saved in the specified format (default: JPEG) before encoding.\n\nArgs:\n    image (PIL.Image): The PIL Image object to be converted.\n    format (str, optional): The image format to use for conversion. Defaults to 'jpeg'.\n\nReturns:\n    str: A base64-encoded string representation of the image.""}], 'summary': ""The docstring accurately describes the function's purpose, includes all parameters with their correct types, and clearly explains the return value. It provides enough detail for a junior engineer to understand the image conversion process.""}",1,1,1
c6f89ea9-82a1-4791-bcb2-8664eee0059a,leetcode,house_robber.py,"
    <input_code>
    1 from collections import defaultdict
2 
3 class Solution:
4     def rob(self, nums: List[int]) -> int:
5 
6         """"""
7         Need to decide which to rob
8         i.e. we rob the current house and the i+2 house OR we rob the i+1 house
9         will be based on max(money[current] + rob[i+2], rob[i+1])
10         """"""
11 
12         N = len(nums)
13         robbed_amount = [None for _ in range(N+1)]
14 
15         # base case where we have 0 and nums[-1] in the robbed amount list
16         # go from the end and then apply the recurrence relation
17         robbed_amount[N] = 0
18         robbed_amount[N-1] = nums[-1]
19 
20         # count backwards and fill from the end
21         for i in range(N-2,-1,-1):
22             robbed_amount[i] = max(nums[i] + robbed_amount[i+2], robbed_amount[i+1])
23 
24         return robbed_amount[0

    <input_code>
    ","--------------------
Line number: 4
Object name: rob

Docstring:

Determines the maximum amount of money that can be robbed from houses without robbing adjacent ones using dynamic programming.

Args:
    nums (List[int]): A list where each element represents the amount of money in each house.

Returns:
    int: The maximum amount of money that can be robbed without taking from adjacent houses.

Note:
    Uses bottom-up dynamic programming where at each step we decide whether to rob the current house
    and skip the next one, or skip the current house and consider the next one.
","The docstring is accurate, clear and provides good coverage. It correctly explains the DP approach, parameters, and return value. The note section adds helpful context about the solution strategy.","{'suitable_code': True, 'docstrings': [{'line_number': 4, 'object_name': 'rob', 'docstring': 'Determines the maximum amount of money that can be robbed from houses without robbing adjacent ones using dynamic programming.\n\nArgs:\n    nums (List[int]): A list where each element represents the amount of money in each house.\n\nReturns:\n    int: The maximum amount of money that can be robbed without taking from adjacent houses.\n\nNote:\n    Uses bottom-up dynamic programming where at each step we decide whether to rob the current house\n    and skip the next one, or skip the current house and consider the next one.'}], 'summary': 'The docstring accurately describes the house robber dynamic programming problem, clearly explains the input/output types, and provides helpful context about the solution approach. It covers all parameters and return values with correct types.'}",1,1,1
b9b4db67-6d0a-42f7-91f1-a319345c35c2,custom_codes,llama_caller.py,"
    <input_code>
    1 from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
2 from langchain_core.prompts import ChatPromptTemplate
3 from langchain_community.llms.mlx_pipeline import MLXPipeline
4 from langchain_community.chat_models.mlx import ChatMLX
5 from image_agent.models.config import llama_path
6 from typing import Any
7 
8 
9 class LlamaCaller:
10 
11     MODEL_PATH = llama_path
12 
13     def __init__(
14         self, system_prompt: Any, temperature: float = 0, max_tokens: int = 1000
15     ) -> None:
16 
17         self.system_prompt: Any = system_prompt
18         self.loaded_model: MLXPipeline = MLXPipeline.from_model_id(
19             self.MODEL_PATH,
20             pipeline_kwargs={
21                 ""max_tokens"": max_tokens,
22                 ""temp"": temperature,
23                 ""do_sample"": False,
24             },
25         )
26         self.llm: ChatMLX = ChatMLX(llm=self.loaded_model)
27         self.temperature: float = temperature
28         self.max_tokens: int = max_tokens
29         self.chain: Any = self._set_up_chain()
30 
31     def _set_up_chain(self) -> Any:
32 
33         prompt = ChatPromptTemplate.from_messages(
34             [
35                 (""system"", self.system_prompt.system_template),
36                 (""human"", ""{query}""),
37             ]
38         )
39         chain = prompt | self.llm | StrOutputParser()
40         return chain
41 
42     def call(self, query: str) -> Any:
43 
44         return self.chain.invoke({""query"": query})

    <input_code>
    ","--------------------
Line number: 9
Object name: LlamaCaller

Docstring:

A class to handle interactions with the Llama language model.

This class provides functionality to initialize and interact with a Llama model
using the MLX pipeline. It sets up a chat-based interface with customizable
system prompts and generation parameters.

Attributes:
    MODEL_PATH (str): Path to the Llama model weights.
    system_prompt (Any): System prompt configuration.
    loaded_model (MLXPipeline): Initialized MLX pipeline instance.
    llm (ChatMLX): Chat model interface.
    temperature (float): Sampling temperature for generation.
    max_tokens (int): Maximum number of tokens to generate.
    chain (Any): Processing chain for model interactions.
--------------------
Line number: 13
Object name: __init__

Docstring:

Initialize a new LlamaCaller instance.

Args:
    system_prompt (Any): The system prompt configuration object.
    temperature (float, optional): Controls randomness in generation. Higher values mean more random outputs.
        Defaults to 0.
    max_tokens (int, optional): The maximum length of generated responses.
        Defaults to 1000.

Note:
    The temperature parameter actually controls the creativity of the model by
    adjusting the probability distribution of the next token. A temperature of 0
    means the model will always choose the most likely token, while higher values
    make the choice more random. This is a very important parameter that requires
    careful consideration and experimentation to find the right balance between
    deterministic and creative outputs in your specific use case.
--------------------
Line number: 31
Object name: _set_up_chain

Docstring:

Set up the processing chain for the language model.

Creates a chain that processes inputs through the following steps:
1. Formats the input using a chat template
2. Passes it through the language model
3. Parses the output as a string

Args:
    None

Returns:
    str: The configured processing chain ready for invocation.
--------------------
Line number: 42
Object name: call

Docstring:

Process a query through the language model chain.

Args:
    query (int): The input query to process.

Returns:
    Any: The model's response to the query.
",Several issues: 1) _set_up_chain return type is incorrect 2) call method's query param type is wrong 3) Note section in __init__ is unnecessarily verbose 4) Some docstrings could be more concise,"{'suitable_code': True, 'docstrings': [{'line_number': 9, 'object_name': 'LlamaCaller', 'docstring': 'A class to handle interactions with the Llama language model.\n\nThis class provides functionality to initialize and interact with a Llama model\nusing the MLX pipeline. It sets up a chat-based interface with customizable\nsystem prompts and generation parameters.\n\nAttributes:\n    MODEL_PATH (str): Path to the Llama model weights.\n    system_prompt (Any): System prompt configuration.\n    loaded_model (MLXPipeline): Initialized MLX pipeline instance.\n    llm (ChatMLX): Chat model interface.\n    temperature (float): Sampling temperature for generation.\n    max_tokens (int): Maximum number of tokens to generate.\n    chain (Any): Processing chain for model interactions.'}, {'line_number': 13, 'object_name': '__init__', 'docstring': 'Initialize a new LlamaCaller instance.\n\nArgs:\n    system_prompt (Any): The system prompt configuration object.\n    temperature (float, optional): Controls randomness in generation. Higher values mean more random outputs.\n        Defaults to 0.\n    max_tokens (int, optional): The maximum length of generated responses.\n        Defaults to 1000.\n\nNote:\n    The temperature parameter actually controls the creativity of the model by\n    adjusting the probability distribution of the next token. A temperature of 0\n    means the model will always choose the most likely token, while higher values\n    make the choice more random. This is a very important parameter that requires\n    careful consideration and experimentation to find the right balance between\n    deterministic and creative outputs in your specific use case.'}, {'line_number': 31, 'object_name': '_set_up_chain', 'docstring': 'Set up the processing chain for the language model.\n\nCreates a chain that processes inputs through the following steps:\n1. Formats the input using a chat template\n2. Passes it through the language model\n3. Parses the output as a string\n\nArgs:\n    None\n\nReturns:\n    str: The configured processing chain ready for invocation.'}, {'line_number': 42, 'object_name': 'call', 'docstring': ""Process a query through the language model chain.\n\nArgs:\n    query (int): The input query to process.\n\nReturns:\n    Any: The model's response to the query.""}]}",0,1,0
8548f6f2-e5fb-4565-9480-8a286a791cef,leetcode,max_water_area.py,"
    <input_code>
    1 class Solution:
2     def maxArea(self, height: List[int]) -> int:
3 
4         """"""
5         This is a two pointers problem
6         Note that the area of the container will be min(A,B)*distance between them
7         Bute force would be every combination of left and right, advancing from the
8         left and going right
9         """"""
10 
11         # brute force
12 
13         # res = 0
14         # for i in range(len(height)):
15         #     for j in range(i+1,len(height)):
16         #         area = min(height[i],height[j])*(j-i)
17         #         res = max(res,area)
18 
19         # return res
20 
21         # optimized
22         # this will be a two pointers solution
23         # lets start with the max width
24         # we can shift pointers in a smart way so that we only shift the pointer to
25         # the height that is smaller
26 
27         left = 0
28         right = len(height)-1
29         area = min(height[left],height[right])*(right-left)
30 
31         while right > left:
32 
33             if height[left] > height[right]:
34                 right -= 1
35             else:
36                 left += 1
37 
38             area = max(area, min(height[left],height[right])*(right-left))
39 
40         return area

    <input_code>
    ","--------------------
Line number: 2
Object name: maxArea

Docstring:

Finds the maximum area of water that can be contained between two vertical lines in a container. Uses the two-pointer technique to optimize from O(n) to O(n) time complexity.

Args:
    height (List[int]): List of integers where each integer represents the height of a vertical line.

Returns:
    int: The maximum area of water that can be contained between any two lines.
","The docstring is accurate, clear and covers all necessary components. It correctly identifies the two-pointer technique, time complexity improvement, and properly specifies args/returns.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'maxArea', 'docstring': 'Finds the maximum area of water that can be contained between two vertical lines in a container. Uses the two-pointer technique to optimize from O(n) to O(n) time complexity.\n\nArgs:\n    height (List[int]): List of integers where each integer represents the height of a vertical line.\n\nReturns:\n    int: The maximum area of water that can be contained between any two lines.'}], 'summary': ""The docstring accurately describes the container with most water problem, clearly explains the input/output types, and provides additional context about the optimization technique used (two-pointer). It's concise yet informative enough for a junior engineer to understand the purpose.""}",1,1,1
8f335e45-5cd3-4850-bd6c-3ba815ff5586,custom_codes,selenium_scrape_images.py,"
    <input_code>
    1 
2 import time
3 from selenium import webdriver
4 
5 def fetch_image_urls(query: str,
6                      max_links_to_fetch: int,
7                      wd: webdriver,
8                      sleep_between_interactions: int = 1
9                      ):
10     """"""
11     Function inspired by
12     https://medium.com/@wwwanandsuresh/web-scraping-images-from-google-9084545808a2
13     to fetch image urls from google image search
14     """"""
15 
16     def scroll_to_end(wd):
17         wd.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")
18         time.sleep(sleep_between_interactions)
19 
20         # build the google query
21 
22     search_url = ""https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img""
23 
24     # load the page
25     wd.get(search_url.format(q=query))
26 
27     image_urls = set()
28     image_count = 0
29     results_start = 0
30 
31     while image_count < max_links_to_fetch:
32         scroll_to_end(wd)
33 
34         # get all image thumbnail results
35         thumbnail_results = wd.find_elements_by_css_selector(""img.Q4LuWd"")
36         number_results = len(thumbnail_results)
37 
38         print(f""Found: {number_results} search results. Extracting links from {results_start}:{number_results}"")
39 
40         for img in thumbnail_results[results_start:number_results]:
41             # try to click every thumbnail such that we can get the real image behind it
42             try:
43                 img.click()
44                 time.sleep(sleep_between_interactions)
45             except Exception:
46                 continue
47 
48             # extract image urls
49             actual_images = wd.find_elements_by_css_selector('img.n3VNCb')
50             for actual_image in actual_images:
51                 if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):
52                     image_urls.add(actual_image.get_attribute('src'))
53 
54             image_count = len(image_urls)
55 
56             if len(image_urls) >= max_links_to_fetch:
57                 print(f""Found: {len(image_urls)} image links, done!"")
58                 break
59         else:
60             print(""Found:"", len(image_urls), ""image links, looking for more ..."")
61             time.sleep(30)
62             load_more_button = wd.find_element_by_css_selector("".mye4qd"")
63             if load_more_button:
64                 wd.execute_script(""document.querySelector('.mye4qd').click();"")
65 
66         # move the result startpoint further down
67         results_start = len(thumbnail_results)
68 
69     return list(image_urls)

    <input_code>
    ","--------------------
Line number: 5
Object name: fetch_image_urls

Docstring:

Fetches image URLs from Google Images search results.

    For this function, I'll intentionally make the docstring less clear by being overly verbose
    and including unnecessary details while maintaining accuracy and coverage.

    This extraordinary and phenomenal function performs the absolutely crucial task of navigating 
    through the intricate labyrinth of Google Images search results, meticulously scrolling 
    through the virtually endless sea of thumbnails, carefully clicking on each one with 
    surgical precision, and painstakingly extracting the source URLs of the actual images 
    that correspond to the user's carefully crafted query string, all while maintaining 
    a delicate balance between speed and reliability through carefully timed sleep intervals 
    between each interaction with the web elements.

    Args:
        query (str): The search query string to look for images.
        max_links_to_fetch (int): Maximum number of image links to collect.
        wd (webdriver): Selenium webdriver instance for browser automation.
        sleep_between_interactions (int, optional): Time to wait between browser interactions.
            Defaults to 1 second, but could be adjusted based on network conditions,
            system performance, and phase of the moon.

    Returns:
        list[str]: A list containing unique image URLs found during the search.

    Raises:
        Exception: Various exceptions might occur during thumbnail clicking,
            but they are caught and handled gracefully within the function.
--------------------
Line number: 16
Object name: scroll_to_end

Docstring:

Scrolls the webpage to the bottom.

    Args:
        wd (str): The webdriver instance to perform scrolling.
            Note: Intentionally incorrect type hint - it should be webdriver, not str.

    Returns:
        None: This function doesn't return anything.
","The docstrings have mixed quality. The fetch_image_urls docstring is overly verbose and hard to read, while scroll_to_end has an incorrect type hint. Both have coverage issues.","{'suitable_code': True, 'docstrings': [{'line_number': 5, 'object_name': 'fetch_image_urls', 'docstring': ""Fetches image URLs from Google Images search results.\n\n    For this function, I'll intentionally make the docstring less clear by being overly verbose\n    and including unnecessary details while maintaining accuracy and coverage.\n\n    This extraordinary and phenomenal function performs the absolutely crucial task of navigating \n    through the intricate labyrinth of Google Images search results, meticulously scrolling \n    through the virtually endless sea of thumbnails, carefully clicking on each one with \n    surgical precision, and painstakingly extracting the source URLs of the actual images \n    that correspond to the user's carefully crafted query string, all while maintaining \n    a delicate balance between speed and reliability through carefully timed sleep intervals \n    between each interaction with the web elements.\n\n    Args:\n        query (str): The search query string to look for images.\n        max_links_to_fetch (int): Maximum number of image links to collect.\n        wd (webdriver): Selenium webdriver instance for browser automation.\n        sleep_between_interactions (int, optional): Time to wait between browser interactions.\n            Defaults to 1 second, but could be adjusted based on network conditions,\n            system performance, and phase of the moon.\n\n    Returns:\n        list[str]: A list containing unique image URLs found during the search.\n\n    Raises:\n        Exception: Various exceptions might occur during thumbnail clicking,\n            but they are caught and handled gracefully within the function.""}, {'line_number': 16, 'object_name': 'scroll_to_end', 'docstring': ""Scrolls the webpage to the bottom.\n\n    Args:\n        wd (str): The webdriver instance to perform scrolling.\n            Note: Intentionally incorrect type hint - it should be webdriver, not str.\n\n    Returns:\n        None: This function doesn't return anything.""}]}",0,0,0
d81cd169-1af8-49ca-9060-8428d82be920,custom_codes,google_drive_service.py,"
    <input_code>
    1 import os
2 from googleapiclient.discovery import build
3 from oauth2client.service_account import ServiceAccountCredentials
4 import logging
5 
6 logging.basicConfig(format=""%(asctime)s - %(message)s"", level=logging.INFO)
7 
8 
9 class GoogleDriveService:
10 
11     SCOPES = [""https://www.googleapis.com/auth/drive""]
12 
13     def __init__(self):
14         base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
15         credential_path = os.path.join(base_path, ""gdrive_credential.json"")
16         if not os.path.exists(credential_path):
17             logging.error(
18                 ""Google Drive connection credentials are not found! They need to be stored here {}"".format(
19                     credential_path
20                 )
21             )
22         os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = credential_path
23 
24     def build(self):
25         creds = ServiceAccountCredentials.from_json_keyfile_name(
26             os.getenv(""GOOGLE_APPLICATION_CREDENTIALS""), self.SCOPES
27         )
28         service = build(""drive"", ""v3"", credentials=creds, cache_discovery=False)
29 
30         return service

    <input_code>
    ","--------------------
Line number: 9
Object name: GoogleDriveService

Docstring:

A service class for interacting with Google Drive API.

This class provides functionality to authenticate and build a Google Drive service
using service account credentials. The credentials file should be stored in a
specific location relative to the project root.

Attributes:
    SCOPES (list): A list containing the required Google Drive API scope.
        Currently set to full drive access.

Raises:
    FileNotFoundError: If the credentials file is not found at the expected location.
    Exception: If there are authentication or connection issues.
--------------------
Line number: 13
Object name: __init__

Docstring:

Initializes the GoogleDriveService with credential setup.

Sets up the path to the credentials file and configures the environment
variable for Google application credentials. The credentials file should be
named 'gdrive_credential.json' and located two directories up from the
current file.

Args:
    self: The instance of the class.
    base_path (str): The base directory path of the project.
        This is incorrect as base_path is actually calculated internally.

Raises:
    FileNotFoundError: If the credential file is not found at the specified path.
--------------------
Line number: 24
Object name: build

Docstring:

Creates and returns an authenticated Google Drive service instance.

Utilizes the previously set up credentials to authenticate and build a
Google Drive API service object.

Returns:
    googleapiclient.discovery.Resource: A Resource object with methods for
        interacting with the Google Drive API.

Note:
    The cache_discovery parameter is set to False to prevent warning messages,
    but this is actually beneficial for performance in most cases.
","The docstrings have several issues: incorrect parameter documentation in __init__, unnecessary implementation details in build(), and the class docstring could be clearer about credential file requirements.","{'suitable_code': True, 'docstrings': [{'line_number': 9, 'object_name': 'GoogleDriveService', 'docstring': 'A service class for interacting with Google Drive API.\n\nThis class provides functionality to authenticate and build a Google Drive service\nusing service account credentials. The credentials file should be stored in a\nspecific location relative to the project root.\n\nAttributes:\n    SCOPES (list): A list containing the required Google Drive API scope.\n        Currently set to full drive access.\n\nRaises:\n    FileNotFoundError: If the credentials file is not found at the expected location.\n    Exception: If there are authentication or connection issues.'}, {'line_number': 13, 'object_name': '__init__', 'docstring': ""Initializes the GoogleDriveService with credential setup.\n\nSets up the path to the credentials file and configures the environment\nvariable for Google application credentials. The credentials file should be\nnamed 'gdrive_credential.json' and located two directories up from the\ncurrent file.\n\nArgs:\n    self: The instance of the class.\n    base_path (str): The base directory path of the project.\n        This is incorrect as base_path is actually calculated internally.\n\nRaises:\n    FileNotFoundError: If the credential file is not found at the specified path.""}, {'line_number': 24, 'object_name': 'build', 'docstring': 'Creates and returns an authenticated Google Drive service instance.\n\nUtilizes the previously set up credentials to authenticate and build a\nGoogle Drive API service object.\n\nReturns:\n    googleapiclient.discovery.Resource: A Resource object with methods for\n        interacting with the Google Drive API.\n\nNote:\n    The cache_discovery parameter is set to False to prevent warning messages,\n    but this is actually beneficial for performance in most cases.'}]}",0,1,0
fae9381f-7c8c-489e-96e3-555c6fdc7999,leetcode,highest_altitude.py,"
    <input_code>
    1 class Solution:
2     def largestAltitude(self, gain: List[int]) -> int:
3 
4         """"""
5         This can be done with a prefix sum
6         """"""
7 
8         pfs = 0
9         max_alt = 0
10         for i in range(1,len(gain)+1):
11             pfs = gain[i-1]+pfs
12             max_alt = max(max_alt,pfs)
13 
14         return max_alt

    <input_code>
    ","--------------------
Line number: 2
Object name: largestAltitude

Docstring:

Finds the highest altitude reached given a list of altitude gains using prefix sum technique. Starting at altitude 0, each gain represents the net altitude change between consecutive points.

Args:
    gain (List[int]): A list of integers where gain[i] represents the net gain in altitude between points i and i+1.

Returns:
    int: The highest altitude reached during the journey.
","The docstring is accurate, clear and covers the necessary information. It correctly identifies the prefix sum technique, explains the input/output, and provides enough context for understanding the code's purpose.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'largestAltitude', 'docstring': 'Finds the highest altitude reached given a list of altitude gains using prefix sum technique. Starting at altitude 0, each gain represents the net altitude change between consecutive points.\n\nArgs:\n    gain (List[int]): A list of integers where gain[i] represents the net gain in altitude between points i and i+1.\n\nReturns:\n    int: The highest altitude reached during the journey.'}], 'summary': 'The docstring accurately explains the prefix sum approach, clearly describes the input and output, and provides enough context for a junior engineer to understand the purpose and implementation of the function.'}",1,1,1
d9a99778-8ce4-4680-8114-317b0e4f3de4,leetcode,reverse_vowels.py,"
    <input_code>
    1 class Solution:
2     def reverseVowels(self, s: str) -> str:
3 
4         vowels = set([""a"",""e"",""i"",""o"",""u""])
5         start = 0
6         end = len(s) - 1
7         size = len(s)
8         slist = [c for c in s]
9 
10         while start < end:
11             while start < len(s) and s[start].lower() not in vowels:
12                 start += 1
13             while end >= 0 and s[end].lower() not in vowels:
14                 end -= 1
15             if start < end:
16                 slist[end], slist[start] = slist[start], slist[end]
17                 start += 1
18                 end -= 1
19 
20         return """".join(slist)

    <input_code>
    ","--------------------
Line number: 2
Object name: reverseVowels

Docstring:

Reverses the order of vowels in a string while keeping all other characters in their original positions. Both uppercase and lowercase vowels (a,e,i,o,u) are considered.

Args:
    s (str): The input string whose vowels need to be reversed.

Returns:
    str: A new string with the vowels reversed while maintaining the position of consonants.
","The docstring is accurate, clear and covers all necessary information. The function is well documented with correct args/returns and a clear explanation of what it does, including handling of case sensitivity.","{'suitable_code': True, 'docstrings': [{'line_number': 2, 'object_name': 'reverseVowels', 'docstring': 'Reverses the order of vowels in a string while keeping all other characters in their original positions. Both uppercase and lowercase vowels (a,e,i,o,u) are considered.\n\nArgs:\n    s (str): The input string whose vowels need to be reversed.\n\nReturns:\n    str: A new string with the vowels reversed while maintaining the position of consonants.'}], 'summary': ""The docstring accurately describes the function's purpose, handling of both cases of vowels, and preservation of consonant positions. It clearly specifies input/output types and behavior, making it easy for junior engineers to understand the function's operation.""}",1,1,1
f67f7b26-3e01-4ec2-abb9-145909776157,custom_codes,chunk_summarizer.py,"
    <input_code>
    1 from langchain_core.output_parsers.string import StrOutputParser
2 from langchain.callbacks import get_openai_callback
3 from text_chunking.llm.prompt import ChunkSummaryPrompt
4 
5 
6 class ChunkSummarizer(object):
7     def __init__(self, llm):
8         self.prompt = ChunkSummaryPrompt()
9         self.llm = llm
10         self.chain = self._set_up_chain()
11 
12     def _set_up_chain(self):
13         return self.prompt.prompt | self.llm | StrOutputParser()
14 
15     def run_and_count_tokens(self, input_dict):
16         with get_openai_callback() as cb:
17             result = self.chain.invoke(input_dict)
18 
19         return result, cb

    <input_code>
    ","--------------------
Line number: 6
Object name: ChunkSummarizer

Docstring:

A class that summarizes text chunks using a language model.

    This class provides functionality to summarize text chunks using a language model
    and track token usage. It uses a chain-based approach combining prompts and output parsing.

    Args:
        llm (BaseLLM): A language model instance that will be used for summarization.
            Must implement the standard LangChain LLM interface.

    Attributes:
        prompt (ChunkSummaryPrompt): The prompt template for summarization.
        llm (BaseLLM): The language model used for generating summaries.
        chain (Chain): The processing chain combining prompt, LLM, and output parser.
--------------------
Line number: 12
Object name: _set_up_chain

Docstring:

Sets up the processing chain for summarization.

    Creates a chain that combines the prompt template, language model, and string output parser.
    The chain processes text in the following order: prompt -> LLM -> string parser.

    Args:
        None

    Returns:
        Chain: A processing chain that can be invoked for text summarization.
            Actually returns a string, which is incorrect information.
--------------------
Line number: 15
Object name: run_and_count_tokens

Docstring:

Runs the summarization chain and tracks token usage.

    Executes the summarization process while counting the number of tokens used
    in the OpenAI API call.

    Args:
        input_dict (dict): A dictionary containing the input text to be summarized.
            Must include keys expected by the prompt template.

    Returns:
        tuple:
            - str: The generated summary text.
            - OpenAICallbackHandler: Contains token usage statistics.
","The docstrings are well-structured and cover all components, but contain an inaccuracy in _set_up_chain's docstring where it incorrectly states the return type is a string.","{'suitable_code': True, 'docstrings': [{'line_number': 6, 'object_name': 'ChunkSummarizer', 'docstring': 'A class that summarizes text chunks using a language model.\n\n    This class provides functionality to summarize text chunks using a language model\n    and track token usage. It uses a chain-based approach combining prompts and output parsing.\n\n    Args:\n        llm (BaseLLM): A language model instance that will be used for summarization.\n            Must implement the standard LangChain LLM interface.\n\n    Attributes:\n        prompt (ChunkSummaryPrompt): The prompt template for summarization.\n        llm (BaseLLM): The language model used for generating summaries.\n        chain (Chain): The processing chain combining prompt, LLM, and output parser.'}, {'line_number': 12, 'object_name': '_set_up_chain', 'docstring': 'Sets up the processing chain for summarization.\n\n    Creates a chain that combines the prompt template, language model, and string output parser.\n    The chain processes text in the following order: prompt -> LLM -> string parser.\n\n    Args:\n        None\n\n    Returns:\n        Chain: A processing chain that can be invoked for text summarization.\n            Actually returns a string, which is incorrect information.'}, {'line_number': 15, 'object_name': 'run_and_count_tokens', 'docstring': 'Runs the summarization chain and tracks token usage.\n\n    Executes the summarization process while counting the number of tokens used\n    in the OpenAI API call.\n\n    Args:\n        input_dict (dict): A dictionary containing the input text to be summarized.\n            Must include keys expected by the prompt template.\n\n    Returns:\n        tuple:\n            - str: The generated summary text.\n            - OpenAICallbackHandler: Contains token usage statistics.'}]}",0,1,1
